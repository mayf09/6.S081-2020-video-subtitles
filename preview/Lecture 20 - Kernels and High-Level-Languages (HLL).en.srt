1
00:00:02,000 --> 00:00:03,360
all right why uh why don't we get

2
00:00:03,360 --> 00:00:03,919
started

3
00:00:03,919 --> 00:00:06,480
uh you know if people want to turn on

4
00:00:06,480 --> 00:00:07,600
the camera again or

5
00:00:07,600 --> 00:00:08,960
well i'm going to do that i'll be great

6
00:00:08,960 --> 00:00:10,800
just to create sort of a

7
00:00:10,800 --> 00:00:14,559
class atmosphere uh as best as we can

8
00:00:14,559 --> 00:00:17,680
okay so this is uh uh i'm going to talk

9
00:00:17,680 --> 00:00:19,199
today about this paper you know the

10
00:00:19,199 --> 00:00:20,800
benefits and cost of writing a unix

11
00:00:20,800 --> 00:00:21,279
kernel

12
00:00:21,279 --> 00:00:24,560
and i love the language um uh

13
00:00:24,560 --> 00:00:26,240
you know this is a basically a paper

14
00:00:26,240 --> 00:00:27,760
that was partly written because of

15
00:00:27,760 --> 00:00:30,800
uh s081 or 828.

16
00:00:30,800 --> 00:00:33,520
uh and uh this is a paper that you know

17
00:00:33,520 --> 00:00:34,239
we've written

18
00:00:34,239 --> 00:00:36,719
uh robert and i and but the main person

19
00:00:36,719 --> 00:00:37,440
was

20
00:00:37,440 --> 00:00:40,239
the main lead offers cody cutler who's a

21
00:00:40,239 --> 00:00:40,879
t8

22
00:00:40,879 --> 00:00:44,239
uh this class many many times

23
00:00:44,239 --> 00:00:45,600
it's always a little bit you know i

24
00:00:45,600 --> 00:00:46,960
don't really enjoy actually particularly

25
00:00:46,960 --> 00:00:47,600
talking about

26
00:00:47,600 --> 00:00:48,719
you know papers that we worked on

27
00:00:48,719 --> 00:00:50,239
ourselves but you know they again this

28
00:00:50,239 --> 00:00:51,120
paper came about

29
00:00:51,120 --> 00:00:54,480
basically of a r81 and a28 and so

30
00:00:54,480 --> 00:00:56,320
i'm going to use some slides uh this

31
00:00:56,320 --> 00:00:58,719
time instead of actually writing on a on

32
00:00:58,719 --> 00:01:00,800
a whiteboard

33
00:01:00,800 --> 00:01:02,719
and so the really the source of this

34
00:01:02,719 --> 00:01:03,840
paper is

35
00:01:03,840 --> 00:01:05,920
this question and then what language

36
00:01:05,920 --> 00:01:07,200
should you write

37
00:01:07,200 --> 00:01:09,920
a kernel and this is a question that you

38
00:01:09,920 --> 00:01:11,040
know many

39
00:01:11,040 --> 00:01:14,320
many of you asked uh or your your

40
00:01:14,320 --> 00:01:17,360
students in the past uh 808 or s8

41
00:01:17,360 --> 00:01:20,000
uh asked many many many times uh partly

42
00:01:20,000 --> 00:01:21,119
you know because you know you have bugs

43
00:01:21,119 --> 00:01:22,400
in the operating system

44
00:01:22,400 --> 00:01:24,240
or in your kernel and you're like well

45
00:01:24,240 --> 00:01:25,439
if i would written in this other

46
00:01:25,439 --> 00:01:27,040
language then you know maybe i would

47
00:01:27,040 --> 00:01:29,040
have not had those bugs

48
00:01:29,040 --> 00:01:31,759
um and so this is a question that often

49
00:01:31,759 --> 00:01:32,479
comes about

50
00:01:32,479 --> 00:01:35,119
and it turns out you know in the

51
00:01:35,119 --> 00:01:36,799
operating system community at large you

52
00:01:36,799 --> 00:01:37,680
know this is a

53
00:01:37,680 --> 00:01:40,159
sort of a hotly debated question but not

54
00:01:40,159 --> 00:01:42,079
that many facts you would actually make

55
00:01:42,079 --> 00:01:42,880
a sort of an

56
00:01:42,880 --> 00:01:45,680
any informed discussion and what we'll

57
00:01:45,680 --> 00:01:46,320
see at this

58
00:01:46,320 --> 00:01:47,520
at the end of this lecture or during

59
00:01:47,520 --> 00:01:48,960
this lecture where you as you read the

60
00:01:48,960 --> 00:01:49,680
paper

61
00:01:49,680 --> 00:01:52,240
i you know we don't really have a crisp

62
00:01:52,240 --> 00:01:53,280
uh

63
00:01:53,280 --> 00:01:56,159
answer to this question uh but we have

64
00:01:56,159 --> 00:01:57,360
sort of a you know this paper

65
00:01:57,360 --> 00:01:58,079
contributes

66
00:01:58,079 --> 00:01:59,600
you know a bunch of data that you know

67
00:01:59,600 --> 00:02:01,040
allows you to have a sort of a little

68
00:02:01,040 --> 00:02:01,840
bit more of an

69
00:02:01,840 --> 00:02:04,320
in-depth discussion uh about you know

70
00:02:04,320 --> 00:02:05,040
what is a

71
00:02:05,040 --> 00:02:06,479
uh what is a good programming language

72
00:02:06,479 --> 00:02:09,119
for the kernel and so that was really

73
00:02:09,119 --> 00:02:12,720
uh the origin of this paper and uh

74
00:02:12,720 --> 00:02:16,229
and that's over

75
00:02:16,239 --> 00:02:19,120
and the the source you know of this

76
00:02:19,120 --> 00:02:22,560
paper is basically you guys so

77
00:02:22,560 --> 00:02:25,599
i tried to answer this question

78
00:02:25,599 --> 00:02:29,200
uh we wrote a new kernel

79
00:02:29,200 --> 00:02:31,120
um and you know we did it in the

80
00:02:31,120 --> 00:02:33,360
language uh with automatic

81
00:02:33,360 --> 00:02:34,720
memory management that means with the

82
00:02:34,720 --> 00:02:36,480
guard collector so you don't actually

83
00:02:36,480 --> 00:02:37,200
have to call

84
00:02:37,200 --> 00:02:40,160
free and that avoids a class of books so

85
00:02:40,160 --> 00:02:41,680
that's one of the properties that a

86
00:02:41,680 --> 00:02:43,440
high-level language typically has

87
00:02:43,440 --> 00:02:45,200
and so we wanted to have we picked a

88
00:02:45,200 --> 00:02:46,879
language that has that and we

89
00:02:46,879 --> 00:02:48,800
followed basically the traditional

90
00:02:48,800 --> 00:02:50,000
monolithic uh unit

91
00:02:50,000 --> 00:02:51,440
organization so we could do a sort of a

92
00:02:51,440 --> 00:02:53,280
fair comparison

93
00:02:53,280 --> 00:02:54,800
and in fact some ways you could think

94
00:02:54,800 --> 00:02:56,480
about what we built is

95
00:02:56,480 --> 00:03:00,560
uh something like xc6 uh much much more

96
00:03:00,560 --> 00:03:05,040
more features and more high performance

97
00:03:05,040 --> 00:03:07,760
i mean as you know xp6 has all kinds of

98
00:03:07,760 --> 00:03:09,040
uh

99
00:03:09,040 --> 00:03:11,519
quadratic algorithms or linear search uh

100
00:03:11,519 --> 00:03:13,120
type algorithms and you know of course

101
00:03:13,120 --> 00:03:14,400
you know if you want to write a gfi

102
00:03:14,400 --> 00:03:17,200
performance you can't have those

103
00:03:17,200 --> 00:03:20,319
uh so that was the origin of this paper

104
00:03:20,319 --> 00:03:22,319
and the reason why we built uh biscuit

105
00:03:22,319 --> 00:03:23,760
you know trying to answer that question

106
00:03:23,760 --> 00:03:25,360
or at least shed some light

107
00:03:25,360 --> 00:03:26,480
so i'm first going to talk a little bit

108
00:03:26,480 --> 00:03:29,360
about sort of more general background uh

109
00:03:29,360 --> 00:03:32,319
a lot of questions over email we're sort

110
00:03:32,319 --> 00:03:32,720
of

111
00:03:32,720 --> 00:03:34,799
trying to get a little bit more context

112
00:03:34,799 --> 00:03:36,239
and then i will dive into

113
00:03:36,239 --> 00:03:38,640
uh biscuit in a more in more detail i

114
00:03:38,640 --> 00:03:39,680
feel free to

115
00:03:39,680 --> 00:03:41,200
jump in you know with questions in any

116
00:03:41,200 --> 00:03:43,040
particular point of time uh

117
00:03:43,040 --> 00:03:45,120
you know as i said you know this paper

118
00:03:45,120 --> 00:03:46,319
was motivated

119
00:03:46,319 --> 00:03:47,840
by questions that you asked and so you

120
00:03:47,840 --> 00:03:49,840
know please please ask keep asking

121
00:03:49,840 --> 00:03:51,440
questions

122
00:03:51,440 --> 00:03:55,280
um so uh as you

123
00:03:55,280 --> 00:03:57,280
know just through sort of the setting of

124
00:03:57,280 --> 00:03:59,040
this paper is that you know a lot of

125
00:03:59,040 --> 00:04:00,879
kernels are written in c and you know

126
00:04:00,879 --> 00:04:02,640
xc6 is written in c you're programming

127
00:04:02,640 --> 00:04:03,439
in c

128
00:04:03,439 --> 00:04:05,120
uh but most popular kernels that you

129
00:04:05,120 --> 00:04:06,480
know sit on your desktop or

130
00:04:06,480 --> 00:04:08,959
you know your phone are written in c you

131
00:04:08,959 --> 00:04:10,400
know windows lindex all

132
00:04:10,400 --> 00:04:12,959
linux dual uh you know the various forms

133
00:04:12,959 --> 00:04:14,799
of bsds

134
00:04:14,799 --> 00:04:17,840
and uh and the reason um

135
00:04:17,840 --> 00:04:20,639
they've written or written in c is that

136
00:04:20,639 --> 00:04:21,840
um

137
00:04:21,840 --> 00:04:23,759
you see it provides you a lot of control

138
00:04:23,759 --> 00:04:25,040
as you know seen in the

139
00:04:25,040 --> 00:04:27,199
labs you have complete control over

140
00:04:27,199 --> 00:04:29,040
memory allocation and freeing

141
00:04:29,040 --> 00:04:31,280
uh there's almost no implicit code you

142
00:04:31,280 --> 00:04:32,800
know you can almost sort of imagine when

143
00:04:32,800 --> 00:04:34,320
you're reading the c code like what the

144
00:04:34,320 --> 00:04:36,880
corresponding risk five instructions are

145
00:04:36,880 --> 00:04:38,720
uh you have direct essays memory you

146
00:04:38,720 --> 00:04:39,919
know you can read and write you know the

147
00:04:39,919 --> 00:04:43,280
pte bits you know or the registers of

148
00:04:43,280 --> 00:04:46,320
devices uh and you know see itself you

149
00:04:46,320 --> 00:04:47,520
come through very few

150
00:04:47,520 --> 00:04:49,120
uh dependencies you know there's no

151
00:04:49,120 --> 00:04:50,720
large run time that you actually have to

152
00:04:50,720 --> 00:04:52,320
have you know to be able to run a c

153
00:04:52,320 --> 00:04:53,759
program you can almost run it almost

154
00:04:53,759 --> 00:04:56,400
immediately on the bare

155
00:04:56,400 --> 00:04:58,479
you've seen that like when xv6 boots you

156
00:04:58,479 --> 00:04:59,680
know it's basically a few lines of

157
00:04:59,680 --> 00:05:00,960
assembly and then basically you're

158
00:05:00,960 --> 00:05:02,720
running c code

159
00:05:02,720 --> 00:05:05,039
um so there are all the sort of good

160
00:05:05,039 --> 00:05:05,759
virtues

161
00:05:05,759 --> 00:05:07,759
of c and you know one reason that we

162
00:05:07,759 --> 00:05:09,360
like c a lot

163
00:05:09,360 --> 00:05:11,840
uh but c also already has some downsides

164
00:05:11,840 --> 00:05:12,880
um

165
00:05:12,880 --> 00:05:14,479
you know it has been proven over the

166
00:05:14,479 --> 00:05:16,320
last you know sort of decades

167
00:05:16,320 --> 00:05:19,199
uh writing security code is difficult uh

168
00:05:19,199 --> 00:05:20,960
you know there are types of bugs

169
00:05:20,960 --> 00:05:24,160
that can you you can

170
00:05:24,160 --> 00:05:26,479
often be exploited uh whether it is

171
00:05:26,479 --> 00:05:28,000
buffer overruns which are probably the

172
00:05:28,000 --> 00:05:29,600
most well-known one like you're writing

173
00:05:29,600 --> 00:05:30,080
behind

174
00:05:30,080 --> 00:05:33,520
the past uh an array bound or you're

175
00:05:33,520 --> 00:05:34,880
writing you know below

176
00:05:34,880 --> 00:05:37,759
you know your stack um use after three

177
00:05:37,759 --> 00:05:38,720
bucks you know where

178
00:05:38,720 --> 00:05:41,440
you know the your freezer memory uh but

179
00:05:41,440 --> 00:05:43,120
it's still in use

180
00:05:43,120 --> 00:05:44,960
uh and someone somebody scribbles on it

181
00:05:44,960 --> 00:05:46,720
and you know you may scribble something

182
00:05:46,720 --> 00:05:47,919
bad on it

183
00:05:47,919 --> 00:05:51,039
uh and generally you know when uh

184
00:05:51,039 --> 00:05:52,639
threats are sharing memory it's

185
00:05:52,639 --> 00:05:54,160
typically difficult to decide you know

186
00:05:54,160 --> 00:05:56,880
one action the memory can be freed

187
00:05:56,880 --> 00:05:58,720
some of these bugs you know don't really

188
00:05:58,720 --> 00:05:59,919
show up that

189
00:05:59,919 --> 00:06:01,840
uh you know some debug manifest

190
00:06:01,840 --> 00:06:04,080
themselves explicitly in xv6 some less

191
00:06:04,080 --> 00:06:04,479
so

192
00:06:04,479 --> 00:06:07,440
you know uh you know xv6 is very little

193
00:06:07,440 --> 00:06:08,080
dynamic

194
00:06:08,080 --> 00:06:09,759
uh memory allocation you know almost

195
00:06:09,759 --> 00:06:11,440
everything is pre-allocated right up

196
00:06:11,440 --> 00:06:12,240
front

197
00:06:12,240 --> 00:06:13,919
uh but buffer overruns and usually after

198
00:06:13,919 --> 00:06:15,759
three bucks you know definitely

199
00:06:15,759 --> 00:06:19,120
do show up um and so

200
00:06:19,120 --> 00:06:22,479
in fact you know if you look at uh cves

201
00:06:22,479 --> 00:06:24,479
you know these are the uh you know

202
00:06:24,479 --> 00:06:25,759
there's a website where there's an

203
00:06:25,759 --> 00:06:26,720
organization that

204
00:06:26,720 --> 00:06:28,720
keeps sort of controlled that checks and

205
00:06:28,720 --> 00:06:30,880
uh keeps a record of all sort of the

206
00:06:30,880 --> 00:06:32,400
security exploits

207
00:06:32,400 --> 00:06:34,080
and you investigate that you know you'll

208
00:06:34,080 --> 00:06:36,080
find that in 2017 when we were doing

209
00:06:36,080 --> 00:06:37,280
this paper that

210
00:06:37,280 --> 00:06:40,800
uh there were 40 linux kernel uh

211
00:06:40,800 --> 00:06:44,000
bugs that can actually lead to a an

212
00:06:44,000 --> 00:06:45,120
attacker running

213
00:06:45,120 --> 00:06:47,360
uh you know take a complete control over

214
00:06:47,360 --> 00:06:48,479
the machine

215
00:06:48,479 --> 00:06:49,840
and clearly you know those are serious

216
00:06:49,840 --> 00:06:51,599
bugs and then those bugs came out of

217
00:06:51,599 --> 00:06:52,960
buffer overruns

218
00:06:52,960 --> 00:06:56,639
and uh other type of memory safety bucks

219
00:06:56,639 --> 00:06:59,840
um so you know that's sort of too bad

220
00:06:59,840 --> 00:07:01,360
you know that you know if you write code

221
00:07:01,360 --> 00:07:03,199
in c you know that actually is hard even

222
00:07:03,199 --> 00:07:04,639
you know for people that do this

223
00:07:04,639 --> 00:07:06,960
professionally and uh to actually get

224
00:07:06,960 --> 00:07:08,639
this uh right

225
00:07:08,639 --> 00:07:10,479
uh and then of course you know i'm sure

226
00:07:10,479 --> 00:07:12,000
you've seen this in the lab you know

227
00:07:12,000 --> 00:07:15,039
probably certainly i remember from some

228
00:07:15,039 --> 00:07:15,440
of the

229
00:07:15,440 --> 00:07:17,280
the piazza questions you know the number

230
00:07:17,280 --> 00:07:19,039
you run into this used after three bucks

231
00:07:19,039 --> 00:07:19,520
you know

232
00:07:19,520 --> 00:07:21,919
in particular in the copy and write lab

233
00:07:21,919 --> 00:07:25,440
uh they showed up a bunch of times

234
00:07:25,440 --> 00:07:27,360
so you know so one reason that a

235
00:07:27,360 --> 00:07:29,199
high-level image would be attractive

236
00:07:29,199 --> 00:07:31,599
uh is that a high-level language you

237
00:07:31,599 --> 00:07:33,360
know provides memory safety

238
00:07:33,360 --> 00:07:36,560
uh and so all these bugs or the cv

239
00:07:36,560 --> 00:07:37,919
exploits that i mentioned on the

240
00:07:37,919 --> 00:07:40,080
previous slide would just not be

241
00:07:40,080 --> 00:07:41,840
would not be possible you know it could

242
00:07:41,840 --> 00:07:44,319
just you know if they happen they either

243
00:07:44,319 --> 00:07:45,599
would result in a panic

244
00:07:45,599 --> 00:07:47,280
you know because you know the run time

245
00:07:47,280 --> 00:07:49,280
would say like oh you're writing past

246
00:07:49,280 --> 00:07:50,720
the rate you can't do that

247
00:07:50,720 --> 00:07:53,599
uh or you know you're just you couldn't

248
00:07:53,599 --> 00:07:54,960
manifest itself at all

249
00:07:54,960 --> 00:07:56,479
you know because these languages will

250
00:07:56,479 --> 00:08:00,629
allow you to write that kind of code

251
00:08:00,639 --> 00:08:02,400
so there are of course other benefits to

252
00:08:02,400 --> 00:08:04,160
a high level language

253
00:08:04,160 --> 00:08:07,199
which often is also mentioned by you

254
00:08:07,199 --> 00:08:08,639
know

255
00:08:08,639 --> 00:08:10,160
students in this class when they're

256
00:08:10,160 --> 00:08:11,759
doing the labs in addition to type

257
00:08:11,759 --> 00:08:13,120
safety you know there's the automatic

258
00:08:13,120 --> 00:08:14,319
memory management of your garbage

259
00:08:14,319 --> 00:08:15,199
collector

260
00:08:15,199 --> 00:08:17,120
uh so freeing is easy you just don't

261
00:08:17,120 --> 00:08:18,240
have to think about it the developer

262
00:08:18,240 --> 00:08:20,240
selector does all the work for you

263
00:08:20,240 --> 00:08:22,319
uh it's good for concurrency you know it

264
00:08:22,319 --> 00:08:23,599
has good abstractions

265
00:08:23,599 --> 00:08:25,120
you know whether it's like in go you

266
00:08:25,120 --> 00:08:27,120
know with interfaces or some other you

267
00:08:27,120 --> 00:08:29,280
know classes or some other form of

268
00:08:29,280 --> 00:08:31,840
you know that forces you or encourage

269
00:08:31,840 --> 00:08:34,800
you to actually write modular code

270
00:08:34,800 --> 00:08:38,080
um the downsides and you might be

271
00:08:38,080 --> 00:08:39,360
wondering like well if you know there's

272
00:08:39,360 --> 00:08:41,279
so many upsides to high-level images

273
00:08:41,279 --> 00:08:44,320
you know why not you know why is xc6 not

274
00:08:44,320 --> 00:08:44,959
written in

275
00:08:44,959 --> 00:08:48,160
you know java go python or whatever um

276
00:08:48,160 --> 00:08:50,000
and the reason is you know the

277
00:08:50,000 --> 00:08:52,000
or linux you know the reason is this is

278
00:08:52,000 --> 00:08:53,519
poor performance you know

279
00:08:53,519 --> 00:08:55,600
there's a cost you know to actually uh

280
00:08:55,600 --> 00:08:56,880
high level language you know sometimes

281
00:08:56,880 --> 00:08:58,080
this is referred to as the

282
00:08:58,080 --> 00:09:01,279
high level language tax um and you know

283
00:09:01,279 --> 00:09:02,240
these are basically

284
00:09:02,240 --> 00:09:04,480
you know if you do an array bound an

285
00:09:04,480 --> 00:09:06,240
array index you know you have to

286
00:09:06,240 --> 00:09:07,920
check the bounce you know you have to

287
00:09:07,920 --> 00:09:11,590
check no pointers

288
00:09:11,600 --> 00:09:14,959
you have to have more expensive casts

289
00:09:14,959 --> 00:09:16,399
and you know garbage collection itself

290
00:09:16,399 --> 00:09:17,680
is also not free you know there's going

291
00:09:17,680 --> 00:09:19,440
to be some cycles spent you know

292
00:09:19,440 --> 00:09:21,279
tracking down which objects are free and

293
00:09:21,279 --> 00:09:22,800
which are allocated and you know

294
00:09:22,800 --> 00:09:26,399
that's the cost uh

295
00:09:26,399 --> 00:09:27,600
so that's you know sort of from the

296
00:09:27,600 --> 00:09:29,680
performance side and a lot of the paper

297
00:09:29,680 --> 00:09:30,720
focuses on this

298
00:09:30,720 --> 00:09:32,959
uh and then in principle you know often

299
00:09:32,959 --> 00:09:33,839
you know i mean

300
00:09:33,839 --> 00:09:34,959
it's perceived that there's sort of

301
00:09:34,959 --> 00:09:37,200
incompatibilities with linux with kernel

302
00:09:37,200 --> 00:09:39,279
programming

303
00:09:39,279 --> 00:09:41,040
no direct memory access you know because

304
00:09:41,040 --> 00:09:43,120
nothing principle could you know

305
00:09:43,120 --> 00:09:46,399
violate type safety uh no handwritten

306
00:09:46,399 --> 00:09:48,160
assembly and you need some handwritten

307
00:09:48,160 --> 00:09:49,279
assembly in the kernel

308
00:09:49,279 --> 00:09:50,720
you know whereas the context switch

309
00:09:50,720 --> 00:09:52,880
between two threads or like to get off

310
00:09:52,880 --> 00:09:53,440
the ground

311
00:09:53,440 --> 00:09:56,800
when the machine boots um in

312
00:09:56,800 --> 00:10:00,720
um uh you know i can

313
00:10:00,720 --> 00:10:02,800
you know the language may have a

314
00:10:02,800 --> 00:10:04,640
particular plan for

315
00:10:04,640 --> 00:10:06,640
a concurrency or parallelism that might

316
00:10:06,640 --> 00:10:08,560
not line up you know with the

317
00:10:08,560 --> 00:10:10,480
plan that the the kernel needs were

318
00:10:10,480 --> 00:10:11,839
concurrently in parallelism you know

319
00:10:11,839 --> 00:10:13,680
we've seen for example in the

320
00:10:13,680 --> 00:10:17,440
uh scheduling lecture the you know

321
00:10:17,440 --> 00:10:19,120
one thread passes a lock to another

322
00:10:19,120 --> 00:10:20,720
thread or you know there's sort of a

323
00:10:20,720 --> 00:10:21,200
couple

324
00:10:21,200 --> 00:10:22,800
you know there's patterns of currency

325
00:10:22,800 --> 00:10:24,480
management that are sort of unusual in

326
00:10:24,480 --> 00:10:26,720
user programs but they do show up in

327
00:10:26,720 --> 00:10:32,079
uh in kernels um and so um

328
00:10:32,079 --> 00:10:34,320
so the goal basically of this you know

329
00:10:34,320 --> 00:10:36,560
uh paper was to sort of measure the

330
00:10:36,560 --> 00:10:37,279
high-level

331
00:10:37,279 --> 00:10:39,040
uh language trade-offs you know explore

332
00:10:39,040 --> 00:10:40,640
the total effects of using high-level 11

333
00:10:40,640 --> 00:10:42,880
instead of c you know both in terms of

334
00:10:42,880 --> 00:10:45,760
uh safety programmability but also for

335
00:10:45,760 --> 00:10:47,040
performance cost

336
00:10:47,040 --> 00:10:48,480
and of course if you'd like to do this

337
00:10:48,480 --> 00:10:49,839
you know this kind of an experiment you

338
00:10:49,839 --> 00:10:50,160
know

339
00:10:50,160 --> 00:10:51,279
you need to do that sort of on a

340
00:10:51,279 --> 00:10:52,720
production grade kernel you can't do

341
00:10:52,720 --> 00:10:54,720
that on xv6 because it's so slow that

342
00:10:54,720 --> 00:10:55,920
basically you probably wouldn't learn

343
00:10:55,920 --> 00:10:57,200
anything you know

344
00:10:57,200 --> 00:10:58,480
if the program the current written

345
00:10:58,480 --> 00:11:00,240
slogan c you know you're writing a slow

346
00:11:00,240 --> 00:11:00,880
in

347
00:11:00,880 --> 00:11:02,480
uh go you know it doesn't really tell

348
00:11:02,480 --> 00:11:04,800
you much about you know the c first go

349
00:11:04,800 --> 00:11:06,560
question it just says like well xp6 is

350
00:11:06,560 --> 00:11:07,519
slow

351
00:11:07,519 --> 00:11:09,040
and so you don't want to like to do that

352
00:11:09,040 --> 00:11:11,200
in a more you know high performance you

353
00:11:11,200 --> 00:11:11,519
know

354
00:11:11,519 --> 00:11:13,600
oriented kernel or the kernel is

355
00:11:13,600 --> 00:11:17,430
designed for high performance

356
00:11:17,440 --> 00:11:18,800
and so you know uh you know one of the

357
00:11:18,800 --> 00:11:20,079
things that was surprising because like

358
00:11:20,079 --> 00:11:20,959
many of you

359
00:11:20,959 --> 00:11:23,839
asked this uh your predecessors asked

360
00:11:23,839 --> 00:11:24,240
this

361
00:11:24,240 --> 00:11:27,279
and uh you know you would imagine well

362
00:11:27,279 --> 00:11:28,640
this question must be answered in the

363
00:11:28,640 --> 00:11:29,519
literature

364
00:11:29,519 --> 00:11:30,800
and you know that turns out that it

365
00:11:30,800 --> 00:11:32,720
actually isn't uh it is

366
00:11:32,720 --> 00:11:34,640
there's quite a number of studies that

367
00:11:34,640 --> 00:11:35,920
look into

368
00:11:35,920 --> 00:11:37,839
the question of like high-level language

369
00:11:37,839 --> 00:11:39,360
trade-offs in the context of user

370
00:11:39,360 --> 00:11:40,480
programs

371
00:11:40,480 --> 00:11:43,519
uh and uh but you know as you know

372
00:11:43,519 --> 00:11:44,880
the kernel is you know quite a bit

373
00:11:44,880 --> 00:11:46,880
different than from user programs uh so

374
00:11:46,880 --> 00:11:48,320
for example memory management careful

375
00:11:48,320 --> 00:11:49,920
manual manager is really important

376
00:11:49,920 --> 00:11:51,600
uh these different types of concurrency

377
00:11:51,600 --> 00:11:53,279
may be slightly different so we

378
00:11:53,279 --> 00:11:55,120
wanted to do it in the context of a

379
00:11:55,120 --> 00:11:57,120
kernel and you know we're going to

380
00:11:57,120 --> 00:11:58,720
actually really find any sort of papers

381
00:11:58,720 --> 00:11:59,279
that really

382
00:11:59,279 --> 00:12:01,519
answer this question the closer you

383
00:12:01,519 --> 00:12:02,880
could come to is there

384
00:12:02,880 --> 00:12:06,399
you know there are many kernels written

385
00:12:06,399 --> 00:12:07,839
in high-level language you know there's

386
00:12:07,839 --> 00:12:09,760
a long history of doing that they are

387
00:12:09,760 --> 00:12:11,839
dating back even to sort of the early

388
00:12:11,839 --> 00:12:13,200
list machines

389
00:12:13,200 --> 00:12:16,320
uh and you know and but many of the sort

390
00:12:16,320 --> 00:12:16,639
of

391
00:12:16,639 --> 00:12:20,639
uh recent versions of these kernels

392
00:12:20,639 --> 00:12:23,040
are not really written with the idea of

393
00:12:23,040 --> 00:12:25,120
evaluating this high-level language

394
00:12:25,120 --> 00:12:28,320
tax question but really to explore new

395
00:12:28,320 --> 00:12:31,120
os designs

396
00:12:31,120 --> 00:12:34,480
or new os architectures and so

397
00:12:34,480 --> 00:12:36,000
none of them sort of really measure

398
00:12:36,000 --> 00:12:37,920
directly you know sort of

399
00:12:37,920 --> 00:12:40,720
do a head-to-head comparison and keep

400
00:12:40,720 --> 00:12:42,560
the structure the same

401
00:12:42,560 --> 00:12:44,000
so that you can really focus on this

402
00:12:44,000 --> 00:12:46,240
issue of the language as opposed to

403
00:12:46,240 --> 00:12:49,990
some other issues

404
00:12:50,000 --> 00:12:51,920
in fact we used to read you know some of

405
00:12:51,920 --> 00:12:53,120
these papers actually in

406
00:12:53,120 --> 00:12:59,269
in the past um

407
00:12:59,279 --> 00:13:02,000
so uh you know turns on one reason maybe

408
00:13:02,000 --> 00:13:03,440
that you know there's not a lot of ton

409
00:13:03,440 --> 00:13:04,000
of work

410
00:13:04,000 --> 00:13:05,360
uh that actually answered these were a

411
00:13:05,360 --> 00:13:06,480
ton of papers that are answering this

412
00:13:06,480 --> 00:13:07,360
question is

413
00:13:07,360 --> 00:13:10,560
uh it's actually tricky to do it uh uh

414
00:13:10,560 --> 00:13:12,160
you know basically if you really do it

415
00:13:12,160 --> 00:13:13,440
right you know you want to compare it

416
00:13:13,440 --> 00:13:14,560
with a production grade c

417
00:13:14,560 --> 00:13:16,560
kernel that means like something like

418
00:13:16,560 --> 00:13:17,839
linux uh

419
00:13:17,839 --> 00:13:20,639
or something in windows or whatever but

420
00:13:20,639 --> 00:13:21,680
then you have to build

421
00:13:21,680 --> 00:13:23,600
a production creates you know kernel and

422
00:13:23,600 --> 00:13:24,880
you know clearly for

423
00:13:24,880 --> 00:13:28,160
a small team that's very hard to do

424
00:13:28,160 --> 00:13:30,160
i mean you know there's lots and lots of

425
00:13:30,160 --> 00:13:31,839
linux kernel developers

426
00:13:31,839 --> 00:13:34,880
they make many many changes you know

427
00:13:34,880 --> 00:13:37,279
week by week day by day and so it's

428
00:13:37,279 --> 00:13:38,480
going to be hard

429
00:13:38,480 --> 00:13:41,360
to uh you know to do the same thing and

430
00:13:41,360 --> 00:13:42,800
build an equivalent you know

431
00:13:42,800 --> 00:13:44,959
type of thing so you have to settle for

432
00:13:44,959 --> 00:13:46,160
something slightly

433
00:13:46,160 --> 00:13:49,199
less than uh

434
00:13:49,199 --> 00:13:52,880
uh so um so so the best move you could

435
00:13:52,880 --> 00:13:54,320
do or the best we could

436
00:13:54,320 --> 00:13:56,160
to do is you know build a high level

437
00:13:56,160 --> 00:13:57,199
build the kernel in a high level

438
00:13:57,199 --> 00:13:58,560
language you know keep most of the

439
00:13:58,560 --> 00:14:02,079
important aspects the same as linux

440
00:14:02,079 --> 00:14:04,079
the performance roughly optimize the

441
00:14:04,079 --> 00:14:05,600
performance until it's roughly similar

442
00:14:05,600 --> 00:14:07,120
to linux you know even though maybe it's

443
00:14:07,120 --> 00:14:08,800
not identically exactly identical

444
00:14:08,800 --> 00:14:10,160
features but you know gets into the same

445
00:14:10,160 --> 00:14:11,199
ballpark

446
00:14:11,199 --> 00:14:12,639
and then you know measure the high level

447
00:14:12,639 --> 00:14:15,590
along with tradeoffs

448
00:14:15,600 --> 00:14:17,199
and of course you know the risk you know

449
00:14:17,199 --> 00:14:18,720
this approach is that you know the

450
00:14:18,720 --> 00:14:20,480
kernel that we built you know actually

451
00:14:20,480 --> 00:14:21,920
is slightly different than linux you

452
00:14:21,920 --> 00:14:23,440
know it's not gonna be exactly like

453
00:14:23,440 --> 00:14:25,120
linux and so you know you gotta you know

454
00:14:25,120 --> 00:14:26,639
there's uh you gotta be very careful

455
00:14:26,639 --> 00:14:27,120
when

456
00:14:27,120 --> 00:14:29,839
drawing any conclusions and you know

457
00:14:29,839 --> 00:14:30,560
we'll

458
00:14:30,560 --> 00:14:32,320
and this is one reason why you cancel or

459
00:14:32,320 --> 00:14:33,839
give a really crystal clear

460
00:14:33,839 --> 00:14:35,199
uh answer to this question that

461
00:14:35,199 --> 00:14:37,360
basically this paper poses uh but

462
00:14:37,360 --> 00:14:38,560
we can hopefully you know get a little

463
00:14:38,560 --> 00:14:40,560
bit more deeper insight than basically

464
00:14:40,560 --> 00:14:44,399
you know saying almost nothing about it

465
00:14:44,399 --> 00:14:47,120
does this make sense so far any

466
00:14:47,120 --> 00:14:48,639
questions

467
00:14:48,639 --> 00:14:50,240
that's sort of the context you know of

468
00:14:50,240 --> 00:14:52,560
this paper and you know

469
00:14:52,560 --> 00:14:55,920
why we went actually often did it

470
00:14:55,920 --> 00:14:58,720
okay so uh if there's no questions i'd

471
00:14:58,720 --> 00:14:59,199
like to

472
00:14:59,199 --> 00:15:00,320
talk a little bit more about the

473
00:15:00,320 --> 00:15:03,120
methodology uh

474
00:15:03,120 --> 00:15:06,320
and uh so uh so basically you know the

475
00:15:06,320 --> 00:15:07,839
sort of setup is you know here's on the

476
00:15:07,839 --> 00:15:10,079
left side you know we have our

477
00:15:10,079 --> 00:15:13,760
uh this is gonna be you know biscuit uh

478
00:15:13,760 --> 00:15:16,800
you know we're gonna in in our

479
00:15:16,800 --> 00:15:18,079
particular case you know we wrote

480
00:15:18,079 --> 00:15:21,519
for this paper to colonel in uh go um

481
00:15:21,519 --> 00:15:24,560
it provides roughly a similar uh you

482
00:15:24,560 --> 00:15:26,000
know subset of the system calls that

483
00:15:26,000 --> 00:15:27,360
linux provides but you know

484
00:15:27,360 --> 00:15:29,360
the way that uh but they have the same

485
00:15:29,360 --> 00:15:31,040
arguments you know the uh

486
00:15:31,040 --> 00:15:33,680
same calling inventions and we run

487
00:15:33,680 --> 00:15:35,360
basically the same applications on top

488
00:15:35,360 --> 00:15:36,639
of that interface

489
00:15:36,639 --> 00:15:38,399
so you know one of the applications is

490
00:15:38,399 --> 00:15:42,320
ngx which is a website web server

491
00:15:42,320 --> 00:15:44,160
and so the idea is that you know we run

492
00:15:44,160 --> 00:15:46,000
the same

493
00:15:46,000 --> 00:15:49,199
uh application both on biscuit and linux

494
00:15:49,199 --> 00:15:50,639
you know the the application will

495
00:15:50,639 --> 00:15:52,480
generate the same system called trace

496
00:15:52,480 --> 00:15:55,120
with exactly the same arguments

497
00:15:55,120 --> 00:15:57,759
and both biscuit and linux you know

498
00:15:57,759 --> 00:15:58,399
perform

499
00:15:58,399 --> 00:16:00,000
you know all the necessary operations

500
00:16:00,000 --> 00:16:02,639
that are invoked by those system calls

501
00:16:02,639 --> 00:16:04,800
and then we can sort of you know look at

502
00:16:04,800 --> 00:16:06,079
you know the differences basically

503
00:16:06,079 --> 00:16:06,800
between

504
00:16:06,800 --> 00:16:08,480
you know the high-level language kernel

505
00:16:08,480 --> 00:16:10,480
and linux and sort of talk about like

506
00:16:10,480 --> 00:16:13,839
you know what are the trade-offs

507
00:16:13,839 --> 00:16:15,920
so that's sort of the core of the

508
00:16:15,920 --> 00:16:17,360
methodology and again

509
00:16:17,360 --> 00:16:19,040
you know because linux and biscuit are

510
00:16:19,040 --> 00:16:20,959
not going to be exactly identical

511
00:16:20,959 --> 00:16:22,560
uh you know there's going to be you know

512
00:16:22,560 --> 00:16:24,720
some uh differences but you know we

513
00:16:24,720 --> 00:16:27,199
you know the we spend a lot of time uh

514
00:16:27,199 --> 00:16:28,639
in this good trying to you know make the

515
00:16:28,639 --> 00:16:30,560
comparison as fair as possible

516
00:16:30,560 --> 00:16:34,160
yeah or whatever possibles we could

517
00:16:34,160 --> 00:16:35,040
think of

518
00:16:35,040 --> 00:16:38,160
making it so a lot of

519
00:16:38,160 --> 00:16:39,519
you know you asked this question on

520
00:16:39,519 --> 00:16:41,199
which high level language you use you

521
00:16:41,199 --> 00:16:42,560
know for this kind of uh

522
00:16:42,560 --> 00:16:45,920
work and you know we pick go

523
00:16:45,920 --> 00:16:48,800
and for a couple of reasons it is a

524
00:16:48,800 --> 00:16:50,639
statically compiled language so

525
00:16:50,639 --> 00:16:53,680
unlike python uh there's no interpreter

526
00:16:53,680 --> 00:16:56,160
uh and the reason that would like you

527
00:16:56,160 --> 00:16:57,519
know standard for compiled because that

528
00:16:57,519 --> 00:16:58,720
basically compiles actually high

529
00:16:58,720 --> 00:17:00,639
performance code in fact a particular go

530
00:17:00,639 --> 00:17:02,639
compiler is pretty good

531
00:17:02,639 --> 00:17:05,199
um so basically you know it's sort of a

532
00:17:05,199 --> 00:17:06,880
high performance language furthermore

533
00:17:06,880 --> 00:17:07,439
you know the go

534
00:17:07,439 --> 00:17:09,360
designer is actually intended for

535
00:17:09,360 --> 00:17:11,360
systems programming and you know kernels

536
00:17:11,360 --> 00:17:12,959
are foreign assistive programming so you

537
00:17:12,959 --> 00:17:14,559
know that needs a good match

538
00:17:14,559 --> 00:17:16,880
and so for example you know aspect that

539
00:17:16,880 --> 00:17:17,760
uh

540
00:17:17,760 --> 00:17:19,360
why it's so good for system programming

541
00:17:19,360 --> 00:17:21,199
it's actually easy to call assembly or

542
00:17:21,199 --> 00:17:22,880
other foreign code

543
00:17:22,880 --> 00:17:24,959
uh it has good support for concurrency

544
00:17:24,959 --> 00:17:26,640
you know quite flexible

545
00:17:26,640 --> 00:17:28,400
uh and then another reason that we

546
00:17:28,400 --> 00:17:29,520
wanted to use it because it has a

547
00:17:29,520 --> 00:17:31,520
garbage collector you know so like two

548
00:17:31,520 --> 00:17:32,480
you know one of the things that you

549
00:17:32,480 --> 00:17:33,679
think about a high-level language and

550
00:17:33,679 --> 00:17:34,960
one of the virtues of the high-level

551
00:17:34,960 --> 00:17:36,160
language is that you don't have to do

552
00:17:36,160 --> 00:17:37,360
memory management

553
00:17:37,360 --> 00:17:38,880
and then garbage collector is typically

554
00:17:38,880 --> 00:17:42,870
in a central role in the uh

555
00:17:42,880 --> 00:17:45,039
uh provides a central role in that sort

556
00:17:45,039 --> 00:17:47,120
of memory management story

557
00:17:47,120 --> 00:17:51,120
um by the time we started this paper

558
00:17:51,120 --> 00:17:54,240
uh or we started this project uh rust

559
00:17:54,240 --> 00:17:56,400
was not very popular the ross was

560
00:17:56,400 --> 00:17:57,840
actually not very stable and mature at

561
00:17:57,840 --> 00:17:59,039
that point then he actually could write

562
00:17:59,039 --> 00:17:59,600
a real

563
00:17:59,600 --> 00:18:02,960
kernel in it uh in retrospect no now

564
00:18:02,960 --> 00:18:04,400
you know you do it again you know you

565
00:18:04,400 --> 00:18:06,400
may would write it in rust

566
00:18:06,400 --> 00:18:08,240
because it's also designed for systems

567
00:18:08,240 --> 00:18:09,840
programming uh

568
00:18:09,840 --> 00:18:13,200
it has a small runtime it produces good

569
00:18:13,200 --> 00:18:14,000
code

570
00:18:14,000 --> 00:18:17,679
um although one thing that actually you

571
00:18:17,679 --> 00:18:18,960
know might may still make it very

572
00:18:18,960 --> 00:18:20,799
interesting to go for go is that

573
00:18:20,799 --> 00:18:23,120
uh rushers takes the starting assumption

574
00:18:23,120 --> 00:18:25,200
that uh

575
00:18:25,200 --> 00:18:26,559
that you know you wanna high perform

576
00:18:26,559 --> 00:18:28,480
systems programs then

577
00:18:28,480 --> 00:18:29,679
you can't do that with a garbage

578
00:18:29,679 --> 00:18:32,960
collector and in fact the

579
00:18:32,960 --> 00:18:34,799
rush type system is set up in a very

580
00:18:34,799 --> 00:18:37,120
clever way in a very interesting way

581
00:18:37,120 --> 00:18:38,559
so that actually a garbage collector is

582
00:18:38,559 --> 00:18:41,440
not necessary and in some ways we really

583
00:18:41,440 --> 00:18:42,080
were interested

584
00:18:42,080 --> 00:18:43,360
in just answering this question like

585
00:18:43,360 --> 00:18:45,039
what is the cost of guard collection in

586
00:18:45,039 --> 00:18:46,960
a high-level language you know on kernel

587
00:18:46,960 --> 00:18:47,840
programming

588
00:18:47,840 --> 00:18:51,360
and it's really impossible to use or

589
00:18:51,360 --> 00:18:53,280
what does that cost and in some ways you

590
00:18:53,280 --> 00:18:54,880
know sort of rush sidestep that question

591
00:18:54,880 --> 00:18:56,000
and just like you know

592
00:18:56,000 --> 00:18:57,039
use the language without garb's

593
00:18:57,039 --> 00:18:58,000
collection they have to don't think

594
00:18:58,000 --> 00:19:01,669
about this particular cost

595
00:19:01,679 --> 00:19:03,760
any questions about this in terms of the

596
00:19:03,760 --> 00:19:05,840
programming language

597
00:19:05,840 --> 00:19:10,480
we decided to use

598
00:19:10,480 --> 00:19:12,080
yeah there were lots of email questions

599
00:19:12,080 --> 00:19:14,720
related to this topic so

600
00:19:14,720 --> 00:19:16,640
this this is a theoretical question that

601
00:19:16,640 --> 00:19:17,919
maybe doesn't

602
00:19:17,919 --> 00:19:20,080
have an immediate answer but if the

603
00:19:20,080 --> 00:19:22,400
linux kernel were to be written

604
00:19:22,400 --> 00:19:25,840
and rust not go and like

605
00:19:25,840 --> 00:19:28,400
optimized in the same capacity would it

606
00:19:28,400 --> 00:19:29,919
be able to achieve

607
00:19:29,919 --> 00:19:34,559
higher performance then

608
00:19:34,559 --> 00:19:37,840
then the ground current then then c like

609
00:19:37,840 --> 00:19:39,520
a linux c kernel

610
00:19:39,520 --> 00:19:42,559
uh i doubt it would be a uh okay uh

611
00:19:42,559 --> 00:19:43,919
hard to know i'm just speculation

612
00:19:43,919 --> 00:19:45,039
correct because we haven't done this

613
00:19:45,039 --> 00:19:46,000
experiment

614
00:19:46,000 --> 00:19:48,559
uh my senses you know would be not

615
00:19:48,559 --> 00:19:50,480
higher performance than c

616
00:19:50,480 --> 00:19:52,240
uh but you know you know probably

617
00:19:52,240 --> 00:19:54,559
roughly in the same ballpark

618
00:19:54,559 --> 00:19:57,120
uh because i see so low level you can

619
00:19:57,120 --> 00:19:57,600
presume

620
00:19:57,600 --> 00:19:58,799
whatever you were doing rushed you could

621
00:19:58,799 --> 00:20:04,630
also have done this c uh

622
00:20:04,640 --> 00:20:11,029
does that make sense yes thank you

623
00:20:11,039 --> 00:20:15,520
okay um okay so let's uh move on them

624
00:20:15,520 --> 00:20:16,960
uh unless there are any other further

625
00:20:16,960 --> 00:20:18,559
questions about this and again you know

626
00:20:18,559 --> 00:20:20,320
feel free to interrupt and you know

627
00:20:20,320 --> 00:20:21,600
this is a bit of a discussion based

628
00:20:21,600 --> 00:20:23,919
lecture you know and so i would

629
00:20:23,919 --> 00:20:25,760
you know it was intended to sort of

630
00:20:25,760 --> 00:20:27,919
stimulate intellectual interest and so

631
00:20:27,919 --> 00:20:28,640
you know

632
00:20:28,640 --> 00:20:30,320
jump in if you have anything to think

633
00:20:30,320 --> 00:20:34,799
about this topic

634
00:20:34,799 --> 00:20:36,720
so actually before you know maybe a

635
00:20:36,720 --> 00:20:38,080
question i want to ask

636
00:20:38,080 --> 00:20:39,679
uh maybe i'll come back to that at the

637
00:20:39,679 --> 00:20:41,039
end of the lecture closer to the end of

638
00:20:41,039 --> 00:20:42,159
the lecture

639
00:20:42,159 --> 00:20:45,440
uh partly you know the whole

640
00:20:45,440 --> 00:20:47,120
uh reasoning we want to use high level

641
00:20:47,120 --> 00:20:48,640
language is to avoid a certain class of

642
00:20:48,640 --> 00:20:49,200
bugs

643
00:20:49,200 --> 00:20:51,520
and one question you should ask yourself

644
00:20:51,520 --> 00:20:52,559
were there bugs

645
00:20:52,559 --> 00:20:54,960
you know in the labs that you had that

646
00:20:54,960 --> 00:20:56,559
would have been avoided if you had a

647
00:20:56,559 --> 00:20:59,120
high level language

648
00:20:59,120 --> 00:21:01,280
you know so you know think back you know

649
00:21:01,280 --> 00:21:02,960
i'm sure you can come up with some

650
00:21:02,960 --> 00:21:04,480
bugs that you know you're costing a lot

651
00:21:04,480 --> 00:21:06,320
of time and a lot of pain

652
00:21:06,320 --> 00:21:08,400
uh and you could ask yourself for those

653
00:21:08,400 --> 00:21:09,600
kind of bugs you know

654
00:21:09,600 --> 00:21:13,039
if we if the xv6 were

655
00:21:13,039 --> 00:21:14,799
rewritten in the labs will be done in

656
00:21:14,799 --> 00:21:16,640
another high-level programming language

657
00:21:16,640 --> 00:21:18,000
would have life you know would you like

658
00:21:18,000 --> 00:21:18,960
me a lot easier

659
00:21:18,960 --> 00:21:20,720
you have a lot more spare time to do

660
00:21:20,720 --> 00:21:22,559
other things

661
00:21:22,559 --> 00:21:24,480
so let's keep that question in your head

662
00:21:24,480 --> 00:21:25,840
and you know

663
00:21:25,840 --> 00:21:27,200
we'll hopefully return to that at the

664
00:21:27,200 --> 00:21:29,360
end of the lecture but if you have

665
00:21:29,360 --> 00:21:32,320
opinions right away that's fine too

666
00:21:32,320 --> 00:21:34,320
okay uh so let me talk a little bit

667
00:21:34,320 --> 00:21:36,080
about biscuit um

668
00:21:36,080 --> 00:21:39,200
and uh you know how it sort of works

669
00:21:39,200 --> 00:21:40,960
uh and sort of the surprises where the

670
00:21:40,960 --> 00:21:42,240
things that we ran into

671
00:21:42,240 --> 00:21:43,600
while building biscuits you know things

672
00:21:43,600 --> 00:21:45,120
that we anticipated and some things that

673
00:21:45,120 --> 00:21:47,039
we actually did not anticipate

674
00:21:47,039 --> 00:21:50,159
um so the user programs you know there's

675
00:21:50,159 --> 00:21:51,600
a classic external

676
00:21:51,600 --> 00:21:53,280
uh monolithic kernel in the same way

677
00:21:53,280 --> 00:21:55,200
that linux or xv6 is

678
00:21:55,200 --> 00:21:56,799
and so there's user space and there's

679
00:21:56,799 --> 00:21:58,400
kernel space uh

680
00:21:58,400 --> 00:22:00,880
user space programs are uh you know

681
00:22:00,880 --> 00:22:02,400
whatever you know it's your compiler

682
00:22:02,400 --> 00:22:04,960
gcc or in our specific paper again it's

683
00:22:04,960 --> 00:22:06,559
mostly a web server

684
00:22:06,559 --> 00:22:09,600
and some other benchmarks uh

685
00:22:09,600 --> 00:22:11,840
and the user programs are actually all

686
00:22:11,840 --> 00:22:12,720
written in c

687
00:22:12,720 --> 00:22:14,080
although it could be principle in any

688
00:22:14,080 --> 00:22:15,440
language you know but since they are

689
00:22:15,440 --> 00:22:16,400
just a benchmark

690
00:22:16,400 --> 00:22:19,520
you know we took c versions and

691
00:22:19,520 --> 00:22:21,280
most of the programs are multi-threaded

692
00:22:21,280 --> 00:22:22,960
so unlike in

693
00:22:22,960 --> 00:22:25,200
xv6 where basically there's one fret per

694
00:22:25,200 --> 00:22:27,039
user program

695
00:22:27,039 --> 00:22:29,760
in biscuit actually you support multiple

696
00:22:29,760 --> 00:22:32,320
user level threads

697
00:22:32,320 --> 00:22:34,000
and for basically for every user level

698
00:22:34,000 --> 00:22:36,320
fret there's a corresponding kernel

699
00:22:36,320 --> 00:22:36,880
thread

700
00:22:36,880 --> 00:22:40,080
in the kernel and

701
00:22:40,080 --> 00:22:41,200
these kernel threads are actually

702
00:22:41,200 --> 00:22:43,120
implemented by go itself

703
00:22:43,120 --> 00:22:47,750
and go calls these go routines

704
00:22:47,760 --> 00:22:49,360
but you can think about go routines just

705
00:22:49,360 --> 00:22:51,280
as ordinary frets you know in the same

706
00:22:51,280 --> 00:22:53,280
way that xv6 has and the kernel

707
00:22:53,280 --> 00:22:57,430
has threads

708
00:22:57,440 --> 00:22:59,360
the go routines are sort of similar the

709
00:22:59,360 --> 00:23:01,039
main difference here correctly is that

710
00:23:01,039 --> 00:23:02,720
in xv6 you know the threads are

711
00:23:02,720 --> 00:23:04,480
implemented by the kernel itself

712
00:23:04,480 --> 00:23:06,480
and in this case you know the go runtime

713
00:23:06,480 --> 00:23:08,320
basically provides them so they go run

714
00:23:08,320 --> 00:23:09,679
time schedules them

715
00:23:09,679 --> 00:23:11,679
go run them have support for like things

716
00:23:11,679 --> 00:23:13,120
like sleep and wake up or condition

717
00:23:13,120 --> 00:23:14,320
variables they're slightly different

718
00:23:14,320 --> 00:23:15,600
asleep and wake up but there's some

719
00:23:15,600 --> 00:23:16,880
condition variable

720
00:23:16,880 --> 00:23:19,039
synchronization mechanism and there's a

721
00:23:19,039 --> 00:23:20,159
whole bunch of other you know things

722
00:23:20,159 --> 00:23:21,600
primitives in the go run them and just

723
00:23:21,600 --> 00:23:22,000
provide

724
00:23:22,000 --> 00:23:24,000
it by the go language itself and should

725
00:23:24,000 --> 00:23:25,520
have not be implemented you know by

726
00:23:25,520 --> 00:23:27,120
biscuit itself we just get them from the

727
00:23:27,120 --> 00:23:29,440
go runtime

728
00:23:29,440 --> 00:23:32,480
the go runtime itself runs directly on

729
00:23:32,480 --> 00:23:36,320
the bare hardware

730
00:23:36,320 --> 00:23:38,799
and i'll talk a little bit about that uh

731
00:23:38,799 --> 00:23:39,440
more

732
00:23:39,440 --> 00:23:41,840
in the lecture uh but like so you think

733
00:23:41,840 --> 00:23:43,279
about this as the machine boots you know

734
00:23:43,279 --> 00:23:44,480
the first thing it actually boots is the

735
00:23:44,480 --> 00:23:46,240
go runtime and

736
00:23:46,240 --> 00:23:47,279
that causes a little bit of

737
00:23:47,279 --> 00:23:48,880
complications because go runtime

738
00:23:48,880 --> 00:23:50,960
normally runs in user space as a user

739
00:23:50,960 --> 00:23:51,760
level program

740
00:23:51,760 --> 00:23:53,279
and assumes that the kernel there's a

741
00:23:53,279 --> 00:23:54,720
kernel there for where they can ask some

742
00:23:54,720 --> 00:23:56,080
services so for example it needs to

743
00:23:56,080 --> 00:23:57,600
allocate memory to

744
00:23:57,600 --> 00:24:00,480
uh for its heap uh and so there's a

745
00:24:00,480 --> 00:24:01,919
little bit of uh yeah so i'll talk a

746
00:24:01,919 --> 00:24:02,960
little bit about that there's a little

747
00:24:02,960 --> 00:24:04,400
bit of shim code

748
00:24:04,400 --> 00:24:06,720
that you know actually the biscuit has

749
00:24:06,720 --> 00:24:07,679
to basically

750
00:24:07,679 --> 00:24:09,600
trick you know the go runtime into

751
00:24:09,600 --> 00:24:11,200
believing that it runs on top of the

752
00:24:11,200 --> 00:24:12,240
operating system even though it's

753
00:24:12,240 --> 00:24:14,480
running on the br hardware and basically

754
00:24:14,480 --> 00:24:16,640
get it to boot

755
00:24:16,640 --> 00:24:18,480
and then the kernel itself you know it's

756
00:24:18,480 --> 00:24:20,720
a very similar you just think xv6

757
00:24:20,720 --> 00:24:22,480
i think there's a group model except you

758
00:24:22,480 --> 00:24:24,320
know it's a little bit more elaborate

759
00:24:24,320 --> 00:24:24,720
and

760
00:24:24,720 --> 00:24:26,000
more high performance and it has a

761
00:24:26,000 --> 00:24:27,520
vertical memory system you know for

762
00:24:27,520 --> 00:24:28,799
example implements map

763
00:24:28,799 --> 00:24:32,240
you know the know it has a laptop system

764
00:24:32,240 --> 00:24:33,520
except there's a more high performance

765
00:24:33,520 --> 00:24:36,240
file system it has a couple drivers you

766
00:24:36,240 --> 00:24:37,520
know it has a disk driver

767
00:24:37,520 --> 00:24:39,440
it has a network driver it has a network

768
00:24:39,440 --> 00:24:41,360
stack um

769
00:24:41,360 --> 00:24:42,960
so a little bit more complete and the

770
00:24:42,960 --> 00:24:44,559
way you can see that is

771
00:24:44,559 --> 00:24:46,960
it has like 58 system calls you know and

772
00:24:46,960 --> 00:24:48,480
like i don't know i can't remember how

773
00:24:48,480 --> 00:24:50,320
much xc6 has but certainly in the order

774
00:24:50,320 --> 00:24:52,799
of 1819 or something like that

775
00:24:52,799 --> 00:24:55,279
uh and the total number of lines of code

776
00:24:55,279 --> 00:24:59,200
is 28 000. and your xc6 is like not in

777
00:24:59,200 --> 00:25:01,440
i think below 10 000 so you know there's

778
00:25:01,440 --> 00:25:04,390
more features

779
00:25:04,400 --> 00:25:05,600
any questions about sort of this high

780
00:25:05,600 --> 00:25:08,390
level overview

781
00:25:08,400 --> 00:25:10,720
oh sorry i wanted to ask about the the

782
00:25:10,720 --> 00:25:11,520
interface

783
00:25:11,520 --> 00:25:14,400
so the interface is just like in xb6

784
00:25:14,400 --> 00:25:14,720
right

785
00:25:14,720 --> 00:25:18,080
so like the the process is they have to

786
00:25:18,080 --> 00:25:19,279
put something

787
00:25:19,279 --> 00:25:22,559
in some register and then they

788
00:25:22,559 --> 00:25:25,360
call the e call or whatever it is yeah

789
00:25:25,360 --> 00:25:26,720
yeah i'll talk a little bit more about

790
00:25:26,720 --> 00:25:28,159
this but it's exactly the same like

791
00:25:28,159 --> 00:25:29,440
there's no difference

792
00:25:29,440 --> 00:25:32,789
okay i see thank you

793
00:25:32,799 --> 00:25:34,480
uh so some of the features you know

794
00:25:34,480 --> 00:25:35,919
already mentioned them a little bit

795
00:25:35,919 --> 00:25:36,320
maybe

796
00:25:36,320 --> 00:25:39,760
more uh talking about so it's multi-core

797
00:25:39,760 --> 00:25:42,240
goal is good support for concurrency and

798
00:25:42,240 --> 00:25:44,240
so you know the biscuit is multi-core

799
00:25:44,240 --> 00:25:47,360
in the same way that uh xv6 sort of has

800
00:25:47,360 --> 00:25:49,279
at least limited support for multi-core

801
00:25:49,279 --> 00:25:50,880
uh in this could we have a little bit

802
00:25:50,880 --> 00:25:51,600
more fine

803
00:25:51,600 --> 00:25:53,440
grade synchronization or coordination

804
00:25:53,440 --> 00:25:55,360
than actually in xv6

805
00:25:55,360 --> 00:25:57,360
uh it has threads you know usual level

806
00:25:57,360 --> 00:25:59,279
threads uh

807
00:25:59,279 --> 00:26:02,240
backed up by uh kernel threads uh which

808
00:26:02,240 --> 00:26:03,679
xv6 doesn't have

809
00:26:03,679 --> 00:26:05,279
and there's a general file system a much

810
00:26:05,279 --> 00:26:06,720
higher performance you know i think you

811
00:26:06,720 --> 00:26:07,039
know

812
00:26:07,039 --> 00:26:09,840
you you're called the ext3 paper uh sort

813
00:26:09,840 --> 00:26:11,440
of like you know the hd free

814
00:26:11,440 --> 00:26:15,039
uh journaling file system uh it has you

815
00:26:15,039 --> 00:26:15,600
know quite

816
00:26:15,600 --> 00:26:16,640
you know reasonable sophisticated

817
00:26:16,640 --> 00:26:18,400
virtual memory system you know using

818
00:26:18,400 --> 00:26:19,360
vmas

819
00:26:19,360 --> 00:26:22,000
uh and you know you can support nmap and

820
00:26:22,000 --> 00:26:23,120
all that stuff

821
00:26:23,120 --> 00:26:25,360
it has a complete tcpa stack you know

822
00:26:25,360 --> 00:26:26,480
good enough to actually

823
00:26:26,480 --> 00:26:28,400
talk to other you know network servers

824
00:26:28,400 --> 00:26:31,120
across the internet and it has two

825
00:26:31,120 --> 00:26:33,360
drivers with high performance drivers so

826
00:26:33,360 --> 00:26:35,440
like a 10 gigabit nic

827
00:26:35,440 --> 00:26:36,799
in the next lap you're going to actually

828
00:26:36,799 --> 00:26:38,720
implement a little driver for a very

829
00:26:38,720 --> 00:26:39,679
very simple

830
00:26:39,679 --> 00:26:41,120
nic and this is a much more high

831
00:26:41,120 --> 00:26:43,679
performance and sophisticated driver

832
00:26:43,679 --> 00:26:45,360
and a pretty sophisticated disc driver

833
00:26:45,360 --> 00:26:47,200
you know more sophisticated than the

834
00:26:47,200 --> 00:26:47,919
virgil

835
00:26:47,919 --> 00:26:50,960
vert i o disk driver uh that you've

836
00:26:50,960 --> 00:26:55,360
sort of seen or you might have looked at

837
00:26:55,360 --> 00:27:00,549
in the labs um

838
00:27:00,559 --> 00:27:06,640
that's great

839
00:27:06,640 --> 00:27:10,320
uh so in terms of uh the user programs

840
00:27:10,320 --> 00:27:12,080
as i mentioned before every user program

841
00:27:12,080 --> 00:27:13,919
runs with its own page table

842
00:27:13,919 --> 00:27:16,400
uh user kernel memory is isolated by

843
00:27:16,400 --> 00:27:17,279
hardware so

844
00:27:17,279 --> 00:27:20,720
you you use your kernel bit basically

845
00:27:20,720 --> 00:27:24,480
and every user fret has a corresponding

846
00:27:24,480 --> 00:27:26,000
kernel thread so that for example when a

847
00:27:26,000 --> 00:27:27,760
user fret makes a system call

848
00:27:27,760 --> 00:27:30,000
it will continue running on the

849
00:27:30,000 --> 00:27:31,600
corresponding kernel thread

850
00:27:31,600 --> 00:27:33,120
and if the system call blocks then

851
00:27:33,120 --> 00:27:34,720
another user thread in the same address

852
00:27:34,720 --> 00:27:36,320
page and the user address space might

853
00:27:36,320 --> 00:27:39,279
actually be scheduled by the kernel

854
00:27:39,279 --> 00:27:40,720
and as i mentioned earlier kernel

855
00:27:40,720 --> 00:27:43,200
threads are provided by the go

856
00:27:43,200 --> 00:27:45,919
runtime and so they're just go routines

857
00:27:45,919 --> 00:27:47,360
so if you write ever

858
00:27:47,360 --> 00:27:49,120
uh usually have you ever written a user

859
00:27:49,120 --> 00:27:50,720
level application in uh

860
00:27:50,720 --> 00:27:53,200
go and you're using go and you use the

861
00:27:53,200 --> 00:27:54,960
go call to create a

862
00:27:54,960 --> 00:27:57,039
thread you know that those those go

863
00:27:57,039 --> 00:27:58,159
routines are the ones that were actually

864
00:27:58,159 --> 00:28:02,320
being used by the biscuit kernel

865
00:28:02,320 --> 00:28:04,000
so talking about system calls you know

866
00:28:04,000 --> 00:28:05,600
this question that uh

867
00:28:05,600 --> 00:28:09,279
was just asked um so it works exactly as

868
00:28:09,279 --> 00:28:12,320
roughly you know as in uh xv6 you know

869
00:28:12,320 --> 00:28:13,679
the use of red boots and arguments in

870
00:28:13,679 --> 00:28:14,880
the registers

871
00:28:14,880 --> 00:28:17,679
uh using a little uh library you know

872
00:28:17,679 --> 00:28:19,840
that provides a

873
00:28:19,840 --> 00:28:22,159
system called interface uh then the user

874
00:28:22,159 --> 00:28:23,919
threads execute the cis intercall

875
00:28:23,919 --> 00:28:26,880
you know this biscuit runs on an x86

876
00:28:26,880 --> 00:28:29,039
processor not on the wrist processor so

877
00:28:29,039 --> 00:28:30,480
the assembly instructions for

878
00:28:30,480 --> 00:28:32,240
actually entering their system kernel

879
00:28:32,240 --> 00:28:34,000
are slightly different than on the risk

880
00:28:34,000 --> 00:28:34,320
fi

881
00:28:34,320 --> 00:28:37,279
on the risk five uh but you know it's

882
00:28:37,279 --> 00:28:38,960
roughly similarly similar

883
00:28:38,960 --> 00:28:40,799
to the wrist bike and then the control

884
00:28:40,799 --> 00:28:42,159
passes through the

885
00:28:42,159 --> 00:28:44,559
kernel thread uh that's you know that

886
00:28:44,559 --> 00:28:46,240
was running that user thread

887
00:28:46,240 --> 00:28:48,000
and then the kernel thread executes the

888
00:28:48,000 --> 00:28:49,360
system call and then returns

889
00:28:49,360 --> 00:28:51,760
you're assuming his exit it's a roughly

890
00:28:51,760 --> 00:28:53,120
similar thing you know there's a track

891
00:28:53,120 --> 00:28:54,480
frame that's being built and all that

892
00:28:54,480 --> 00:29:00,870
kind of stuff okay

893
00:29:00,880 --> 00:29:03,840
any questions so far before i dive into

894
00:29:03,840 --> 00:29:04,159
sort of

895
00:29:04,159 --> 00:29:05,919
the more sort of you know things that

896
00:29:05,919 --> 00:29:08,559
were unexpected or expected but were a

897
00:29:08,559 --> 00:29:09,760
little bit more challenging than

898
00:29:09,760 --> 00:29:12,240
or different than i think would go than

899
00:29:12,240 --> 00:29:13,760
in xv6

900
00:29:13,760 --> 00:29:16,880
i have a question um i guess

901
00:29:16,880 --> 00:29:20,640
i think um go wants you to use

902
00:29:20,640 --> 00:29:24,159
channels more than uh mutual

903
00:29:24,159 --> 00:29:27,120
locks i guess so would you like would

904
00:29:27,120 --> 00:29:28,880
there be like

905
00:29:28,880 --> 00:29:31,279
will the design of some things in xv6 be

906
00:29:31,279 --> 00:29:32,799
like could use as

907
00:29:32,799 --> 00:29:34,640
channels instead of holding a lock for

908
00:29:34,640 --> 00:29:36,480
something yeah so

909
00:29:36,480 --> 00:29:38,399
this is great uh great question so we

910
00:29:38,399 --> 00:29:40,159
i'll come back to it a little bit at the

911
00:29:40,159 --> 00:29:40,559
end

912
00:29:40,559 --> 00:29:42,960
uh further down and uh we have some

913
00:29:42,960 --> 00:29:44,480
slides about like what features of go

914
00:29:44,480 --> 00:29:45,200
did we use

915
00:29:45,200 --> 00:29:48,480
in this kit uh but you know the

916
00:29:48,480 --> 00:29:50,080
in the index we didn't end up using

917
00:29:50,080 --> 00:29:52,240
channels that much uh we mostly used

918
00:29:52,240 --> 00:29:54,640
locks and condition variables so in some

919
00:29:54,640 --> 00:29:56,880
sense closer to like the way xc6 looks

920
00:29:56,880 --> 00:29:59,520
then actually uh you won you would then

921
00:29:59,520 --> 00:30:00,720
you would do it with channels

922
00:30:00,720 --> 00:30:02,720
we did experiment actually with designs

923
00:30:02,720 --> 00:30:05,279
of the file system that were much more

924
00:30:05,279 --> 00:30:08,480
channel heavy and but it didn't work out

925
00:30:08,480 --> 00:30:09,279
that great

926
00:30:09,279 --> 00:30:11,360
we got bad performance and so yeah we

927
00:30:11,360 --> 00:30:12,880
switched back to sort of more

928
00:30:12,880 --> 00:30:14,720
uh you know similar style of

929
00:30:14,720 --> 00:30:16,720
synchronization as xv6 does

930
00:30:16,720 --> 00:30:20,470
or linux uses

931
00:30:20,480 --> 00:30:23,360
um okay so there were a couple sort of

932
00:30:23,360 --> 00:30:24,640
uh little puzzles

933
00:30:24,640 --> 00:30:27,120
or implementation challenges uh as we

934
00:30:27,120 --> 00:30:28,000
went through

935
00:30:28,000 --> 00:30:30,640
uh one uh we got to get the runtime to

936
00:30:30,640 --> 00:30:31,840
work on the bare metal

937
00:30:31,840 --> 00:30:34,320
and you know the required we wanted to

938
00:30:34,320 --> 00:30:35,919
make of course like zero modifications

939
00:30:35,919 --> 00:30:37,919
to the runtime or as little as possible

940
00:30:37,919 --> 00:30:38,799
so that you know

941
00:30:38,799 --> 00:30:40,320
go come out with a new version of the

942
00:30:40,320 --> 00:30:42,080
runtime we could just use it

943
00:30:42,080 --> 00:30:44,720
and in fact you know through the uh

944
00:30:44,720 --> 00:30:46,080
years you know that we

945
00:30:46,080 --> 00:30:47,520
worked on this where the coding worked

946
00:30:47,520 --> 00:30:50,000
on this we upgraded the runtime many you

947
00:30:50,000 --> 00:30:50,559
know a

948
00:30:50,559 --> 00:30:53,120
number of times uh and that was turned

949
00:30:53,120 --> 00:30:54,799
out to be a good thing and it turned out

950
00:30:54,799 --> 00:30:56,480
not to be too difficult actually to get

951
00:30:56,480 --> 00:30:58,240
it to work on the bare metal

952
00:30:58,240 --> 00:31:01,360
uh you know go in general is designed uh

953
00:31:01,360 --> 00:31:04,159
pretty carefully to sort of be mostly os

954
00:31:04,159 --> 00:31:05,600
agnostic because they want to be able to

955
00:31:05,600 --> 00:31:05,919
run

956
00:31:05,919 --> 00:31:07,360
the mini operating system so it doesn't

957
00:31:07,360 --> 00:31:10,000
rely on a ton of os features

958
00:31:10,000 --> 00:31:11,760
and we basically emulated the features

959
00:31:11,760 --> 00:31:13,679
that actually needed it

960
00:31:13,679 --> 00:31:15,120
and mostly you know those are the

961
00:31:15,120 --> 00:31:16,640
features that actually just get off the

962
00:31:16,640 --> 00:31:17,200
for

963
00:31:17,200 --> 00:31:19,200
go run them to get started and once it

964
00:31:19,200 --> 00:31:21,919
started it runs just happily

965
00:31:21,919 --> 00:31:25,590
um

966
00:31:25,600 --> 00:31:26,880
we have to sort of arrange the go

967
00:31:26,880 --> 00:31:28,559
routine run different applications you

968
00:31:28,559 --> 00:31:28,880
know

969
00:31:28,880 --> 00:31:32,080
normally in go program correct

970
00:31:32,080 --> 00:31:34,399
uh there's all one single application

971
00:31:34,399 --> 00:31:36,240
and here now we're using go routines to

972
00:31:36,240 --> 00:31:38,480
actually run different user uh

973
00:31:38,480 --> 00:31:41,600
uh different user applications uh and

974
00:31:41,600 --> 00:31:43,360
uh but you know these user applications

975
00:31:43,360 --> 00:31:45,440
have to run with different page tables

976
00:31:45,440 --> 00:31:46,320
uh

977
00:31:46,320 --> 00:31:48,880
and the little you know wrinkle here is

978
00:31:48,880 --> 00:31:49,840
that you know the

979
00:31:49,840 --> 00:31:51,840
we don't control or basically doesn't

980
00:31:51,840 --> 00:31:53,600
control the scheduler because we're

981
00:31:53,600 --> 00:31:54,480
using the go

982
00:31:54,480 --> 00:31:56,399
runtime unmodified so we're using the go

983
00:31:56,399 --> 00:31:57,519
runtime scheduler

984
00:31:57,519 --> 00:31:59,120
and so in the scheduler we can't switch

985
00:31:59,120 --> 00:32:01,039
page tables

986
00:32:01,039 --> 00:32:02,960
and so what the xv6 is actually

987
00:32:02,960 --> 00:32:04,640
basically what the biscuit does is very

988
00:32:04,640 --> 00:32:05,840
similar to xv6

989
00:32:05,840 --> 00:32:07,840
it actually switches heat stables or

990
00:32:07,840 --> 00:32:09,440
when it changes from current to user

991
00:32:09,440 --> 00:32:10,000
space

992
00:32:10,000 --> 00:32:13,679
or the other way around so when an

993
00:32:13,679 --> 00:32:15,679
entry and exit of the kernel you know we

994
00:32:15,679 --> 00:32:17,120
switch page tables

995
00:32:17,120 --> 00:32:19,600
and that means like in x36 and then when

996
00:32:19,600 --> 00:32:21,120
you need to copy

997
00:32:21,120 --> 00:32:23,039
data from user space to kernel space or

998
00:32:23,039 --> 00:32:24,960
the other way around you have to do that

999
00:32:24,960 --> 00:32:26,960
sort of using those copy in and copy out

1000
00:32:26,960 --> 00:32:28,720
functions that we also have in xv6 so

1001
00:32:28,720 --> 00:32:30,320
basically you do the page table walking

1002
00:32:30,320 --> 00:32:33,830
software

1003
00:32:33,840 --> 00:32:36,320
another sort of challenge or little

1004
00:32:36,320 --> 00:32:38,880
challenge was the device interrupts

1005
00:32:38,880 --> 00:32:41,200
not go run normally runs in user mode

1006
00:32:41,200 --> 00:32:43,200
you know doesn't really get interrupts

1007
00:32:43,200 --> 00:32:46,080
right from the hardware but we're using

1008
00:32:46,080 --> 00:32:46,880
it on the bare

1009
00:32:46,880 --> 00:32:48,399
metal and so we're going to get

1010
00:32:48,399 --> 00:32:50,480
interrupts time clock interrupts uh

1011
00:32:50,480 --> 00:32:51,679
interruption the network driver

1012
00:32:51,679 --> 00:32:54,000
interruption the disk driver etc

1013
00:32:54,000 --> 00:32:57,200
you know from the uart um and so we need

1014
00:32:57,200 --> 00:32:57,440
to

1015
00:32:57,440 --> 00:33:00,640
deal with that and uh and there's also

1016
00:33:00,640 --> 00:33:01,360
no notion

1017
00:33:01,360 --> 00:33:03,279
and go you know for you know switching

1018
00:33:03,279 --> 00:33:05,360
off interrupts like while holding a lock

1019
00:33:05,360 --> 00:33:06,880
you know that because it just doesn't

1020
00:33:06,880 --> 00:33:08,720
show up in user applications

1021
00:33:08,720 --> 00:33:09,840
and so we have to be a little bit

1022
00:33:09,840 --> 00:33:11,919
careful with how to actually write uh

1023
00:33:11,919 --> 00:33:15,440
device interrupt and basically the way

1024
00:33:15,440 --> 00:33:16,320
we did it is

1025
00:33:16,320 --> 00:33:17,919
we do almost nothing in the device

1026
00:33:17,919 --> 00:33:20,159
interrupt we don't take any locks out

1027
00:33:20,159 --> 00:33:22,799
basically we don't allocate any memory

1028
00:33:22,799 --> 00:33:24,559
uh the only thing we do is basically

1029
00:33:24,559 --> 00:33:26,640
sending a flag somewhere that wasn't

1030
00:33:26,640 --> 00:33:28,399
interrupt and then wake up

1031
00:33:28,399 --> 00:33:30,559
a really functional go routine to

1032
00:33:30,559 --> 00:33:34,870
actually deal with the interrupt

1033
00:33:34,880 --> 00:33:36,320
and that go routine of course you know

1034
00:33:36,320 --> 00:33:37,760
can use all the go features that it

1035
00:33:37,760 --> 00:33:39,120
wants

1036
00:33:39,120 --> 00:33:40,720
because it doesn't run in the context of

1037
00:33:40,720 --> 00:33:42,320
an interrupt handler just it runs in the

1038
00:33:42,320 --> 00:33:45,360
context of a normal normal go routine

1039
00:33:45,360 --> 00:33:47,600
then one thing that surprises uh it was

1040
00:33:47,600 --> 00:33:48,720
a bit more of a surprise

1041
00:33:48,720 --> 00:33:50,399
you know the first three things we

1042
00:33:50,399 --> 00:33:51,840
completely anticipated that we would

1043
00:33:51,840 --> 00:33:53,519
have to deal with when uh

1044
00:33:53,519 --> 00:33:55,039
building biscuit the hardest one that

1045
00:33:55,039 --> 00:33:56,559
actually hadn't

1046
00:33:56,559 --> 00:33:59,360
surprised us um and we learned a lot

1047
00:33:59,360 --> 00:33:59,840
about

1048
00:33:59,840 --> 00:34:01,519
it was this puzzle of the heap

1049
00:34:01,519 --> 00:34:03,919
exhaustion so i'm going to talk mostly

1050
00:34:03,919 --> 00:34:05,519
for a little while about heat exhaustion

1051
00:34:05,519 --> 00:34:07,039
and you know what it is you know how it

1052
00:34:07,039 --> 00:34:07,679
comes about

1053
00:34:07,679 --> 00:34:09,440
and you know how we solved it but maybe

1054
00:34:09,440 --> 00:34:10,960
before diving into that

1055
00:34:10,960 --> 00:34:18,950
you know any any questions so far

1056
00:34:18,960 --> 00:34:24,470
so crystal clear

1057
00:34:24,480 --> 00:34:25,919
okay so let's talk a little bit about

1058
00:34:25,919 --> 00:34:27,200
the heat exhaustion i'm not going to go

1059
00:34:27,200 --> 00:34:28,800
with full depth as in the paper but

1060
00:34:28,800 --> 00:34:30,240
at least to give you the flavor of like

1061
00:34:30,240 --> 00:34:32,839
what the problem is

1062
00:34:32,839 --> 00:34:40,869
um yeah

1063
00:34:40,879 --> 00:34:43,280
so in the heap exhaustion uh you know

1064
00:34:43,280 --> 00:34:44,240
let's say you

1065
00:34:44,240 --> 00:34:49,440
the blue box here is the kernel again

1066
00:34:49,440 --> 00:34:51,919
and you know the kernel has a heap uh

1067
00:34:51,919 --> 00:34:53,440
from which it allocates dynamically

1068
00:34:53,440 --> 00:34:54,079
memory

1069
00:34:54,079 --> 00:34:56,320
uh in xc6 we don't have such a heap

1070
00:34:56,320 --> 00:34:57,839
because we don't have a memory allocator

1071
00:34:57,839 --> 00:34:59,599
in the kernel every statically allocated

1072
00:34:59,599 --> 00:35:01,040
but the any other kernel

1073
00:35:01,040 --> 00:35:02,480
will have a heap so that you know you

1074
00:35:02,480 --> 00:35:04,400
can call malloc

1075
00:35:04,400 --> 00:35:08,079
you know m3 in the kernel

1076
00:35:08,079 --> 00:35:09,280
and you know the things that actually

1077
00:35:09,280 --> 00:35:10,800
get allocated on the heap are for

1078
00:35:10,800 --> 00:35:11,760
example

1079
00:35:11,760 --> 00:35:14,480
uh you know socket objects or file

1080
00:35:14,480 --> 00:35:16,160
descriptor objects or

1081
00:35:16,160 --> 00:35:18,160
process objects like you know struck

1082
00:35:18,160 --> 00:35:19,760
proc you know struct fd

1083
00:35:19,760 --> 00:35:20,960
all the structures that we basically

1084
00:35:20,960 --> 00:35:22,800
statically allocate and actually occur

1085
00:35:22,800 --> 00:35:25,200
xv6 normal kernels they dynamically

1086
00:35:25,200 --> 00:35:26,160
allocate them

1087
00:35:26,160 --> 00:35:28,000
so when you open the new file descriptor

1088
00:35:28,000 --> 00:35:29,599
it will be a file descriptor object you

1089
00:35:29,599 --> 00:35:32,160
know allocated in the heap

1090
00:35:32,160 --> 00:35:34,079
and so then the problem is like you know

1091
00:35:34,079 --> 00:35:35,520
if you're running many applications you

1092
00:35:35,520 --> 00:35:36,640
know they might open many file

1093
00:35:36,640 --> 00:35:38,720
descriptors maybe you have mini sockets

1094
00:35:38,720 --> 00:35:40,320
and they sort of start filling the heap

1095
00:35:40,320 --> 00:35:42,560
basically slowly and so

1096
00:35:42,560 --> 00:35:44,400
and then the issue is that at some point

1097
00:35:44,400 --> 00:35:46,000
like the heap is full you know there's

1098
00:35:46,000 --> 00:35:46,800
no

1099
00:35:46,800 --> 00:35:48,960
space anymore for allocating a new

1100
00:35:48,960 --> 00:35:50,560
object so when an

1101
00:35:50,560 --> 00:35:52,320
application asks for example opens new

1102
00:35:52,320 --> 00:35:54,079
file descriptor and there's like no

1103
00:35:54,079 --> 00:35:55,760
you know a new processor like this new

1104
00:35:55,760 --> 00:35:57,760
fork and the kernel wants to allocate

1105
00:35:57,760 --> 00:35:58,560
his truck proc

1106
00:35:58,560 --> 00:36:00,240
in the heap he's like there's no space

1107
00:36:00,240 --> 00:36:01,680
anymore

1108
00:36:01,680 --> 00:36:04,079
um and what do you do then you know what

1109
00:36:04,079 --> 00:36:04,960
is the

1110
00:36:04,960 --> 00:36:07,280
uh you know how do you deal with that

1111
00:36:07,280 --> 00:36:08,720
particular case

1112
00:36:08,720 --> 00:36:10,240
and this is typically you know this is

1113
00:36:10,240 --> 00:36:12,000
you know maybe in common cases doesn't

1114
00:36:12,000 --> 00:36:12,320
show

1115
00:36:12,320 --> 00:36:14,640
up that often uh but like if you're

1116
00:36:14,640 --> 00:36:16,400
pushing machine hard you may have you

1117
00:36:16,400 --> 00:36:18,000
know a couple heavy consumer processes

1118
00:36:18,000 --> 00:36:19,760
around user level processes you might

1119
00:36:19,760 --> 00:36:21,599
end in this situation where basically

1120
00:36:21,599 --> 00:36:23,040
you know all the available memory is

1121
00:36:23,040 --> 00:36:24,800
just in use and

1122
00:36:24,800 --> 00:36:28,240
uh your heat is just full and no process

1123
00:36:28,240 --> 00:36:29,200
is calling me

1124
00:36:29,200 --> 00:36:30,720
free yet you know because they're all

1125
00:36:30,720 --> 00:36:32,240
running and trying to allocate more

1126
00:36:32,240 --> 00:36:33,920
you know resources for their for their

1127
00:36:33,920 --> 00:36:40,240
particular jobs

1128
00:36:40,240 --> 00:36:41,920
and so all kernels face this problem

1129
00:36:41,920 --> 00:36:43,200
whether it's like a c kernel or a

1130
00:36:43,200 --> 00:36:43,760
biscuit

1131
00:36:43,760 --> 00:36:46,400
or uh anything and any kernel must solve

1132
00:36:46,400 --> 00:36:48,160
this particular problem

1133
00:36:48,160 --> 00:36:50,079
uh the reason they they sort of showed

1134
00:36:50,079 --> 00:36:52,880
up for us as a serious issue in

1135
00:36:52,880 --> 00:36:56,160
uh biscuit was because

1136
00:36:56,160 --> 00:36:58,340
in many kernels the

1137
00:36:58,340 --> 00:37:01,200
[Music]

1138
00:37:01,200 --> 00:37:03,520
you could return an error on a malloc

1139
00:37:03,520 --> 00:37:05,599
and in fact xv6 does that correct once

1140
00:37:05,599 --> 00:37:07,040
in a while but you know in

1141
00:37:07,040 --> 00:37:09,359
the go runtime when you call new to

1142
00:37:09,359 --> 00:37:10,320
allocate a go

1143
00:37:10,320 --> 00:37:12,960
object there's no air condition you know

1144
00:37:12,960 --> 00:37:14,320
new succeeds

1145
00:37:14,320 --> 00:37:17,520
uh and so there's no way to fail it so

1146
00:37:17,520 --> 00:37:18,720
let's talk a little bit about you know

1147
00:37:18,720 --> 00:37:21,280
possible ways to solve this problem

1148
00:37:21,280 --> 00:37:24,640
um the you know

1149
00:37:24,640 --> 00:37:26,240
we've seen it actually in xv6 once in a

1150
00:37:26,240 --> 00:37:27,839
while like if you remember

1151
00:37:27,839 --> 00:37:31,359
the b cache uh if you know x36 can't

1152
00:37:31,359 --> 00:37:32,240
find

1153
00:37:32,240 --> 00:37:35,599
uh a new block you know to free block to

1154
00:37:35,599 --> 00:37:37,920
use you know for storing a disc block in

1155
00:37:37,920 --> 00:37:40,160
and actually sometimes just panics uh

1156
00:37:40,160 --> 00:37:41,599
now this clearly is a

1157
00:37:41,599 --> 00:37:44,800
completely undesirable uh solution

1158
00:37:44,800 --> 00:37:46,560
and it's not a real solution so here's

1159
00:37:46,560 --> 00:37:48,960
like why we call it astronomy solution

1160
00:37:48,960 --> 00:37:51,200
uh the other sort of straw main solution

1161
00:37:51,200 --> 00:37:52,160
is to

1162
00:37:52,160 --> 00:37:54,640
uh when you call let's say you allocate

1163
00:37:54,640 --> 00:37:55,599
a new piece of memory

1164
00:37:55,599 --> 00:37:58,240
you know you can go to call alec or new

1165
00:37:58,240 --> 00:37:59,680
to actually allocate it

1166
00:37:59,680 --> 00:38:01,040
you could actually you know wait for

1167
00:38:01,040 --> 00:38:03,200
memory in the allocator i'm gonna

1168
00:38:03,200 --> 00:38:04,880
be one proposal to do it it turns out

1169
00:38:04,880 --> 00:38:06,560
not to be a good proposal

1170
00:38:06,560 --> 00:38:08,640
uh and and the reason it's not a good

1171
00:38:08,640 --> 00:38:10,480
proposal is that you may deadlock you

1172
00:38:10,480 --> 00:38:11,359
know

1173
00:38:11,359 --> 00:38:12,880
assume the following scenario you're

1174
00:38:12,880 --> 00:38:14,320
holding some let's say the kernel has

1175
00:38:14,320 --> 00:38:15,920
one big kernel lock

1176
00:38:15,920 --> 00:38:18,400
uh and you call malloc you know you wait

1177
00:38:18,400 --> 00:38:19,520
into the

1178
00:38:19,520 --> 00:38:21,760
memory allocator then basically no other

1179
00:38:21,760 --> 00:38:23,440
other process can run

1180
00:38:23,440 --> 00:38:25,200
uh and you would have a sort of deadlock

1181
00:38:25,200 --> 00:38:26,480
type now and your next process that

1182
00:38:26,480 --> 00:38:28,240
would actually try to run for example to

1183
00:38:28,240 --> 00:38:29,359
freeze some memory

1184
00:38:29,359 --> 00:38:31,119
uh you know couldn't run the next good

1185
00:38:31,119 --> 00:38:33,280
deadlock and of course this is if you

1186
00:38:33,280 --> 00:38:33,599
have a

1187
00:38:33,599 --> 00:38:35,200
kernel or a big kernel lock that is an

1188
00:38:35,200 --> 00:38:36,880
obvious problem you know but even if you

1189
00:38:36,880 --> 00:38:37,839
have a very

1190
00:38:37,839 --> 00:38:40,560
small uh you know fine-grained locking

1191
00:38:40,560 --> 00:38:42,240
is easy to run in a situation where

1192
00:38:42,240 --> 00:38:43,119
basically

1193
00:38:43,119 --> 00:38:45,200
the person or the process that's waiting

1194
00:38:45,200 --> 00:38:46,800
in the allocator

1195
00:38:46,800 --> 00:38:48,640
is holding some lock that somebody else

1196
00:38:48,640 --> 00:38:51,040
needs to actually free the memory

1197
00:38:51,040 --> 00:38:52,320
and that can get you basically in this

1198
00:38:52,320 --> 00:38:54,640
deadlock situation

1199
00:38:54,640 --> 00:38:58,160
um and so again strongman 3

1200
00:38:58,160 --> 00:39:01,920
is to basically fail uh or when you're

1201
00:39:01,920 --> 00:39:03,760
uh there's no memory anymore alec just

1202
00:39:03,760 --> 00:39:05,119
returns like a null pointer

1203
00:39:05,119 --> 00:39:06,880
you check with the null pointer it's no

1204
00:39:06,880 --> 00:39:09,760
point do you fail and use your bailout

1205
00:39:09,760 --> 00:39:12,160
uh but bailing out is actually not that

1206
00:39:12,160 --> 00:39:14,000
sort of straightforward uh

1207
00:39:14,000 --> 00:39:15,680
you know the process might actually have

1208
00:39:15,680 --> 00:39:17,599
allocated memory uh already

1209
00:39:17,599 --> 00:39:19,680
uh you need to get rid of that uh you

1210
00:39:19,680 --> 00:39:21,280
may have done some partial disk

1211
00:39:21,280 --> 00:39:22,720
operations like for example if you do a

1212
00:39:22,720 --> 00:39:24,000
multi-step you know file system

1213
00:39:24,000 --> 00:39:25,359
operation maybe you have done some of it

1214
00:39:25,359 --> 00:39:26,880
but not all of it you have to bail out

1215
00:39:26,880 --> 00:39:28,079
of that uh

1216
00:39:28,079 --> 00:39:30,400
and so it turns out to actually get very

1217
00:39:30,400 --> 00:39:32,320
it's very hard to get right

1218
00:39:32,320 --> 00:39:35,680
um and sort of interesting uh

1219
00:39:35,680 --> 00:39:38,079
you know when digging into this uh and

1220
00:39:38,079 --> 00:39:39,280
trying to think about like how to solve

1221
00:39:39,280 --> 00:39:40,000
this problem

1222
00:39:40,000 --> 00:39:41,680
you know linda sort of uses you know

1223
00:39:41,680 --> 00:39:43,440
both of these solutions

1224
00:39:43,440 --> 00:39:46,079
um and you know both actually have uh

1225
00:39:46,079 --> 00:39:47,680
trouble or problems

1226
00:39:47,680 --> 00:39:50,160
and indeed you know kernel developers

1227
00:39:50,160 --> 00:39:51,680
actually have difficulty to actually get

1228
00:39:51,680 --> 00:39:53,520
this all straight if you're very

1229
00:39:53,520 --> 00:39:54,960
interested in this and we want to see

1230
00:39:54,960 --> 00:39:56,720
some interesting discussion about this

1231
00:39:56,720 --> 00:39:59,359
uh google for too small to fail uh and

1232
00:39:59,359 --> 00:40:00,560
then you know there's a little article

1233
00:40:00,560 --> 00:40:00,880
that

1234
00:40:00,880 --> 00:40:02,560
talks about some of these complications

1235
00:40:02,560 --> 00:40:03,920
you know uh of

1236
00:40:03,920 --> 00:40:05,440
freeing memory or waiting in the

1237
00:40:05,440 --> 00:40:06,960
allocator uh

1238
00:40:06,960 --> 00:40:10,640
and uh the problem that can cause

1239
00:40:10,640 --> 00:40:13,440
now it turns out uh for us you know so

1240
00:40:13,440 --> 00:40:14,640
strongman 2 would be sort of the

1241
00:40:14,640 --> 00:40:16,000
solution that you could imagine doing

1242
00:40:16,000 --> 00:40:17,359
but then for us to just as mentioned

1243
00:40:17,359 --> 00:40:18,160
earlier

1244
00:40:18,160 --> 00:40:20,640
for biscuit was not possible because new

1245
00:40:20,640 --> 00:40:22,160
just cannot return

1246
00:40:22,160 --> 00:40:24,560
cannot fail it just always succeeds so

1247
00:40:24,560 --> 00:40:26,240
we got to range in some way that just

1248
00:40:26,240 --> 00:40:29,599
this cannot happen uh plus

1249
00:40:29,599 --> 00:40:30,800
neither of these two solutions actually

1250
00:40:30,800 --> 00:40:32,480
particularly ideal so we wanted to come

1251
00:40:32,480 --> 00:40:33,200
up with something

1252
00:40:33,200 --> 00:40:36,560
that was potentially better

1253
00:40:36,560 --> 00:40:39,040
any questions so far about the setup uh

1254
00:40:39,040 --> 00:40:40,800
around heap exhaustion before i talk

1255
00:40:40,800 --> 00:40:41,520
about like i said

1256
00:40:41,520 --> 00:40:48,230
how the way biscuit does it

1257
00:40:48,240 --> 00:40:58,710
does this problem make sense

1258
00:40:58,720 --> 00:41:01,280
i will interpret the signings as yes and

1259
00:41:01,280 --> 00:41:02,319
then keep going but

1260
00:41:02,319 --> 00:41:06,720
if you figure to interrupt any time

1261
00:41:06,720 --> 00:41:09,599
okay so what is the biscuit solution um

1262
00:41:09,599 --> 00:41:10,640
you know

1263
00:41:10,640 --> 00:41:12,319
at a high level the biscuit solution is

1264
00:41:12,319 --> 00:41:14,480
like almost straightforward

1265
00:41:14,480 --> 00:41:16,319
uh but biscuit does like when you

1266
00:41:16,319 --> 00:41:17,680
execute a system called like say

1267
00:41:17,680 --> 00:41:21,040
read or fork uh

1268
00:41:21,040 --> 00:41:23,119
before jumping actually into the forex

1269
00:41:23,119 --> 00:41:24,640
system call like right at the beginning

1270
00:41:24,640 --> 00:41:26,319
of the fork system call if you feel like

1271
00:41:26,319 --> 00:41:28,079
in the system called dispatcher

1272
00:41:28,079 --> 00:41:30,400
in xv6 then first thing it does actually

1273
00:41:30,400 --> 00:41:32,560
it calls reserve

1274
00:41:32,560 --> 00:41:35,200
and it basically reserves enough memory

1275
00:41:35,200 --> 00:41:35,680
uh

1276
00:41:35,680 --> 00:41:38,560
to be able to execute the system call uh

1277
00:41:38,560 --> 00:41:40,400
so there's reserves free memory

1278
00:41:40,400 --> 00:41:43,040
uh in enough that that connects in

1279
00:41:43,040 --> 00:41:44,560
whatever amount of memory that actually

1280
00:41:44,560 --> 00:41:45,839
the system call needs

1281
00:41:45,839 --> 00:41:47,839
uh the reservation will be big enough

1282
00:41:47,839 --> 00:41:50,400
that actually it will succeed

1283
00:41:50,400 --> 00:41:53,200
so so once the system call goes off and

1284
00:41:53,200 --> 00:41:55,200
actually successfully reserving memory

1285
00:41:55,200 --> 00:41:56,800
uh it will actually run all the way

1286
00:41:56,800 --> 00:41:58,640
through and we will never with the

1287
00:41:58,640 --> 00:42:00,319
problem that there won't be enough uh

1288
00:42:00,319 --> 00:42:03,200
memory or a heap exhaustion

1289
00:42:03,200 --> 00:42:05,280
and if there's not enough memory at the

1290
00:42:05,280 --> 00:42:06,880
point you want to do the recitation then

1291
00:42:06,880 --> 00:42:09,839
basically it just waits here

1292
00:42:09,839 --> 00:42:11,520
uh but at the beginning of the system

1293
00:42:11,520 --> 00:42:13,119
call the system call doesn't hold any

1294
00:42:13,119 --> 00:42:14,880
locks it doesn't hold any resources yet

1295
00:42:14,880 --> 00:42:16,319
so it actually is perfectly fine

1296
00:42:16,319 --> 00:42:18,640
you know it waits there so there's no no

1297
00:42:18,640 --> 00:42:19,440
risk of

1298
00:42:19,440 --> 00:42:22,640
uh deadlock and

1299
00:42:22,640 --> 00:42:24,319
while it's waiting you know it can of

1300
00:42:24,319 --> 00:42:26,480
course you know doing it it can call

1301
00:42:26,480 --> 00:42:29,119
uh the kernel can actually uh evict

1302
00:42:29,119 --> 00:42:30,160
caches you know

1303
00:42:30,160 --> 00:42:32,079
to try to reduce the uh basically make

1304
00:42:32,079 --> 00:42:33,839
free of hip space

1305
00:42:33,839 --> 00:42:36,800
maybe uh as you know you've seen that

1306
00:42:36,800 --> 00:42:37,599
maybe kill

1307
00:42:37,599 --> 00:42:39,839
a process that to force you know memory

1308
00:42:39,839 --> 00:42:41,520
to actually be freed

1309
00:42:41,520 --> 00:42:43,440
um and then once you know memory is

1310
00:42:43,440 --> 00:42:44,880
available and the kernel decides well

1311
00:42:44,880 --> 00:42:45,839
you know i can

1312
00:42:45,839 --> 00:42:47,920
meet the reservation then it will let

1313
00:42:47,920 --> 00:42:49,520
the system call basically goes off and

1314
00:42:49,520 --> 00:42:50,079
runs

1315
00:42:50,079 --> 00:42:51,760
and basically executes you know whatever

1316
00:42:51,760 --> 00:42:53,599
needs to be done and then at the very

1317
00:42:53,599 --> 00:42:54,880
end you know when the system calls down

1318
00:42:54,880 --> 00:42:56,240
it's just like okay i'm done

1319
00:42:56,240 --> 00:42:57,680
and all the memory that was reserved

1320
00:42:57,680 --> 00:42:59,520
basically goes back to the pool

1321
00:42:59,520 --> 00:43:03,599
uh available for subsequent system calls

1322
00:43:03,599 --> 00:43:05,680
and so there's a couple nice properties

1323
00:43:05,680 --> 00:43:07,280
about this particular solutions

1324
00:43:07,280 --> 00:43:09,040
uh there's no checks necessary in the

1325
00:43:09,040 --> 00:43:10,880
kernel itself right like you never have

1326
00:43:10,880 --> 00:43:12,000
to check you know whether

1327
00:43:12,000 --> 00:43:14,400
memory uh and memory allocation can fail

1328
00:43:14,400 --> 00:43:15,280
which is particularly

1329
00:43:15,280 --> 00:43:17,040
in our case good because you know and go

1330
00:43:17,040 --> 00:43:18,480
they can't fail

1331
00:43:18,480 --> 00:43:19,760
there's no error handling code

1332
00:43:19,760 --> 00:43:21,680
unnecessary at all and there's no risk

1333
00:43:21,680 --> 00:43:22,880
for deadlock because you're

1334
00:43:22,880 --> 00:43:24,720
avoiding in the very beginning without

1335
00:43:24,720 --> 00:43:26,960
when you actually hold no locks

1336
00:43:26,960 --> 00:43:29,119
of course you know this is all wonderful

1337
00:43:29,119 --> 00:43:30,000
and well

1338
00:43:30,000 --> 00:43:31,520
the only thing is like how the you know

1339
00:43:31,520 --> 00:43:32,880
there's a challenge of course how you do

1340
00:43:32,880 --> 00:43:34,160
the reservation you know how do you

1341
00:43:34,160 --> 00:43:34,800
compute

1342
00:43:34,800 --> 00:43:38,560
you know how much memory a system call

1343
00:43:38,560 --> 00:43:42,079
might need to uh to

1344
00:43:42,079 --> 00:43:44,720
execute it and so that was sort of a

1345
00:43:44,720 --> 00:43:46,160
puzzle

1346
00:43:46,160 --> 00:43:49,520
um and you know that it's important that

1347
00:43:49,520 --> 00:43:50,240
that

1348
00:43:50,240 --> 00:43:52,800
uh the amount you reserve you know one

1349
00:43:52,800 --> 00:43:54,319
one you could do is like you can reserve

1350
00:43:54,319 --> 00:43:55,520
like half a memory or something like

1351
00:43:55,520 --> 00:43:56,160
that like some

1352
00:43:56,160 --> 00:43:57,920
ridiculous amount of memory for every

1353
00:43:57,920 --> 00:43:59,760
system call but that means you limit the

1354
00:43:59,760 --> 00:44:01,119
number of system calls you can execute

1355
00:44:01,119 --> 00:44:02,800
concurrently so you want to sort of

1356
00:44:02,800 --> 00:44:05,119
do a pretty good job at actually uh

1357
00:44:05,119 --> 00:44:06,240
computing a bound

1358
00:44:06,240 --> 00:44:07,920
of the amount of memory that the system

1359
00:44:07,920 --> 00:44:09,280
call

1360
00:44:09,280 --> 00:44:12,960
might need so

1361
00:44:12,960 --> 00:44:16,319
the way uh we

1362
00:44:16,319 --> 00:44:18,640
ended up doing this and turned out like

1363
00:44:18,640 --> 00:44:21,280
sort of the high level language

1364
00:44:21,280 --> 00:44:23,440
helped us here uh turned out like go is

1365
00:44:23,440 --> 00:44:24,319
actually pretty easy to

1366
00:44:24,319 --> 00:44:27,839
statically analyze in fact the go uh

1367
00:44:27,839 --> 00:44:29,920
runtime and go infrastructure ecosystem

1368
00:44:29,920 --> 00:44:31,280
comes comes with a whole bunch of

1369
00:44:31,280 --> 00:44:32,160
packages

1370
00:44:32,160 --> 00:44:35,520
to analyze go code and we use those uh

1371
00:44:35,520 --> 00:44:36,000
packages

1372
00:44:36,000 --> 00:44:39,520
basically to compute uh the

1373
00:44:39,520 --> 00:44:42,400
amount of memory that the system call

1374
00:44:42,400 --> 00:44:44,000
needs so you can think about just

1375
00:44:44,000 --> 00:44:45,359
let's say like you know you have to read

1376
00:44:45,359 --> 00:44:47,680
system call right you know

1377
00:44:47,680 --> 00:44:49,359
and you know we can look at the call

1378
00:44:49,359 --> 00:44:50,960
graph of the system call you know call

1379
00:44:50,960 --> 00:44:52,640
some function f calls the function g

1380
00:44:52,640 --> 00:44:54,319
calls the function h or blah blah blah

1381
00:44:54,319 --> 00:44:55,839
might continue with a whole bunch

1382
00:44:55,839 --> 00:44:57,280
and then do you know at the end of the

1383
00:44:57,280 --> 00:44:58,960
system also it rewinds to stack again

1384
00:44:58,960 --> 00:44:59,440
and then

1385
00:44:59,440 --> 00:45:01,359
goes back to the and returns to user

1386
00:45:01,359 --> 00:45:02,480
space

1387
00:45:02,480 --> 00:45:04,319
and basically what we can do is like you

1388
00:45:04,319 --> 00:45:06,079
know allocate you know or figure out

1389
00:45:06,079 --> 00:45:07,200
like what the

1390
00:45:07,200 --> 00:45:12,470
maximum depth you know of this this

1391
00:45:12,480 --> 00:45:16,000
call graph is uh at any particular time

1392
00:45:16,000 --> 00:45:17,520
and then basically for that maximum

1393
00:45:17,520 --> 00:45:18,880
depth you know computing you know how

1394
00:45:18,880 --> 00:45:20,720
much you know live memory each of these

1395
00:45:20,720 --> 00:45:22,240
you know functions need so like if this

1396
00:45:22,240 --> 00:45:23,760
function calls new

1397
00:45:23,760 --> 00:45:25,520
you know that i'll allocate some memory

1398
00:45:25,520 --> 00:45:27,200
you know we know what kind of objects

1399
00:45:27,200 --> 00:45:28,720
there are here's a high level language

1400
00:45:28,720 --> 00:45:30,160
so we can compute what the size of that

1401
00:45:30,160 --> 00:45:31,520
object is you know we can just add them

1402
00:45:31,520 --> 00:45:32,079
up

1403
00:45:32,079 --> 00:45:33,680
and that gives us some number s that

1404
00:45:33,680 --> 00:45:35,280
says like the total amount of memory or

1405
00:45:35,280 --> 00:45:35,599
the

1406
00:45:35,599 --> 00:45:37,280
maximum amount of memory that it can be

1407
00:45:37,280 --> 00:45:39,520
live at any particular point in time

1408
00:45:39,520 --> 00:45:43,280
for uh that call graph

1409
00:45:43,280 --> 00:45:44,800
and the reason is you know it's slightly

1410
00:45:44,800 --> 00:45:46,480
tricky it's not as simple as this

1411
00:45:46,480 --> 00:45:47,839
because for example a function

1412
00:45:47,839 --> 00:45:50,720
h you know might allocate some memory

1413
00:45:50,720 --> 00:45:51,280
and then

1414
00:45:51,280 --> 00:45:53,920
pass it back you know to g and so you

1415
00:45:53,920 --> 00:45:55,440
know h finishes

1416
00:45:55,440 --> 00:45:58,079
uh and uh but you know g actually you

1417
00:45:58,079 --> 00:45:58,640
know gets

1418
00:45:58,640 --> 00:46:01,920
uh the memory that h is allocated and

1419
00:46:01,920 --> 00:46:03,760
this is called escaping or the memory

1420
00:46:03,760 --> 00:46:05,200
escapes from

1421
00:46:05,200 --> 00:46:09,040
you know from h to g uh and it turns out

1422
00:46:09,040 --> 00:46:10,480
like you know there are standard

1423
00:46:10,480 --> 00:46:12,079
algorithms for doing sort of this escape

1424
00:46:12,079 --> 00:46:13,839
analysis to see determine which

1425
00:46:13,839 --> 00:46:16,000
variables escape to the callers

1426
00:46:16,000 --> 00:46:17,599
and uh and in that case you know

1427
00:46:17,599 --> 00:46:19,119
basically whatever memory was allocated

1428
00:46:19,119 --> 00:46:19,839
by age and that's

1429
00:46:19,839 --> 00:46:21,839
still alive we have to add you know to

1430
00:46:21,839 --> 00:46:23,599
whatever g is

1431
00:46:23,599 --> 00:46:26,960
uh so you know it has to be added into s

1432
00:46:26,960 --> 00:46:30,319
a quick question about this so

1433
00:46:30,319 --> 00:46:32,800
let's assume we're in some function like

1434
00:46:32,800 --> 00:46:34,720
depending on different workloads that

1435
00:46:34,720 --> 00:46:36,640
the function is expected to have

1436
00:46:36,640 --> 00:46:39,119
there might be different memories memory

1437
00:46:39,119 --> 00:46:40,400
amounts allocated

1438
00:46:40,400 --> 00:46:42,800
so what is there like a worst case web

1439
00:46:42,800 --> 00:46:44,560
memory allocation process

1440
00:46:44,560 --> 00:46:45,839
yeah that's basically it it's sort of

1441
00:46:45,839 --> 00:46:47,440
conserving the scheme correct i mean you

1442
00:46:47,440 --> 00:46:49,040
know we

1443
00:46:49,040 --> 00:46:51,359
we compute the the tool computes

1444
00:46:51,359 --> 00:46:52,319
basically the

1445
00:46:52,319 --> 00:46:55,520
uh worst possible uh depth of function

1446
00:46:55,520 --> 00:46:56,800
calls

1447
00:46:56,800 --> 00:46:59,599
um and you know for that in the worst

1448
00:46:59,599 --> 00:47:01,680
case it analyzes how much memory that

1449
00:47:01,680 --> 00:47:03,119
reach system call

1450
00:47:03,119 --> 00:47:04,800
might need you know in practice it might

1451
00:47:04,800 --> 00:47:06,240
mean the resistance might need a lot

1452
00:47:06,240 --> 00:47:06,880
less

1453
00:47:06,880 --> 00:47:09,520
uh but you know for uh you know to be

1454
00:47:09,520 --> 00:47:11,040
conservative you know we have to

1455
00:47:11,040 --> 00:47:11,839
allocate the work

1456
00:47:11,839 --> 00:47:14,960
we plan for the worst case and so

1457
00:47:14,960 --> 00:47:17,440
we've come to a couple of uh important

1458
00:47:17,440 --> 00:47:18,640
points here because

1459
00:47:18,640 --> 00:47:20,559
uh you know some system calls for

1460
00:47:20,559 --> 00:47:21,920
example execute the for loop that's

1461
00:47:21,920 --> 00:47:23,520
dependent on an argument to the system

1462
00:47:23,520 --> 00:47:24,559
call

1463
00:47:24,559 --> 00:47:25,599
right and so you can't actually

1464
00:47:25,599 --> 00:47:27,839
statically figure out what the bound is

1465
00:47:27,839 --> 00:47:30,160
and so a number of cases you know we

1466
00:47:30,160 --> 00:47:32,000
annotated the code to say like well this

1467
00:47:32,000 --> 00:47:34,160
is the maximum bound of this loop

1468
00:47:34,160 --> 00:47:35,760
and you can assume it's no more than

1469
00:47:35,760 --> 00:47:37,440
that and you use that to actually

1470
00:47:37,440 --> 00:47:40,079
compute this number s

1471
00:47:40,079 --> 00:47:42,400
uh similarly you know for example if you

1472
00:47:42,400 --> 00:47:43,839
have a recursive function

1473
00:47:43,839 --> 00:47:45,040
you know who knows how deep the

1474
00:47:45,040 --> 00:47:47,119
recursion is right and that might also

1475
00:47:47,119 --> 00:47:47,599
be

1476
00:47:47,599 --> 00:47:49,520
dependent on a dynamic variable or an

1477
00:47:49,520 --> 00:47:51,040
argument to system call

1478
00:47:51,040 --> 00:47:53,119
and in fact you know you know we you

1479
00:47:53,119 --> 00:47:55,200
know we tweak biscuit in some places to

1480
00:47:55,200 --> 00:47:56,640
basically avoid recursive

1481
00:47:56,640 --> 00:47:58,880
function calls uh so that actually was

1482
00:47:58,880 --> 00:48:00,480
possible to do this you know

1483
00:48:00,480 --> 00:48:03,119
to do this kind of analysis and so this

1484
00:48:03,119 --> 00:48:04,640
kind of analysis not for free it's not

1485
00:48:04,640 --> 00:48:05,680
completely automatic

1486
00:48:05,680 --> 00:48:07,760
it takes a couple days of work you know

1487
00:48:07,760 --> 00:48:08,880
for in this case

1488
00:48:08,880 --> 00:48:10,960
you know cody to go through you know

1489
00:48:10,960 --> 00:48:12,480
look at all these loops

1490
00:48:12,480 --> 00:48:16,800
uh and uh and and annotate

1491
00:48:16,800 --> 00:48:18,720
uh you know there are a couple other go

1492
00:48:18,720 --> 00:48:20,160
specific issues that you have to deal

1493
00:48:20,160 --> 00:48:21,200
with slices

1494
00:48:21,200 --> 00:48:22,960
you know they might double in size if

1495
00:48:22,960 --> 00:48:25,520
you uh add an element to the slice

1496
00:48:25,520 --> 00:48:28,079
uh and so we we annotate the slices with

1497
00:48:28,079 --> 00:48:29,760
some maximum capacity

1498
00:48:29,760 --> 00:48:31,839
uh but it's all sort of doable so a

1499
00:48:31,839 --> 00:48:32,800
couple days work

1500
00:48:32,800 --> 00:48:35,359
and uh you know using this tool then you

1501
00:48:35,359 --> 00:48:36,800
can sort of get a number out that is

1502
00:48:36,800 --> 00:48:38,000
reasonable good

1503
00:48:38,000 --> 00:48:41,119
in terms of you know computing uh and

1504
00:48:41,119 --> 00:48:43,520
a maximum amount of memory that a

1505
00:48:43,520 --> 00:48:46,079
particular system call needs

1506
00:48:46,079 --> 00:48:48,559
and so this is basically how you know we

1507
00:48:48,559 --> 00:48:50,319
basically biscuit solves this particular

1508
00:48:50,319 --> 00:48:53,990
problem

1509
00:48:54,000 --> 00:48:56,880
oh sorry what else are people using this

1510
00:48:56,880 --> 00:48:57,920
tool for

1511
00:48:57,920 --> 00:48:59,760
like they're not they're not building a

1512
00:48:59,760 --> 00:49:01,760
kernel what are they using it for over

1513
00:49:01,760 --> 00:49:03,520
the static analysis packages

1514
00:49:03,520 --> 00:49:06,160
uh yeah the go compiler internally uses

1515
00:49:06,160 --> 00:49:07,440
it for all kinds of uh

1516
00:49:07,440 --> 00:49:10,880
optimizations you know to uh uh

1517
00:49:10,880 --> 00:49:14,400
and do static analysis on uh the gogo to

1518
00:49:14,400 --> 00:49:14,880
figure out

1519
00:49:14,880 --> 00:49:16,319
like the best way to comp to for the

1520
00:49:16,319 --> 00:49:18,160
best way to compile it

1521
00:49:18,160 --> 00:49:21,200
i see i see okay thank you uh

1522
00:49:21,200 --> 00:49:22,640
so this is one of the cool things about

1523
00:49:22,640 --> 00:49:23,920
it just as a package you know that the

1524
00:49:23,920 --> 00:49:25,440
compiler happens to use you know but we

1525
00:49:25,440 --> 00:49:28,309
could use it too

1526
00:49:28,319 --> 00:49:30,079
you'll see later on we also use it for a

1527
00:49:30,079 --> 00:49:32,640
couple other features uh

1528
00:49:32,640 --> 00:49:35,839
uh it's very convenient to have

1529
00:49:35,839 --> 00:49:40,480
um okay uh thank you

1530
00:49:40,480 --> 00:49:42,960
okay turns with the implementation uh

1531
00:49:42,960 --> 00:49:44,000
you know biscuit was basically

1532
00:49:44,000 --> 00:49:47,040
very similar to other uh kernels or like

1533
00:49:47,040 --> 00:49:49,280
you know in xv6 except you know more

1534
00:49:49,280 --> 00:49:52,960
uh high performance uh you know what

1535
00:49:52,960 --> 00:49:55,359
we adopted many of the optimizations or

1536
00:49:55,359 --> 00:49:56,240
cleverness that

1537
00:49:56,240 --> 00:49:58,240
the linux kernel has you know at least

1538
00:49:58,240 --> 00:49:59,599
for the system calls that we're trying

1539
00:49:59,599 --> 00:50:00,800
to implement

1540
00:50:00,800 --> 00:50:02,720
uh you know we use large pages for

1541
00:50:02,720 --> 00:50:04,559
kernel text you know to avoid you know

1542
00:50:04,559 --> 00:50:06,319
tob costs

1543
00:50:06,319 --> 00:50:09,440
uh we have per cpu nic transmit cues

1544
00:50:09,440 --> 00:50:12,800
so to avoid synchronization uh between

1545
00:50:12,800 --> 00:50:14,000
port

1546
00:50:14,000 --> 00:50:16,559
we have an rcu uh i'll talk a little bit

1547
00:50:16,559 --> 00:50:18,000
more about the directory cache

1548
00:50:18,000 --> 00:50:20,400
that is in basically lock free or read

1549
00:50:20,400 --> 00:50:21,520
lock free

1550
00:50:21,520 --> 00:50:23,119
directory cache at the end of the

1551
00:50:23,119 --> 00:50:24,720
semester we'll talk about rcu in more

1552
00:50:24,720 --> 00:50:26,800
detail but you know uh this could happen

1553
00:50:26,800 --> 00:50:27,920
too

1554
00:50:27,920 --> 00:50:31,200
uh you know

1555
00:50:31,200 --> 00:50:33,119
sort of the usual type of optimization

1556
00:50:33,119 --> 00:50:34,800
that actually you need to get

1557
00:50:34,800 --> 00:50:37,119
done to get high performance and the

1558
00:50:37,119 --> 00:50:37,920
main

1559
00:50:37,920 --> 00:50:40,240
lesson i think we learned is that you

1560
00:50:40,240 --> 00:50:41,920
know go was not standing in the way of

1561
00:50:41,920 --> 00:50:43,599
implementing these optimizations

1562
00:50:43,599 --> 00:50:46,480
uh so you know this optimization could

1563
00:50:46,480 --> 00:50:46,800
be

1564
00:50:46,800 --> 00:50:48,559
that were implemented in c and linux you

1565
00:50:48,559 --> 00:50:50,400
know we basically implemented the same

1566
00:50:50,400 --> 00:50:52,160
uh optimization but every implemented

1567
00:50:52,160 --> 00:50:54,000
bingo and so the language itself is not

1568
00:50:54,000 --> 00:50:57,359
a hurdle or a problem in fact it was

1569
00:50:57,359 --> 00:50:58,720
completely conducive to actually

1570
00:50:58,720 --> 00:51:01,359
implementing these optimizations

1571
00:51:01,359 --> 00:51:02,800
it was a lot of work to implement these

1572
00:51:02,800 --> 00:51:04,319
optimizations but you know those

1573
00:51:04,319 --> 00:51:09,680
irrespective of the language

1574
00:51:09,680 --> 00:51:12,240
okay so that brings me sort of to uh the

1575
00:51:12,240 --> 00:51:14,319
evaluation which is really what the

1576
00:51:14,319 --> 00:51:15,520
you know motivation of the whole paper

1577
00:51:15,520 --> 00:51:17,599
was which is like trying to get a

1578
00:51:17,599 --> 00:51:20,400
handle on uh the benefits and the costs

1579
00:51:20,400 --> 00:51:22,480
of high-level language so basically

1580
00:51:22,480 --> 00:51:24,240
the evaluation uh sort of split in two

1581
00:51:24,240 --> 00:51:25,680
parts first talking about the benefits

1582
00:51:25,680 --> 00:51:29,270
and then talking about the costs

1583
00:51:29,280 --> 00:51:32,240
so uh so three questions you know first

1584
00:51:32,240 --> 00:51:32,640
of all

1585
00:51:32,640 --> 00:51:34,800
you know there's a question like didn't

1586
00:51:34,800 --> 00:51:35,680
cheat you know

1587
00:51:35,680 --> 00:51:37,119
maybe we avoided all the expensive

1588
00:51:37,119 --> 00:51:38,880
high-level language features

1589
00:51:38,880 --> 00:51:42,160
uh that go offers um doesn't uh this is

1590
00:51:42,160 --> 00:51:43,280
the second question of course does the

1591
00:51:43,280 --> 00:51:45,599
high level simplify the basic code and

1592
00:51:45,599 --> 00:51:47,040
in order to prevent some of these

1593
00:51:47,040 --> 00:51:48,480
exploits that you know i mentioned

1594
00:51:48,480 --> 00:51:51,280
earlier on in the in the lecture

1595
00:51:51,280 --> 00:51:53,200
so first this back to the new high level

1596
00:51:53,200 --> 00:51:54,960
language uh features

1597
00:51:54,960 --> 00:51:56,880
we just wanted to see whether we were

1598
00:51:56,880 --> 00:51:58,800
sort of similar in terms of other big go

1599
00:51:58,800 --> 00:52:00,319
projects in terms of language features

1600
00:52:00,319 --> 00:52:01,680
so that you know we could say like well

1601
00:52:01,680 --> 00:52:03,200
the kernel seems to be doing

1602
00:52:03,200 --> 00:52:05,440
sort of roughly the same advantage of

1603
00:52:05,440 --> 00:52:06,240
the same features

1604
00:52:06,240 --> 00:52:08,400
in sort of similar ways so we use

1605
00:52:08,400 --> 00:52:10,319
actually the same static analysis tool

1606
00:52:10,319 --> 00:52:12,079
or package to basically analyze

1607
00:52:12,079 --> 00:52:15,839
a whole bunch of uh two big pieces of

1608
00:52:15,839 --> 00:52:17,440
ghost offer that are in github

1609
00:52:17,440 --> 00:52:18,720
you know there are millions of lines of

1610
00:52:18,720 --> 00:52:20,319
code one is you know the go runtime

1611
00:52:20,319 --> 00:52:22,000
itself and all its packages

1612
00:52:22,000 --> 00:52:25,119
and uh the system called moby and then

1613
00:52:25,119 --> 00:52:27,280
we just basically plot it for

1614
00:52:27,280 --> 00:52:28,640
sort of numerous high level language

1615
00:52:28,640 --> 00:52:30,160
features how many times they were used

1616
00:52:30,160 --> 00:52:31,200
per thousand lines

1617
00:52:31,200 --> 00:52:33,119
so this graph shows that so usually

1618
00:52:33,119 --> 00:52:34,240
around the

1619
00:52:34,240 --> 00:52:36,319
x-axis are the language features you

1620
00:52:36,319 --> 00:52:38,160
know basically allocations correspond to

1621
00:52:38,160 --> 00:52:38,640
calling

1622
00:52:38,640 --> 00:52:40,400
you know new and sort of this

1623
00:52:40,400 --> 00:52:42,319
corresponds to memory that it will be

1624
00:52:42,319 --> 00:52:43,839
dynamically allocated by the garbage

1625
00:52:43,839 --> 00:52:46,319
collector you know maps are like hash

1626
00:52:46,319 --> 00:52:47,200
tables

1627
00:52:47,200 --> 00:52:49,440
slices or dynamic arrays you know here's

1628
00:52:49,440 --> 00:52:51,280
the channels synchronization as you can

1629
00:52:51,280 --> 00:52:51,839
see we

1630
00:52:51,839 --> 00:52:53,760
use them very very literally but so does

1631
00:52:53,760 --> 00:52:57,040
the go runtime and mobi

1632
00:52:57,040 --> 00:52:59,119
clearly the feature that we liked most

1633
00:52:59,119 --> 00:53:01,200
was multi-function return

1634
00:53:01,200 --> 00:53:03,520
so being being able to return multiple

1635
00:53:03,520 --> 00:53:04,720
values

1636
00:53:04,720 --> 00:53:07,520
uh you know we use closures uh we didn't

1637
00:53:07,520 --> 00:53:08,480
use finalizer

1638
00:53:08,480 --> 00:53:10,960
uh use deferred a little bit you know

1639
00:53:10,960 --> 00:53:12,400
there's a bunch of you know go routines

1640
00:53:12,400 --> 00:53:13,280
that we do create

1641
00:53:13,280 --> 00:53:16,079
we use interfaces uh you know type

1642
00:53:16,079 --> 00:53:17,440
assertions to convert from

1643
00:53:17,440 --> 00:53:20,800
one type to another uh in a

1644
00:53:20,800 --> 00:53:23,599
type state manner and importing many

1645
00:53:23,599 --> 00:53:24,240
packages

1646
00:53:24,240 --> 00:53:26,640
so the kernel itself is built out of any

1647
00:53:26,640 --> 00:53:28,720
packages or not like for one big single

1648
00:53:28,720 --> 00:53:29,760
program

1649
00:53:29,760 --> 00:53:31,359
so if you look at this you know some

1650
00:53:31,359 --> 00:53:33,599
features you know uh biscuit uses less

1651
00:53:33,599 --> 00:53:35,359
than gold line and mobi and sometimes

1652
00:53:35,359 --> 00:53:36,000
you know

1653
00:53:36,000 --> 00:53:37,680
basically loses some features more or

1654
00:53:37,680 --> 00:53:39,920
roughly in there

1655
00:53:39,920 --> 00:53:42,800
not not in any sort of distinctly

1656
00:53:42,800 --> 00:53:44,000
different way

1657
00:53:44,000 --> 00:53:46,079
uh so the main conclusion from this is

1658
00:53:46,079 --> 00:53:48,480
you know biscuit uses the high level of

1659
00:53:48,480 --> 00:53:49,680
features that actually go offers and

1660
00:53:49,680 --> 00:53:53,829
doesn't sidestep them

1661
00:53:53,839 --> 00:53:56,880
to basically get good forms

1662
00:53:56,880 --> 00:54:01,359
okay um i have a question

1663
00:54:01,359 --> 00:54:04,240
how did you uh how how were you able to

1664
00:54:04,240 --> 00:54:05,359
count all of this

1665
00:54:05,359 --> 00:54:08,240
did you use the static analysis tool

1666
00:54:08,240 --> 00:54:08,800
yeah

1667
00:54:08,800 --> 00:54:10,559
yeah you basically use the static uh

1668
00:54:10,559 --> 00:54:12,240
package static analysis package and then

1669
00:54:12,240 --> 00:54:13,680
wrote a little program that uses a

1670
00:54:13,680 --> 00:54:15,520
static analysis packages go over every

1671
00:54:15,520 --> 00:54:17,040
statement in these programs and look at

1672
00:54:17,040 --> 00:54:19,760
what kind of type of statement it is

1673
00:54:19,760 --> 00:54:22,480
and then or you get the argument to see

1674
00:54:22,480 --> 00:54:23,920
how the arguments are being used and

1675
00:54:23,920 --> 00:54:27,589
that gives you a sense about how

1676
00:54:27,599 --> 00:54:31,240
that allows you to count these features

1677
00:54:31,250 --> 00:54:37,510
[Music]

1678
00:54:37,520 --> 00:54:40,160
okay so uh the the next thing is a

1679
00:54:40,160 --> 00:54:41,280
little bit subjective

1680
00:54:41,280 --> 00:54:43,680
uh the the high level and simplified

1681
00:54:43,680 --> 00:54:44,960
biscuit code

1682
00:54:44,960 --> 00:54:48,160
uh i think it generally did

1683
00:54:48,160 --> 00:54:50,880
uh and i also will argue one or two

1684
00:54:50,880 --> 00:54:52,559
examples explicitly but

1685
00:54:52,559 --> 00:54:55,200
uh not having the gcd allocation is

1686
00:54:55,200 --> 00:54:56,799
actually very nice and maybe i can make

1687
00:54:56,799 --> 00:54:58,559
the point like if you think about xv6 or

1688
00:54:58,559 --> 00:55:00,079
like you do an exit

1689
00:55:00,079 --> 00:55:01,839
on a point of exit there's a lot of data

1690
00:55:01,839 --> 00:55:03,680
structures that need to be freed or

1691
00:55:03,680 --> 00:55:07,040
returned to the kernel and

1692
00:55:07,040 --> 00:55:09,359
so that later process can use uh using

1693
00:55:09,359 --> 00:55:10,799
the garbage lecture is really easy you

1694
00:55:10,799 --> 00:55:12,160
know the garbage collector takes care of

1695
00:55:12,160 --> 00:55:13,440
all of it you know you don't really have

1696
00:55:13,440 --> 00:55:14,559
to do much

1697
00:55:14,559 --> 00:55:16,000
so if you allocate you know through your

1698
00:55:16,000 --> 00:55:17,760
address space you know the vmas that

1699
00:55:17,760 --> 00:55:19,440
corresponds up at address space will be

1700
00:55:19,440 --> 00:55:20,720
automatically freed by the garbage

1701
00:55:20,720 --> 00:55:22,480
collector too

1702
00:55:22,480 --> 00:55:25,119
so you know just that's just simple uh

1703
00:55:25,119 --> 00:55:26,240
as you mentioned earlier the

1704
00:55:26,240 --> 00:55:28,160
multi-return values were really nice

1705
00:55:28,160 --> 00:55:30,000
in terms of programming style uh

1706
00:55:30,000 --> 00:55:31,839
closures were nice maps were great you

1707
00:55:31,839 --> 00:55:32,880
know

1708
00:55:32,880 --> 00:55:36,319
you don't have to many places xp6 for

1709
00:55:36,319 --> 00:55:37,200
example

1710
00:55:37,200 --> 00:55:39,280
you know looks up something in a linear

1711
00:55:39,280 --> 00:55:40,319
fashion uh

1712
00:55:40,319 --> 00:55:42,160
but if you have hash tables or maps as a

1713
00:55:42,160 --> 00:55:43,920
first class object or abstraction in the

1714
00:55:43,920 --> 00:55:44,960
programming language you would never do

1715
00:55:44,960 --> 00:55:45,280
that

1716
00:55:45,280 --> 00:55:49,119
right right just use map and the runtime

1717
00:55:49,119 --> 00:55:50,240
will take care of you know doing

1718
00:55:50,240 --> 00:55:51,920
everything efficiently

1719
00:55:51,920 --> 00:55:53,520
so in effect i think you know

1720
00:55:53,520 --> 00:55:55,200
qualitatively you know it feels

1721
00:55:55,200 --> 00:55:58,160
you get simpler code but that's clearly

1722
00:55:58,160 --> 00:55:59,599
qualitatively you know just to give a

1723
00:55:59,599 --> 00:56:01,119
little bit more of a concrete example

1724
00:56:01,119 --> 00:56:01,599
where

1725
00:56:01,599 --> 00:56:03,520
really where sort of a high level

1726
00:56:03,520 --> 00:56:04,960
language a particular garbage collector

1727
00:56:04,960 --> 00:56:06,000
shines

1728
00:56:06,000 --> 00:56:07,119
is you know when there's a lot of

1729
00:56:07,119 --> 00:56:09,280
concurrency between uh when there's

1730
00:56:09,280 --> 00:56:10,640
concurrency threats and the threats have

1731
00:56:10,640 --> 00:56:11,280
to share

1732
00:56:11,280 --> 00:56:14,240
a particular shared data item and so for

1733
00:56:14,240 --> 00:56:15,680
example the

1734
00:56:15,680 --> 00:56:17,200
here's the sort of simplest case you

1735
00:56:17,200 --> 00:56:18,960
know where you can boil down this

1736
00:56:18,960 --> 00:56:20,799
question too let's say you allocate some

1737
00:56:20,799 --> 00:56:24,400
uh dynamically an object like a buffer

1738
00:56:24,400 --> 00:56:27,280
um your fork fret you know and that

1739
00:56:27,280 --> 00:56:29,119
process that buffer and there's another

1740
00:56:29,119 --> 00:56:30,640
thread that also process that buffer and

1741
00:56:30,640 --> 00:56:32,240
do something with this buffer

1742
00:56:32,240 --> 00:56:33,599
then when both frets are done you know

1743
00:56:33,599 --> 00:56:35,040
the buffer needs to be freed so that

1744
00:56:35,040 --> 00:56:36,160
they can be used for

1745
00:56:36,160 --> 00:56:38,799
later uh you know linear kernel

1746
00:56:38,799 --> 00:56:40,000
operations

1747
00:56:40,000 --> 00:56:41,520
and the question is like who should do

1748
00:56:41,520 --> 00:56:44,319
this who's in charge uh

1749
00:56:44,319 --> 00:56:46,559
and there's a little bit difficult uh to

1750
00:56:46,559 --> 00:56:47,359
coordinate

1751
00:56:47,359 --> 00:56:50,720
uh in uh c because you know you have to

1752
00:56:50,720 --> 00:56:52,400
have some way of deciding that actually

1753
00:56:52,400 --> 00:56:54,000
the buffer is actually not being used

1754
00:56:54,000 --> 00:56:55,440
if you use a garbage collector there's

1755
00:56:55,440 --> 00:56:56,960
nothing to decide you know basically

1756
00:56:56,960 --> 00:56:58,400
both threads run when they're done with

1757
00:56:58,400 --> 00:56:59,119
the

1758
00:56:59,119 --> 00:57:01,520
buffer uh no threat is pointing to that

1759
00:57:01,520 --> 00:57:03,119
buffer anymore the garbage collector you

1760
00:57:03,119 --> 00:57:04,880
know will trace you know starting from

1761
00:57:04,880 --> 00:57:06,240
the threat stacks

1762
00:57:06,240 --> 00:57:08,079
and we'll never you know and will not

1763
00:57:08,079 --> 00:57:09,440
account the buffer in any of the fret

1764
00:57:09,440 --> 00:57:10,720
stacks and therefore the garbage

1765
00:57:10,720 --> 00:57:11,680
collector will free

1766
00:57:11,680 --> 00:57:13,760
you know the memory at some point later

1767
00:57:13,760 --> 00:57:15,040
and so in

1768
00:57:15,040 --> 00:57:16,160
garbage collective language you just

1769
00:57:16,160 --> 00:57:17,280
don't have to think about this problem

1770
00:57:17,280 --> 00:57:18,640
at all

1771
00:57:18,640 --> 00:57:21,920
um so you know one way you could try to

1772
00:57:21,920 --> 00:57:24,559
solve this you know problem in occurring

1773
00:57:24,559 --> 00:57:25,200
language like c

1774
00:57:25,200 --> 00:57:27,359
so you maybe could put reference counts

1775
00:57:27,359 --> 00:57:28,640
on the objects you know the reference

1776
00:57:28,640 --> 00:57:30,000
counts of course have to be uh

1777
00:57:30,000 --> 00:57:32,079
protected you know by locks perhaps or

1778
00:57:32,079 --> 00:57:33,839
by some atomic operations

1779
00:57:33,839 --> 00:57:35,280
and then when the refs come to reach a

1780
00:57:35,280 --> 00:57:37,599
zero then you you can uh different

1781
00:57:37,599 --> 00:57:41,280
dereference it um and it turns out like

1782
00:57:41,280 --> 00:57:42,160
you know locks and

1783
00:57:42,160 --> 00:57:43,280
reference accounts actually slightly

1784
00:57:43,280 --> 00:57:45,680
expensive you know if you want a

1785
00:57:45,680 --> 00:57:48,240
high performance you know concurrency

1786
00:57:48,240 --> 00:57:49,920
and scale up your watch number course

1787
00:57:49,920 --> 00:57:51,119
then that actually can

1788
00:57:51,119 --> 00:57:52,720
be your bottleneck and we'll see that

1789
00:57:52,720 --> 00:57:54,640
later in a couple weeks we'll read a

1790
00:57:54,640 --> 00:57:55,760
paper that actually

1791
00:57:55,760 --> 00:57:58,480
talks about this very explicitly and so

1792
00:57:58,480 --> 00:57:59,359
people tend to

1793
00:57:59,359 --> 00:58:00,960
if you want to do a high performance you

1794
00:58:00,960 --> 00:58:02,799
and get good parallelism you people tend

1795
00:58:02,799 --> 00:58:03,920
to avoid them

1796
00:58:03,920 --> 00:58:06,000
uh and in fact in particular the

1797
00:58:06,000 --> 00:58:07,599
scenario that we try to avoid them is

1798
00:58:07,599 --> 00:58:09,280
like uh in read lock

1799
00:58:09,280 --> 00:58:11,119
you would like to make at least reading

1800
00:58:11,119 --> 00:58:12,640
sort of lock free so you don't have to

1801
00:58:12,640 --> 00:58:13,920
pay the cost

1802
00:58:13,920 --> 00:58:15,200
and so for example here's a code

1803
00:58:15,200 --> 00:58:16,960
fragment that would do that

1804
00:58:16,960 --> 00:58:18,799
here we have a get function that

1805
00:58:18,799 --> 00:58:20,880
basically you know reads the head of a

1806
00:58:20,880 --> 00:58:23,760
queue and returns the whatever is at the

1807
00:58:23,760 --> 00:58:25,280
head of the cube

1808
00:58:25,280 --> 00:58:27,280
and does it basically in a lock-free

1809
00:58:27,280 --> 00:58:29,119
manner you know it uses an atomic

1810
00:58:29,119 --> 00:58:31,520
load to actually read the head but it

1811
00:58:31,520 --> 00:58:33,440
doesn't actually take a lock out

1812
00:58:33,440 --> 00:58:35,119
then the writer you know does stick

1813
00:58:35,119 --> 00:58:36,960
locks out so this is like

1814
00:58:36,960 --> 00:58:39,839
block free but the writer is not block

1815
00:58:39,839 --> 00:58:41,280
free

1816
00:58:41,280 --> 00:58:43,119
and this is a very common style in the

1817
00:58:43,119 --> 00:58:45,040
linux kernel and so the writer actually

1818
00:58:45,040 --> 00:58:46,160
you know takes out the lock

1819
00:58:46,160 --> 00:58:48,000
you know whatever looks at the head

1820
00:58:48,000 --> 00:58:49,200
maybe

1821
00:58:49,200 --> 00:58:51,040
this is the pop function and it pops up

1822
00:58:51,040 --> 00:58:52,880
the head from the queue

1823
00:58:52,880 --> 00:58:54,480
and then you know in principle you could

1824
00:58:54,480 --> 00:58:57,280
reuse it and then unlocks

1825
00:58:57,280 --> 00:59:00,280
when you free the head now again in

1826
00:59:00,280 --> 00:59:02,640
[Music]

1827
00:59:02,640 --> 00:59:03,599
in see see there's a little bit

1828
00:59:03,599 --> 00:59:05,040
difficult you know when do you actually

1829
00:59:05,040 --> 00:59:05,839
free the head

1830
00:59:05,839 --> 00:59:07,520
uh because it could be the case that

1831
00:59:07,520 --> 00:59:09,040
some other concurrent threat that just

1832
00:59:09,040 --> 00:59:09,440
you know

1833
00:59:09,440 --> 00:59:11,839
just before you did this atomic store

1834
00:59:11,839 --> 00:59:13,599
you know this guy actually came through

1835
00:59:13,599 --> 00:59:15,359
and basically got a pointer to that

1836
00:59:15,359 --> 00:59:16,720
particular object so

1837
00:59:16,720 --> 00:59:18,559
once you're done with this atomic store

1838
00:59:18,559 --> 00:59:20,240
you can't actually free the pointer

1839
00:59:20,240 --> 00:59:21,359
because you know the

1840
00:59:21,359 --> 00:59:22,720
could be another fret actually has a

1841
00:59:22,720 --> 00:59:24,400
pointer to it and if you free it right

1842
00:59:24,400 --> 00:59:24,799
here

1843
00:59:24,799 --> 00:59:26,480
you could actually have use after free

1844
00:59:26,480 --> 00:59:29,119
buck and so the uh

1845
00:59:29,119 --> 00:59:31,839
and so you know we'll see uh in a couple

1846
00:59:31,839 --> 00:59:32,960
lectures

1847
00:59:32,960 --> 00:59:35,440
uh the linux kernel has a very clever

1848
00:59:35,440 --> 00:59:36,799
solution for this

1849
00:59:36,799 --> 00:59:39,520
which is called read copy update or rcu

1850
00:59:39,520 --> 00:59:41,119
and basically what it does is

1851
00:59:41,119 --> 00:59:43,119
it defers freeing of memory until it

1852
00:59:43,119 --> 00:59:45,280
really knows it's safe

1853
00:59:45,280 --> 00:59:46,640
and it has a very clever scheme to

1854
00:59:46,640 --> 00:59:48,640
actually decide how to when it's safe

1855
00:59:48,640 --> 00:59:50,079
but that scheme does come with all kinds

1856
00:59:50,079 --> 00:59:51,520
of it comes with restrictions and

1857
00:59:51,520 --> 00:59:53,119
programmers actually have to obey some

1858
00:59:53,119 --> 00:59:54,400
set of rules

1859
00:59:54,400 --> 00:59:57,599
uh that you must follow for sort of rcu

1860
00:59:57,599 --> 00:59:59,920
critical sections as they're called uh

1861
00:59:59,920 --> 01:00:01,280
for example you can't call

1862
01:00:01,280 --> 01:00:03,520
uh this you can't call you can't go to

1863
01:00:03,520 --> 01:00:04,880
sleep in an rcu

1864
01:00:04,880 --> 01:00:07,119
critical section or schedule and so it

1865
01:00:07,119 --> 01:00:08,240
turns out that you know

1866
01:00:08,240 --> 01:00:10,160
although you know the linux kernel uses

1867
01:00:10,160 --> 01:00:11,680
this extremely successful you know it's

1868
01:00:11,680 --> 01:00:14,319
a bit error prone and you know that

1869
01:00:14,319 --> 01:00:16,799
requires careful program to get it right

1870
01:00:16,799 --> 01:00:17,599
and

1871
01:00:17,599 --> 01:00:18,960
in the case of the garbage collector

1872
01:00:18,960 --> 01:00:20,799
language like you know go this is again

1873
01:00:20,799 --> 01:00:22,400
this is like a non-issue

1874
01:00:22,400 --> 01:00:23,920
because the carbs collector will

1875
01:00:23,920 --> 01:00:25,040
actually determine when actually

1876
01:00:25,040 --> 01:00:26,559
something's not in use anymore and then

1877
01:00:26,559 --> 01:00:28,079
only then free it

1878
01:00:28,079 --> 01:00:29,359
and so there's nothing really you know

1879
01:00:29,359 --> 01:00:30,400
there's no restrictions on the

1880
01:00:30,400 --> 01:00:31,280
programmer

1881
01:00:31,280 --> 01:00:33,520
uh it just taken care of by the garbage

1882
01:00:33,520 --> 01:00:35,839
collector

1883
01:00:35,839 --> 01:00:37,440
so that's sort of an example of you know

1884
01:00:37,440 --> 01:00:39,680
where sort of more maybe

1885
01:00:39,680 --> 01:00:42,720
quantitatively or more you know explicit

1886
01:00:42,720 --> 01:00:43,920
you can see sort of the advantage of a

1887
01:00:43,920 --> 01:00:45,839
garbage collected language

1888
01:00:45,839 --> 01:00:47,760
okay turns to the cvs you know i sort of

1889
01:00:47,760 --> 01:00:49,200
mentioned this already

1890
01:00:49,200 --> 01:00:51,280
we went through all these cvs and you

1891
01:00:51,280 --> 01:00:53,280
know sort of inspected them manually

1892
01:00:53,280 --> 01:00:54,880
and then tried to decide whether to

1893
01:00:54,880 --> 01:00:56,720
actually go with fix the problem

1894
01:00:56,720 --> 01:00:58,000
if we're living them you know we

1895
01:00:58,000 --> 01:01:00,000
couldn't figure out you know we looked

1896
01:01:00,000 --> 01:01:00,799
at the fix

1897
01:01:00,799 --> 01:01:02,640
you know the the patch that addresses

1898
01:01:02,640 --> 01:01:04,160
this if we

1899
01:01:04,160 --> 01:01:05,440
couldn't really figure out like what the

1900
01:01:05,440 --> 01:01:06,960
outcome and goal would like or how it

1901
01:01:06,960 --> 01:01:08,240
would manifest or how would

1902
01:01:08,240 --> 01:01:10,720
change we could see how we implemented

1903
01:01:10,720 --> 01:01:11,920
the fix but we couldn't decide whether

1904
01:01:11,920 --> 01:01:13,119
it would actually go with avoided the

1905
01:01:13,119 --> 01:01:14,559
problem or not

1906
01:01:14,559 --> 01:01:16,480
uh there were a number of logic blocks

1907
01:01:16,480 --> 01:01:18,000
in these cvs and so

1908
01:01:18,000 --> 01:01:19,440
presumably you know go you remain the

1909
01:01:19,440 --> 01:01:21,359
same logic bug as in c and you know

1910
01:01:21,359 --> 01:01:23,839
the the outcome would be the same but

1911
01:01:23,839 --> 01:01:25,680
then you know there were about 40

1912
01:01:25,680 --> 01:01:27,680
memory safety bugs you know use after

1913
01:01:27,680 --> 01:01:29,920
three or double freeze or out of bounds

1914
01:01:29,920 --> 01:01:32,160
and in you know eight of days you just

1915
01:01:32,160 --> 01:01:33,920
disappear because the garbage collector

1916
01:01:33,920 --> 01:01:35,920
takes care of them as i sure described

1917
01:01:35,920 --> 01:01:37,359
in the last couple slides

1918
01:01:37,359 --> 01:01:39,839
and in 32 cases you know we go with a

1919
01:01:39,839 --> 01:01:41,520
generated panic because your example

1920
01:01:41,520 --> 01:01:42,160
would go

1921
01:01:42,160 --> 01:01:45,280
outside of an array bound um and

1922
01:01:45,280 --> 01:01:46,880
of course panic is not good you know the

1923
01:01:46,880 --> 01:01:48,799
kernel crashes but it's probably better

1924
01:01:48,799 --> 01:01:50,799
than a security exploit

1925
01:01:50,799 --> 01:01:52,960
and so yeah so in 40 cases you know

1926
01:01:52,960 --> 01:01:54,559
basically the high level language helped

1927
01:01:54,559 --> 01:01:59,829
us

1928
01:01:59,839 --> 01:02:02,319
okay so that's the quality of the the

1929
01:02:02,319 --> 01:02:02,960
benefits

1930
01:02:02,960 --> 01:02:04,839
so now i want to talk a little bit about

1931
01:02:04,839 --> 01:02:06,640
the uh

1932
01:02:06,640 --> 01:02:09,680
the performance cost i love language

1933
01:02:09,680 --> 01:02:10,799
text

1934
01:02:10,799 --> 01:02:12,480
but before doing that let me ask if

1935
01:02:12,480 --> 01:02:20,960
there's any more questions

1936
01:02:20,960 --> 01:02:23,119
okay um you know i'm going to go through

1937
01:02:23,119 --> 01:02:24,559
them i'm not sure

1938
01:02:24,559 --> 01:02:26,559
we'll make it through all six uh because

1939
01:02:26,559 --> 01:02:27,920
i want to reserve a couple minutes at

1940
01:02:27,920 --> 01:02:29,200
least at the end you know to come back

1941
01:02:29,200 --> 01:02:29,839
to the

1942
01:02:29,839 --> 01:02:31,760
the starting point of the lecture

1943
01:02:31,760 --> 01:02:35,839
today's question

1944
01:02:35,839 --> 01:02:38,160
uh so the setup in terms of experiments

1945
01:02:38,160 --> 01:02:38,960
uh

1946
01:02:38,960 --> 01:02:41,680
you know the basically runs on raw

1947
01:02:41,680 --> 01:02:42,640
hardware

1948
01:02:42,640 --> 01:02:44,319
so these experiments are on little

1949
01:02:44,319 --> 01:02:47,440
physical machines not on top of qmu

1950
01:02:47,440 --> 01:02:50,799
there's a four core 2.8 gigahertz uh

1951
01:02:50,799 --> 01:02:53,280
intel processor 16 gigabyte rim but

1952
01:02:53,280 --> 01:02:54,960
hyper that's disabled we use three

1953
01:02:54,960 --> 01:02:55,680
applications

1954
01:02:55,680 --> 01:02:57,680
a web server a key value store and a

1955
01:02:57,680 --> 01:02:59,039
mail server benchmark

1956
01:02:59,039 --> 01:03:01,680
and all these applications stress uh the

1957
01:03:01,680 --> 01:03:02,960
kernel intensively

1958
01:03:02,960 --> 01:03:06,240
and so they run execute system calls and

1959
01:03:06,240 --> 01:03:09,280
the kernel must do a lot of work and you

1960
01:03:09,280 --> 01:03:10,079
can see that because

1961
01:03:10,079 --> 01:03:11,200
most of the time actually in this

1962
01:03:11,200 --> 01:03:14,950
application is spent in the kernel

1963
01:03:14,960 --> 01:03:16,960
so first question is like is linux even

1964
01:03:16,960 --> 01:03:18,559
or is biscuit even in the

1965
01:03:18,559 --> 01:03:21,039
neighborhood of you know production call

1966
01:03:21,039 --> 01:03:21,760
the uh

1967
01:03:21,760 --> 01:03:24,799
kernel or industrial quality kernel and

1968
01:03:24,799 --> 01:03:26,400
so what we did we compared the apps you

1969
01:03:26,400 --> 01:03:29,280
know through biscuit and linux

1970
01:03:29,280 --> 01:03:31,839
for linux we used 4.9 linux it's a

1971
01:03:31,839 --> 01:03:33,200
little bit out of date now because the

1972
01:03:33,200 --> 01:03:34,240
papers of course are

1973
01:03:34,240 --> 01:03:36,559
a couple of years old again but of

1974
01:03:36,559 --> 01:03:38,160
course when we linux we had to disable

1975
01:03:38,160 --> 01:03:39,839
all kinds of features that

1976
01:03:39,839 --> 01:03:42,400
uh biscuit uses or doesn't provide i

1977
01:03:42,400 --> 01:03:43,200
mean so like

1978
01:03:43,200 --> 01:03:45,440
page table isolation reptilian you know

1979
01:03:45,440 --> 01:03:46,559
all kinds of you know

1980
01:03:46,559 --> 01:03:48,240
long lists of features that interaction

1981
01:03:48,240 --> 01:03:51,119
disco doesn't provide norix36 provides

1982
01:03:51,119 --> 01:03:52,720
and we disable them linux to make the

1983
01:03:52,720 --> 01:03:54,720
comparison as fair as possible

1984
01:03:54,720 --> 01:03:56,079
and of course you know some features are

1985
01:03:56,079 --> 01:03:57,760
hard to disable and you know

1986
01:03:57,760 --> 01:04:00,000
we were not able to disable those but

1987
01:04:00,000 --> 01:04:01,440
you know we tried to get as close as

1988
01:04:01,440 --> 01:04:02,799
possible

1989
01:04:02,799 --> 01:04:04,319
and then you know we measured basically

1990
01:04:04,319 --> 01:04:06,720
the throughput and you know as you can

1991
01:04:06,720 --> 01:04:07,920
see you know the

1992
01:04:07,920 --> 01:04:10,960
biscuit is almost always slower

1993
01:04:10,960 --> 01:04:14,079
uh was always slower than linux uh

1994
01:04:14,079 --> 01:04:15,680
you know for mailbench you know it's

1995
01:04:15,680 --> 01:04:17,280
about to get whatever 10

1996
01:04:17,280 --> 01:04:19,280
on ngx gets a little bit more you know

1997
01:04:19,280 --> 01:04:21,839
the red is a little bit of 10 15 percent

1998
01:04:21,839 --> 01:04:23,039
but you should just use these numbers

1999
01:04:23,039 --> 01:04:25,440
very very grain salt right because

2000
01:04:25,440 --> 01:04:28,640
uh you know they're not identical uh and

2001
01:04:28,640 --> 01:04:30,720
it's not an apples to apples comparison

2002
01:04:30,720 --> 01:04:32,079
uh but they're like two sort of first

2003
01:04:32,079 --> 01:04:34,400
order you know they're roughly in the

2004
01:04:34,400 --> 01:04:35,839
same ballpark at least you know they're

2005
01:04:35,839 --> 01:04:38,480
not like 2x 3x 4x or 10x off

2006
01:04:38,480 --> 01:04:41,359
and so you know maybe it is worthwhile

2007
01:04:41,359 --> 01:04:42,799
to actually you know be able to do and

2008
01:04:42,799 --> 01:04:43,680
actually

2009
01:04:43,680 --> 01:04:45,359
you know to draw some conclusions out of

2010
01:04:45,359 --> 01:04:48,630
it

2011
01:04:48,640 --> 01:04:51,680
so um

2012
01:04:51,680 --> 01:04:53,200
so then we sort of looked at like you

2013
01:04:53,200 --> 01:04:55,039
know we looked basically profiled the

2014
01:04:55,039 --> 01:04:56,079
code and tried to

2015
01:04:56,079 --> 01:04:58,799
bucket you know the cycles uh that were

2016
01:04:58,799 --> 01:05:00,240
spent by the code and

2017
01:05:00,240 --> 01:05:01,760
particularly we're looking at like now

2018
01:05:01,760 --> 01:05:03,119
which cycles were actually in the

2019
01:05:03,119 --> 01:05:03,920
garbage collector

2020
01:05:03,920 --> 01:05:05,520
which cycles were actually in the

2021
01:05:05,520 --> 01:05:08,160
prologue of function calls uh

2022
01:05:08,160 --> 01:05:10,319
and the prologue actually in go does a

2023
01:05:10,319 --> 01:05:12,000
bunch of work you know to ensure

2024
01:05:12,000 --> 01:05:13,520
that the stack is large enough so you

2025
01:05:13,520 --> 01:05:15,039
don't run off to stack

2026
01:05:15,039 --> 01:05:17,760
uh write various cycles this is actually

2027
01:05:17,760 --> 01:05:18,240
uh

2028
01:05:18,240 --> 01:05:20,720
when in garbage collection mode you know

2029
01:05:20,720 --> 01:05:21,680
the

2030
01:05:21,680 --> 01:05:22,960
garbage collector turns on right

2031
01:05:22,960 --> 01:05:24,960
barriers

2032
01:05:24,960 --> 01:05:27,760
to basically track pointers between uh

2033
01:05:27,760 --> 01:05:29,280
different spaces

2034
01:05:29,280 --> 01:05:31,760
um and the safety cycles you know which

2035
01:05:31,760 --> 01:05:33,039
are safety cycles are

2036
01:05:33,039 --> 01:05:37,039
the cycles spent on

2037
01:05:37,039 --> 01:05:39,280
rebound checks and things like that and

2038
01:05:39,280 --> 01:05:42,390
no appointed checks

2039
01:05:42,400 --> 01:05:44,960
and so if you look at these applications

2040
01:05:44,960 --> 01:05:47,039
you know here are the numbers

2041
01:05:47,039 --> 01:05:48,880
so three percent of the execution time

2042
01:05:48,880 --> 01:05:50,640
was actually spent in sort of gc

2043
01:05:50,640 --> 01:05:53,680
cycles and i'll talk a little bit about

2044
01:05:53,680 --> 01:05:56,960
why that's low um but you know there is

2045
01:05:56,960 --> 01:05:58,000
the case that the card's collector was

2046
01:05:58,000 --> 01:05:58,480
running

2047
01:05:58,480 --> 01:06:00,319
while running these applications so it's

2048
01:06:00,319 --> 01:06:01,760
not the case that we measured the

2049
01:06:01,760 --> 01:06:03,039
applications you know we get so much

2050
01:06:03,039 --> 01:06:04,480
memory that you know just could run

2051
01:06:04,480 --> 01:06:06,559
without after half of running the

2052
01:06:06,559 --> 01:06:09,440
uh the garbage collector uh surprisingly

2053
01:06:09,440 --> 01:06:10,960
actually the prologue cycles turned out

2054
01:06:10,960 --> 01:06:11,920
to be the highest

2055
01:06:11,920 --> 01:06:13,520
uh and this is basically you know the

2056
01:06:13,520 --> 01:06:15,200
way they the scheme that we're

2057
01:06:15,200 --> 01:06:17,599
using that time for uh checking what the

2058
01:06:17,599 --> 01:06:19,119
kernel stack or the stack of the threat

2059
01:06:19,119 --> 01:06:19,599
needed

2060
01:06:19,599 --> 01:06:21,760
or go routine needed to be grown or not

2061
01:06:21,760 --> 01:06:23,039
and this is something that actually you

2062
01:06:23,039 --> 01:06:24,240
know the go

2063
01:06:24,240 --> 01:06:25,920
desires that point in a thought that is

2064
01:06:25,920 --> 01:06:27,680
probably easier to get lower

2065
01:06:27,680 --> 01:06:29,680
uh very little time actually barriers

2066
01:06:29,680 --> 01:06:31,280
and you know so two to three percent you

2067
01:06:31,280 --> 01:06:32,480
know in the

2068
01:06:32,480 --> 01:06:36,160
uh safety cycles uh and so in some sense

2069
01:06:36,160 --> 01:06:36,880
you know the

2070
01:06:36,880 --> 01:06:38,799
this is good news you know not uh you

2071
01:06:38,799 --> 01:06:39,920
know the tax is not

2072
01:06:39,920 --> 01:06:42,640
you know gigantic uh of course this

2073
01:06:42,640 --> 01:06:43,839
number could be much higher

2074
01:06:43,839 --> 01:06:44,960
you know because this is completely

2075
01:06:44,960 --> 01:06:47,119
dependent on how many

2076
01:06:47,119 --> 01:06:49,839
uh how big you know the heap is or light

2077
01:06:49,839 --> 01:06:50,160
and

2078
01:06:50,160 --> 01:06:51,920
how big the live number of live objects

2079
01:06:51,920 --> 01:06:53,119
is because the garbage collector will

2080
01:06:53,119 --> 01:06:55,039
have to trace all the live objects to

2081
01:06:55,039 --> 01:06:56,480
actually determine which objects are not

2082
01:06:56,480 --> 01:06:57,520
like

2083
01:06:57,520 --> 01:06:59,920
and so if you know there's a lot of live

2084
01:06:59,920 --> 01:07:01,200
objects you know the garbage collector

2085
01:07:01,200 --> 01:07:02,640
will have to trace more objects

2086
01:07:02,640 --> 01:07:04,319
and so it's completely sort of linear

2087
01:07:04,319 --> 01:07:07,280
with the number of live objects

2088
01:07:07,280 --> 01:07:09,680
so we did some other experiments let me

2089
01:07:09,680 --> 01:07:11,119
zoom ahead a little bit

2090
01:07:11,119 --> 01:07:13,200
where we basically i allocated a ton of

2091
01:07:13,200 --> 01:07:15,680
light data like a 2 million imb notes

2092
01:07:15,680 --> 01:07:17,760
think about this as 2 million eye notes

2093
01:07:17,760 --> 01:07:19,760
and then free the amount of sort of

2094
01:07:19,760 --> 01:07:21,680
head room or like change the amount of

2095
01:07:21,680 --> 01:07:23,760
headroom that the garbage collector has

2096
01:07:23,760 --> 01:07:24,400
you know for

2097
01:07:24,400 --> 01:07:27,119
free memory and then impact and then

2098
01:07:27,119 --> 01:07:29,119
measure the the cost

2099
01:07:29,119 --> 01:07:31,119
so this is the table here so we have

2100
01:07:31,119 --> 01:07:33,520
like 640 megabytes of light data

2101
01:07:33,520 --> 01:07:34,960
and then there's we run it with

2102
01:07:34,960 --> 01:07:37,039
different memory sizes and so

2103
01:07:37,039 --> 01:07:39,680
one says case there are 320 megabytes of

2104
01:07:39,680 --> 01:07:42,000
data so the ratio of life to phase two

2105
01:07:42,000 --> 01:07:44,960
and you see that in that case uh you

2106
01:07:44,960 --> 01:07:45,839
know go doesn't

2107
01:07:45,839 --> 01:07:47,359
do it a great imputation or search

2108
01:07:47,359 --> 01:07:48,720
overhead for garbage collector because

2109
01:07:48,720 --> 01:07:50,079
you know the guard selector needs to run

2110
01:07:50,079 --> 01:07:51,359
a lot you know because it doesn't have

2111
01:07:51,359 --> 01:07:52,960
much headroom

2112
01:07:52,960 --> 01:07:55,200
but you know if you basically if the

2113
01:07:55,200 --> 01:07:56,000
free memory is about

2114
01:07:56,000 --> 01:07:57,440
twice you know you could buy enough

2115
01:07:57,440 --> 01:07:58,880
memories the free members twice you know

2116
01:07:58,880 --> 01:08:00,240
that of the life memory

2117
01:08:00,240 --> 01:08:02,160
then the garbage collection on overhead

2118
01:08:02,160 --> 01:08:03,680
is not actually that crazy it's like in

2119
01:08:03,680 --> 01:08:05,839
the nine percent uh range

2120
01:08:05,839 --> 01:08:07,760
so basically to keep the gc overhead

2121
01:08:07,760 --> 01:08:09,599
like sort of a roughly one

2122
01:08:09,599 --> 01:08:11,680
around below ten percent you need about

2123
01:08:11,680 --> 01:08:13,920
you know three times the heap size

2124
01:08:13,920 --> 01:08:17,040
uh in terms of physical memory

2125
01:08:17,040 --> 01:08:23,430
uh any questions about this

2126
01:08:23,440 --> 01:08:26,719
um i had a question about the right

2127
01:08:26,719 --> 01:08:27,600
barriers

2128
01:08:27,600 --> 01:08:31,440
what are those do you is it like you

2129
01:08:31,440 --> 01:08:34,560
set some permissions okay

2130
01:08:34,560 --> 01:08:36,239
no it's not uh so if you i don't know if

2131
01:08:36,239 --> 01:08:38,159
you remember the lecture from a little

2132
01:08:38,159 --> 01:08:39,359
while ago the kind

2133
01:08:39,359 --> 01:08:42,000
appellant paper uh paper where we talked

2134
01:08:42,000 --> 01:08:42,719
about

2135
01:08:42,719 --> 01:08:45,759
the two and from spaces and oh

2136
01:08:45,759 --> 01:08:48,480
yeah garbage collector runs then uh you

2137
01:08:48,480 --> 01:08:49,920
have to check whether the pointers in

2138
01:08:49,920 --> 01:08:51,359
the from space right because it's in the

2139
01:08:51,359 --> 01:08:53,359
from space you have to copy it

2140
01:08:53,359 --> 01:08:55,679
uh and basically that the bright barrier

2141
01:08:55,679 --> 01:08:57,679
is very similar

2142
01:08:57,679 --> 01:08:59,440
that is the same sort of type idea where

2143
01:08:59,440 --> 01:09:00,799
you need to check every

2144
01:09:00,799 --> 01:09:02,400
uh pointer to see if actually it

2145
01:09:02,400 --> 01:09:04,080
actually uh points in

2146
01:09:04,080 --> 01:09:05,759
space that actually you need to guard

2147
01:09:05,759 --> 01:09:07,279
collect

2148
01:09:07,279 --> 01:09:11,669
and that's the right barrier

2149
01:09:11,679 --> 01:09:15,120
sorry so like the free memory

2150
01:09:15,120 --> 01:09:17,040
what is what is it exactly like how does

2151
01:09:17,040 --> 01:09:19,679
it work that the life is more than free

2152
01:09:19,679 --> 01:09:22,719
all right okay so you buy some amount of

2153
01:09:22,719 --> 01:09:23,759
memory

2154
01:09:23,759 --> 01:09:25,440
and live memory is actually memory that

2155
01:09:25,440 --> 01:09:27,040
was used by these v notes

2156
01:09:27,040 --> 01:09:28,480
and then there was another free under 20

2157
01:09:28,480 --> 01:09:30,480
megabyte that was just free

2158
01:09:30,480 --> 01:09:32,400
and so when this application allocated

2159
01:09:32,400 --> 01:09:33,759
more you know v notes

2160
01:09:33,759 --> 01:09:35,440
they first came out of the free memory

2161
01:09:35,440 --> 01:09:36,960
until the free memory is full accord and

2162
01:09:36,960 --> 01:09:37,440
then

2163
01:09:37,440 --> 01:09:38,880
concurrently the garbage selector was

2164
01:09:38,880 --> 01:09:41,279
running and

2165
01:09:41,279 --> 01:09:43,359
uh and so we run it in like three

2166
01:09:43,359 --> 01:09:44,960
configurations in one configuration

2167
01:09:44,960 --> 01:09:46,319
basically the amount of three members

2168
01:09:46,319 --> 01:09:46,799
twice

2169
01:09:46,799 --> 01:09:49,920
as the sort of the life memory

2170
01:09:49,920 --> 01:09:50,880
and so that means that the garbage

2171
01:09:50,880 --> 01:09:52,880
collector has a lot of sort of headroom

2172
01:09:52,880 --> 01:09:54,480
to do sort of concurrently

2173
01:09:54,480 --> 01:09:56,719
while running with the application and

2174
01:09:56,719 --> 01:09:58,159
if there's a lot of headroom

2175
01:09:58,159 --> 01:09:59,920
uh in this case we're in free memory

2176
01:09:59,920 --> 01:10:01,040
then you know the garbage collection

2177
01:10:01,040 --> 01:10:03,199
overheads are not that high

2178
01:10:03,199 --> 01:10:07,440
or they're around 10 instead of 34

2179
01:10:07,440 --> 01:10:09,360
okay i see i see thank you you think

2180
01:10:09,360 --> 01:10:10,560
about it like there's a little bit of

2181
01:10:10,560 --> 01:10:11,040
slack

2182
01:10:11,040 --> 01:10:12,000
you know sort of for the garbage

2183
01:10:12,000 --> 01:10:14,400
collector to do its work

2184
01:10:14,400 --> 01:10:17,440
right i thought that it's like total 320

2185
01:10:17,440 --> 01:10:19,040
and i was confused no no the total is

2186
01:10:19,040 --> 01:10:21,120
320 plus you know 640.

2187
01:10:21,120 --> 01:10:24,640
and my last line is 640 plus 1280.

2188
01:10:24,640 --> 01:10:30,400
okay thank you um

2189
01:10:30,400 --> 01:10:33,520
i'm going to skip this um

2190
01:10:33,520 --> 01:10:35,600
actually let me talk a little bit of

2191
01:10:35,600 --> 01:10:37,760
pauses you know this is a

2192
01:10:37,760 --> 01:10:39,360
the go garbage collector is a concurrent

2193
01:10:39,360 --> 01:10:41,520
garbage collector and with short pauses

2194
01:10:41,520 --> 01:10:44,719
uh it stops the world for a very short

2195
01:10:44,719 --> 01:10:46,320
period of time basically to enable right

2196
01:10:46,320 --> 01:10:47,760
barriers and then basically

2197
01:10:47,760 --> 01:10:50,000
the application keep on running while

2198
01:10:50,000 --> 01:10:51,120
the garbage selector doesn't

2199
01:10:51,120 --> 01:10:54,159
work and it's incremental as uh like the

2200
01:10:54,159 --> 01:10:55,840
one that we discussed a couple weeks ago

2201
01:10:55,840 --> 01:10:56,159
where

2202
01:10:56,159 --> 01:10:58,400
basically every call to neo does a

2203
01:10:58,400 --> 01:11:00,640
little bit of garbage selection work

2204
01:11:00,640 --> 01:11:01,840
and so every time that you do a little

2205
01:11:01,840 --> 01:11:02,960
bit of garbage collection work you know

2206
01:11:02,960 --> 01:11:04,000
there's some some delay

2207
01:11:04,000 --> 01:11:06,239
you know that's being cost correct and

2208
01:11:06,239 --> 01:11:07,520
so we measured

2209
01:11:07,520 --> 01:11:10,640
you know the uh we took one application

2210
01:11:10,640 --> 01:11:12,159
and looked at the sort of the maximum

2211
01:11:12,159 --> 01:11:14,400
pause time uh so the maximum time that

2212
01:11:14,400 --> 01:11:16,000
an application could be stopped you know

2213
01:11:16,000 --> 01:11:16,480
because the

2214
01:11:16,480 --> 01:11:19,040
guard's collector needs to do some work

2215
01:11:19,040 --> 01:11:19,840
and

2216
01:11:19,840 --> 01:11:22,239
it turned out to be you know the max

2217
01:11:22,239 --> 01:11:25,440
single pass you know 150 microseconds

2218
01:11:25,440 --> 01:11:27,199
that's in the case of the web server

2219
01:11:27,199 --> 01:11:28,800
that was using the tcp stack and

2220
01:11:28,800 --> 01:11:29,760
basically

2221
01:11:29,760 --> 01:11:31,760
uh a large part of the tcp connection

2222
01:11:31,760 --> 01:11:33,040
table needed to be marked

2223
01:11:33,040 --> 01:11:35,120
you know before you know continuing and

2224
01:11:35,120 --> 01:11:38,000
that took 150 microseconds

2225
01:11:38,000 --> 01:11:41,360
the maximum total pass time for a single

2226
01:11:41,360 --> 01:11:44,560
uh ngx or an http request is the sum

2227
01:11:44,560 --> 01:11:46,320
of the number of you know single passes

2228
01:11:46,320 --> 01:11:48,480
and the maximum pass time in total for a

2229
01:11:48,480 --> 01:11:49,679
single request

2230
01:11:49,679 --> 01:11:52,560
was 582 microseconds so basically when

2231
01:11:52,560 --> 01:11:52,960
the

2232
01:11:52,960 --> 01:11:55,520
request comes into the machine uh during

2233
01:11:55,520 --> 01:11:56,960
you know

2234
01:11:56,960 --> 01:11:58,880
there was a total delay of 582

2235
01:11:58,880 --> 01:12:00,320
microseconds to actually execute that

2236
01:12:00,320 --> 01:12:01,840
request

2237
01:12:01,840 --> 01:12:05,600
um and uh and it just happened very very

2238
01:12:05,600 --> 01:12:07,600
seldom you know only you know 0.3

2239
01:12:07,600 --> 01:12:08,800
percent of the requested times actually

2240
01:12:08,800 --> 01:12:09,280
had

2241
01:12:09,280 --> 01:12:12,320
a delay of more than 100 microseconds

2242
01:12:12,320 --> 01:12:14,880
um and so you know that's not good if

2243
01:12:14,880 --> 01:12:16,640
you're trying to achieve like

2244
01:12:16,640 --> 01:12:20,159
an sla or uh

2245
01:12:20,159 --> 01:12:22,000
where basically the longest retirement

2246
01:12:22,000 --> 01:12:24,239
request uh takes you know is

2247
01:12:24,239 --> 01:12:27,280
small uh but you know the if you look at

2248
01:12:27,280 --> 01:12:27,920
you know

2249
01:12:27,920 --> 01:12:29,520
google papers about like in the tailored

2250
01:12:29,520 --> 01:12:31,120
scale like you know how long the

2251
01:12:31,120 --> 01:12:33,360
longest request takes uh you know

2252
01:12:33,360 --> 01:12:34,800
they're talking about the new order of

2253
01:12:34,800 --> 01:12:35,920
you know tens of milliseconds or

2254
01:12:35,920 --> 01:12:37,760
milliseconds to 10 milliseconds

2255
01:12:37,760 --> 01:12:41,120
and so uh probably the programs that

2256
01:12:41,120 --> 01:12:42,640
uh these particular programs that

2257
01:12:42,640 --> 01:12:44,320
actually have a past time with maximum

2258
01:12:44,320 --> 01:12:46,400
price to pass number 582

2259
01:12:46,400 --> 01:12:47,679
microseconds is sort of within the

2260
01:12:47,679 --> 01:12:50,000
budget uh you know it's not ideal but

2261
01:12:50,000 --> 01:12:51,280
you know it's not not crazy

2262
01:12:51,280 --> 01:12:53,120
and so that basically says that they're

2263
01:12:53,120 --> 01:12:54,960
actually the

2264
01:12:54,960 --> 01:12:56,640
real what this basically says that they

2265
01:12:56,640 --> 01:12:58,239
know the go designers you know did

2266
01:12:58,239 --> 01:12:59,840
actually a terribly good job of actually

2267
01:12:59,840 --> 01:13:02,000
implementing their garbage collector

2268
01:13:02,000 --> 01:13:04,480
or impressively good job and this is one

2269
01:13:04,480 --> 01:13:05,840
of the things that we've noticed you

2270
01:13:05,840 --> 01:13:07,280
know while doing this project like every

2271
01:13:07,280 --> 01:13:09,199
time we upgraded the go run time

2272
01:13:09,199 --> 01:13:10,960
to the next runtime it came with a

2273
01:13:10,960 --> 01:13:12,080
better garbage collector and actually

2274
01:13:12,080 --> 01:13:15,830
these numbers got better and better

2275
01:13:15,840 --> 01:13:19,520
um okay one more sort of technical

2276
01:13:19,520 --> 01:13:20,560
detail that i want to

2277
01:13:20,560 --> 01:13:23,600
uh go over and uh so far

2278
01:13:23,600 --> 01:13:25,040
you know like the first comparison

2279
01:13:25,040 --> 01:13:26,960
between linux and biscuit you know it's

2280
01:13:26,960 --> 01:13:30,560
not really fair because biscuit and

2281
01:13:30,560 --> 01:13:31,920
linux implement slightly different

2282
01:13:31,920 --> 01:13:33,600
features so we did one more

2283
01:13:33,600 --> 01:13:35,199
experiment where we basically tried to

2284
01:13:35,199 --> 01:13:37,360
code up two kernel paths

2285
01:13:37,360 --> 01:13:40,719
completely identical both in uh linux

2286
01:13:40,719 --> 01:13:41,040
and

2287
01:13:41,040 --> 01:13:44,239
in uh like in c and in go and so we

2288
01:13:44,239 --> 01:13:46,080
looked at the

2289
01:13:46,080 --> 01:13:48,560
code path and sort of verified that

2290
01:13:48,560 --> 01:13:49,600
basically you know

2291
01:13:49,600 --> 01:13:51,120
it implements exactly the same thing and

2292
01:13:51,120 --> 01:13:52,960
we looked at the assembly instructions

2293
01:13:52,960 --> 01:13:55,120
to really see what what the differences

2294
01:13:55,120 --> 01:13:56,640
are they're going to be some differences

2295
01:13:56,640 --> 01:13:57,360
right because

2296
01:13:57,360 --> 01:13:59,760
goal is going to pay these safety checks

2297
01:13:59,760 --> 01:14:01,760
but look just in terms of

2298
01:14:01,760 --> 01:14:03,440
basic operation that at least the code

2299
01:14:03,440 --> 01:14:05,040
paths are sort of identical in terms of

2300
01:14:05,040 --> 01:14:07,360
functionality

2301
01:14:07,360 --> 01:14:09,920
and we did that for two code pass you

2302
01:14:09,920 --> 01:14:11,280
know this is difficult to do it was a

2303
01:14:11,280 --> 01:14:13,280
painstaking

2304
01:14:13,280 --> 01:14:15,360
that we did for two or cody did actually

2305
01:14:15,360 --> 01:14:18,000
for two and then we compared them

2306
01:14:18,000 --> 01:14:20,000
uh and so here's the results from one of

2307
01:14:20,000 --> 01:14:21,840
them this is a pipe ping-pong

2308
01:14:21,840 --> 01:14:23,120
you know sort of test you know your

2309
01:14:23,120 --> 01:14:25,120
ping-ponging a bite across the pipe

2310
01:14:25,120 --> 01:14:26,640
and we just looked at the code path

2311
01:14:26,640 --> 01:14:28,320
through the kernel to actually get that

2312
01:14:28,320 --> 01:14:29,920
byte from one then to the pipe to the

2313
01:14:29,920 --> 01:14:31,760
other end to the pipe

2314
01:14:31,760 --> 01:14:35,760
um and uh you know the third amount of

2315
01:14:35,760 --> 01:14:37,920
code in go is like this is one point

2316
01:14:37,920 --> 01:14:39,040
thousand lights code

2317
01:14:39,040 --> 01:14:41,280
and see it's one point eight thousand

2318
01:14:41,280 --> 01:14:42,480
lines of code

2319
01:14:42,480 --> 01:14:44,400
there's no allocation no gc so those

2320
01:14:44,400 --> 01:14:45,520
things are just

2321
01:14:45,520 --> 01:14:48,239
uh differ we also looked at like the run

2322
01:14:48,239 --> 01:14:50,080
time like where's the most time spent

2323
01:14:50,080 --> 01:14:52,560
and in both coast paths you know that

2324
01:14:52,560 --> 01:14:54,400
same top ten instructions showed up so

2325
01:14:54,400 --> 01:14:56,159
we sort of some confidence that the code

2326
01:14:56,159 --> 01:14:58,000
paths really are close

2327
01:14:58,000 --> 01:15:00,159
close as you can get to make them

2328
01:15:00,159 --> 01:15:01,280
similar

2329
01:15:01,280 --> 01:15:02,800
and then we looked at basically the

2330
01:15:02,800 --> 01:15:04,080
amount of operations you can do per

2331
01:15:04,080 --> 01:15:04,560
second

2332
01:15:04,560 --> 01:15:07,360
and as you see here you know basically

2333
01:15:07,360 --> 01:15:08,080
you know the go

2334
01:15:08,080 --> 01:15:10,719
is a little bit slower than the the c

2335
01:15:10,719 --> 01:15:11,920
implementation

2336
01:15:11,920 --> 01:15:14,960
and you know the ratio is about 1.5 15

2337
01:15:14,960 --> 01:15:18,800
slower and uh and that's sort of

2338
01:15:18,800 --> 01:15:20,400
you know if you look at the pro local

2339
01:15:20,400 --> 01:15:21,760
safety checks you know these are all the

2340
01:15:21,760 --> 01:15:23,120
instructions that the c code does not

2341
01:15:23,120 --> 01:15:24,080
have to execute

2342
01:15:24,080 --> 01:15:25,199
you know they turned out to be sort of

2343
01:15:25,199 --> 01:15:27,520
16 more uh

2344
01:15:27,520 --> 01:15:29,920
uh assembly instructions and so that

2345
01:15:29,920 --> 01:15:31,280
sort of roughly

2346
01:15:31,280 --> 01:15:33,679
sort of makes sense uh so you know the

2347
01:15:33,679 --> 01:15:36,320
main conclusion is you know go is slower

2348
01:15:36,320 --> 01:15:38,480
but pretty competitive you know not not

2349
01:15:38,480 --> 01:15:40,480
ridiculously slower

2350
01:15:40,480 --> 01:15:42,159
and that seems in line with the early

2351
01:15:42,159 --> 01:15:44,239
results of where we did this uh linux to

2352
01:15:44,239 --> 01:15:47,750
biscuit comparisons directly

2353
01:15:47,760 --> 01:15:50,880
okay so let me zoom a little bit further

2354
01:15:50,880 --> 01:15:53,120
uh let me skip this because i want to

2355
01:15:53,120 --> 01:15:54,400
talk a little bit about

2356
01:15:54,400 --> 01:15:56,320
uh this sort of the question that we

2357
01:15:56,320 --> 01:15:57,679
asked in the beginning you know whether

2358
01:15:57,679 --> 01:15:59,120
should one use a high level loan for a

2359
01:15:59,120 --> 01:16:00,719
new kernel

2360
01:16:00,719 --> 01:16:03,360
and uh maybe you're like i mean instead

2361
01:16:03,360 --> 01:16:04,640
of answering i have some thoughts about

2362
01:16:04,640 --> 01:16:06,000
this here on this slide you know there

2363
01:16:06,000 --> 01:16:07,440
were some conclusions that we draw and

2364
01:16:07,440 --> 01:16:08,880
you know it's not a crisp conclusion you

2365
01:16:08,880 --> 01:16:10,640
know there's some considerations

2366
01:16:10,640 --> 01:16:12,080
so maybe to take a step back it's just

2367
01:16:12,080 --> 01:16:14,719
like asking yourself the question like

2368
01:16:14,719 --> 01:16:16,159
what would you have preferred you know

2369
01:16:16,159 --> 01:16:18,320
would you prefer to write you know xv6

2370
01:16:18,320 --> 01:16:19,360
in the labs in c

2371
01:16:19,360 --> 01:16:21,199
or would you prefer to use a high level

2372
01:16:21,199 --> 01:16:22,560
limits for example like

2373
01:16:22,560 --> 01:16:25,360
go and particularly answering this

2374
01:16:25,360 --> 01:16:26,320
question

2375
01:16:26,320 --> 01:16:28,159
what kind of bugs would you have avoided

2376
01:16:28,159 --> 01:16:30,320
and you know maybe you had to have some

2377
01:16:30,320 --> 01:16:30,800
time

2378
01:16:30,800 --> 01:16:32,239
during this lecture to think about like

2379
01:16:32,239 --> 01:16:34,320
what bugs you had and i would love to

2380
01:16:34,320 --> 01:16:34,880
hear

2381
01:16:34,880 --> 01:16:38,159
you know what your experience

2382
01:16:38,159 --> 01:16:40,880
how you think uh switching to a

2383
01:16:40,880 --> 01:16:42,239
high-level lens would have changed your

2384
01:16:42,239 --> 01:16:44,950
experience

2385
01:16:44,960 --> 01:16:46,480
or if you have any thoughts on this

2386
01:16:46,480 --> 01:16:51,030
question at all

2387
01:16:51,040 --> 01:16:55,120
so let me boss you for a little bit so

2388
01:16:55,120 --> 01:16:55,760
you can

2389
01:16:55,760 --> 01:16:59,040
think about this and maybe chime in

2390
01:16:59,040 --> 01:17:01,040
i have had a couple of times when i did

2391
01:17:01,040 --> 01:17:03,360
the the thing where i create an object

2392
01:17:03,360 --> 01:17:04,480
in a function

2393
01:17:04,480 --> 01:17:06,880
and then i return a pointer to it and

2394
01:17:06,880 --> 01:17:08,719
then i do stuff with the pointer

2395
01:17:08,719 --> 01:17:10,640
and then i realize that the object is

2396
01:17:10,640 --> 01:17:12,800
gone yeah so this is a classic example

2397
01:17:12,800 --> 01:17:14,880
of a sort of use after free

2398
01:17:14,880 --> 01:17:18,239
case correct yeah

2399
01:17:18,239 --> 01:17:20,880
um the second time i realized it faster

2400
01:17:20,880 --> 01:17:22,239
than the first time

2401
01:17:22,239 --> 01:17:24,000
yeah that's definitely true we've seen

2402
01:17:24,000 --> 01:17:25,360
you a couple of times in those boxes

2403
01:17:25,360 --> 01:17:28,320
you get better at them any other

2404
01:17:28,320 --> 01:17:29,600
thoughts on this you know

2405
01:17:29,600 --> 01:17:33,120
all the experiences that people have had

2406
01:17:33,120 --> 01:17:36,080
think about your worst bugs or the bugs

2407
01:17:36,080 --> 01:17:38,640
that took the most time

2408
01:17:38,640 --> 01:17:40,320
would i let the language would have

2409
01:17:40,320 --> 01:17:43,189
helped

2410
01:17:43,199 --> 01:17:45,199
i think it definitely like like some of

2411
01:17:45,199 --> 01:17:47,040
the bugs were absolutely terrible to

2412
01:17:47,040 --> 01:17:47,679
deal with

2413
01:17:47,679 --> 01:17:50,159
but at the same time like in in this

2414
01:17:50,159 --> 01:17:51,280
context i

2415
01:17:51,280 --> 01:17:53,120
definitely appreciated having to work

2416
01:17:53,120 --> 01:17:55,280
with such a low-level language as c

2417
01:17:55,280 --> 01:17:57,520
because it helped me to really gain a

2418
01:17:57,520 --> 01:17:58,400
very

2419
01:17:58,400 --> 01:18:00,239
like a deep understanding of what's

2420
01:18:00,239 --> 01:18:02,239
actually going on inside the operating

2421
01:18:02,239 --> 01:18:02,960
system like

2422
01:18:02,960 --> 01:18:05,199
how it's working with memory like it it

2423
01:18:05,199 --> 01:18:06,960
it's definitely refreshing to

2424
01:18:06,960 --> 01:18:09,280
to like not have all of that abstracted

2425
01:18:09,280 --> 01:18:10,400
away and to actually

2426
01:18:10,400 --> 01:18:15,350
see exactly what's going on

2427
01:18:15,360 --> 01:18:17,840
that makes a lot of sense any other any

2428
01:18:17,840 --> 01:18:20,000
other people have opinions on this

2429
01:18:20,000 --> 01:18:23,280
um i think i also made

2430
01:18:23,280 --> 01:18:28,630
a lot of bugs in which i was

2431
01:18:28,640 --> 01:18:31,520
writing after the end of a string or

2432
01:18:31,520 --> 01:18:32,719
something like that

2433
01:18:32,719 --> 01:18:35,600
but then i wasn't getting any useful

2434
01:18:35,600 --> 01:18:37,040
feedback about it and then

2435
01:18:37,040 --> 01:18:39,120
very strange things happened that i

2436
01:18:39,120 --> 01:18:41,120
couldn't explain

2437
01:18:41,120 --> 01:18:44,480
um so yeah that better showed up in lab

2438
01:18:44,480 --> 01:18:46,080
one

2439
01:18:46,080 --> 01:18:47,360
where there was a bunch of strings

2440
01:18:47,360 --> 01:18:48,880
operations like when you're parsing

2441
01:18:48,880 --> 01:18:51,360
directories and things like that

2442
01:18:51,360 --> 01:18:54,960
it showed up in multiple apps okay okay

2443
01:18:54,960 --> 01:18:57,360
no i'm not surprised okay that's a great

2444
01:18:57,360 --> 01:18:58,960
example like you know the

2445
01:18:58,960 --> 01:19:00,320
it's very nice to actually have real

2446
01:19:00,320 --> 01:19:03,669
string objects

2447
01:19:03,679 --> 01:19:06,480
one thing on my end is that i i found

2448
01:19:06,480 --> 01:19:08,159
myself lacking whenever i needed

2449
01:19:08,159 --> 01:19:09,600
something like a map

2450
01:19:09,600 --> 01:19:12,000
and i just i cringed every time i needed

2451
01:19:12,000 --> 01:19:13,440
to do a for loop over

2452
01:19:13,440 --> 01:19:16,480
something and then find however i will

2453
01:19:16,480 --> 01:19:16,880
say

2454
01:19:16,880 --> 01:19:18,640
like coming from a high-level

2455
01:19:18,640 --> 01:19:20,640
programming background

2456
01:19:20,640 --> 01:19:22,560
this was my first real exposure to

2457
01:19:22,560 --> 01:19:24,880
something like c so going off of noah's

2458
01:19:24,880 --> 01:19:27,040
point it kind of helped me to understand

2459
01:19:27,040 --> 01:19:29,600
really what it means that like this code

2460
01:19:29,600 --> 01:19:31,120
that i'm writing is actually running on

2461
01:19:31,120 --> 01:19:32,640
the cpu and everything is from the

2462
01:19:32,640 --> 01:19:36,640
perspective of the cpu

2463
01:19:36,640 --> 01:19:41,910
any other

2464
01:19:41,920 --> 01:19:46,470
thoughts

2465
01:19:46,480 --> 01:19:47,920
oh i actually remember it was

2466
01:19:47,920 --> 01:19:50,719
specifically the difference between

2467
01:19:50,719 --> 01:19:53,760
cop safe string copy or just string

2468
01:19:53,760 --> 01:19:56,960
copy one of them was putting uh

2469
01:19:56,960 --> 01:19:59,840
was using the null terminator and that

2470
01:19:59,840 --> 01:20:01,920
was yeah

2471
01:20:01,920 --> 01:20:04,960
yep yeah a common c bug well so you know

2472
01:20:04,960 --> 01:20:06,880
first of all you know uh

2473
01:20:06,880 --> 01:20:08,719
thanks for the input uh of course we're

2474
01:20:08,719 --> 01:20:10,000
not going to change uh

2475
01:20:10,000 --> 01:20:12,880
xv6 to uh go or any high level limits

2476
01:20:12,880 --> 01:20:14,239
exactly for the reasons that you know i

2477
01:20:14,239 --> 01:20:15,440
think a number of you like no

2478
01:20:15,440 --> 01:20:18,719
uh meteor actually mentioned uh

2479
01:20:18,719 --> 01:20:20,800
go still hides too much and they're in

2480
01:20:20,800 --> 01:20:22,159
this particular class the whole purpose

2481
01:20:22,159 --> 01:20:23,360
is really trying to understand

2482
01:20:23,360 --> 01:20:23,920
everything

2483
01:20:23,920 --> 01:20:26,159
everything sort of between the cpu and

2484
01:20:26,159 --> 01:20:27,760
the system called interface

2485
01:20:27,760 --> 01:20:29,760
uh and so for example you go of course

2486
01:20:29,760 --> 01:20:30,880
you know heights threads

2487
01:20:30,880 --> 01:20:32,880
and you know in you know we don't want

2488
01:20:32,880 --> 01:20:34,239
to hide that we want to explain to you

2489
01:20:34,239 --> 01:20:36,000
actually how frets are implemented

2490
01:20:36,000 --> 01:20:39,280
and so uh we would not want to hide this

2491
01:20:39,280 --> 01:20:40,159
from you

2492
01:20:40,159 --> 01:20:42,159
so certainly future years you know of

2493
01:20:42,159 --> 01:20:44,320
actually six or uh this class will

2494
01:20:44,320 --> 01:20:46,480
keep on using c uh but like if you

2495
01:20:46,480 --> 01:20:48,000
implement a new kernel and

2496
01:20:48,000 --> 01:20:50,960
you know the the goal is not you know

2497
01:20:50,960 --> 01:20:52,480
educating you know students about

2498
01:20:52,480 --> 01:20:53,120
kernels

2499
01:20:53,120 --> 01:20:54,800
uh but you know the goal is to write

2500
01:20:54,800 --> 01:20:56,639
like a sort of a safe you know

2501
01:20:56,639 --> 01:20:58,400
high performance kernel you know there's

2502
01:20:58,400 --> 01:20:59,760
sort of you know some things you can

2503
01:20:59,760 --> 01:21:00,480
conclude from

2504
01:21:00,480 --> 01:21:02,239
the study that i've done that we've done

2505
01:21:02,239 --> 01:21:03,600
right

2506
01:21:03,600 --> 01:21:05,840
you know if memory or if performance is

2507
01:21:05,840 --> 01:21:07,600
really paramount you know you can't like

2508
01:21:07,600 --> 01:21:09,199
sacrifice 50

2509
01:21:09,199 --> 01:21:11,120
then you should probably you see if you

2510
01:21:11,120 --> 01:21:12,560
want to minimize memory use

2511
01:21:12,560 --> 01:21:15,280
you probably should see you see too if

2512
01:21:15,280 --> 01:21:16,639
safety is important or security is

2513
01:21:16,639 --> 01:21:17,760
important then probably the high level

2514
01:21:17,760 --> 01:21:19,520
language is the way to go

2515
01:21:19,520 --> 01:21:21,360
and probably in many cases performance

2516
01:21:21,360 --> 01:21:22,800
is merely important as opposed to

2517
01:21:22,800 --> 01:21:23,840
absolute you know

2518
01:21:23,840 --> 01:21:25,840
paramount and in many cases i think you

2519
01:21:25,840 --> 01:21:27,280
know high losing high level languages

2520
01:21:27,280 --> 01:21:28,560
are a perfectly reasonable thing to do

2521
01:21:28,560 --> 01:21:30,159
for a kernel

2522
01:21:30,159 --> 01:21:31,600
probably one thing i've learned or

2523
01:21:31,600 --> 01:21:33,199
probably you know

2524
01:21:33,199 --> 01:21:34,560
cody robin and i've learned from this

2525
01:21:34,560 --> 01:21:36,400
whole project is like whatever

2526
01:21:36,400 --> 01:21:37,600
programming language is a programming

2527
01:21:37,600 --> 01:21:39,360
language and you can use it to build

2528
01:21:39,360 --> 01:21:40,320
kernels you can build

2529
01:21:40,320 --> 01:21:42,320
user applications it's not really

2530
01:21:42,320 --> 01:21:43,679
standing anything in

2531
01:21:43,679 --> 01:21:50,709
really in the way

2532
01:21:50,719 --> 01:21:52,960
okay you know i think it's time to wrap

2533
01:21:52,960 --> 01:21:54,080
up

2534
01:21:54,080 --> 01:21:55,679
but you know if you uh have any more

2535
01:21:55,679 --> 01:21:57,360
questions you know free for you to hang

2536
01:21:57,360 --> 01:21:57,920
around

2537
01:21:57,920 --> 01:22:00,639
and ask them if you have to go somewhere

2538
01:22:00,639 --> 01:22:01,440
else

2539
01:22:01,440 --> 01:22:03,679
uh you know good luck with finishing the

2540
01:22:03,679 --> 01:22:04,719
map lab and

2541
01:22:04,719 --> 01:22:06,560
for those of you who have to are leaving

2542
01:22:06,560 --> 01:22:08,320
campus for thanksgiving

2543
01:22:08,320 --> 01:22:10,880
safe travels and well hope to see you

2544
01:22:10,880 --> 01:22:12,239
after thanksgiving in

2545
01:22:12,239 --> 01:22:17,590
monday's lecture after thanksgiving

2546
01:22:17,600 --> 01:22:21,920
thank you i was curious how did you

2547
01:22:21,920 --> 01:22:23,679
implement it like i said you are doing

2548
01:22:23,679 --> 01:22:25,440
that just on the hardware

2549
01:22:25,440 --> 01:22:28,239
so like when you start out how do you

2550
01:22:28,239 --> 01:22:29,920
start out

2551
01:22:29,920 --> 01:22:31,360
uh you know there's basically a little

2552
01:22:31,360 --> 01:22:34,080
shim code uh that sets up enough of the

2553
01:22:34,080 --> 01:22:36,480
hardware so that when biscuit you know

2554
01:22:36,480 --> 01:22:37,280
asks for

2555
01:22:37,280 --> 01:22:39,600
or when to go to a function the go

2556
01:22:39,600 --> 01:22:41,360
runtime ask for memory for the heap that

2557
01:22:41,360 --> 01:22:44,159
we can actually uh respond

2558
01:22:44,159 --> 01:22:47,600
uh that was one of the main things that

2559
01:22:47,600 --> 01:22:49,520
actually uh the go runtime actually

2560
01:22:49,520 --> 01:22:51,440
relies on

2561
01:22:51,440 --> 01:22:53,120
right i guess i was like you said that

2562
01:22:53,120 --> 01:22:54,480
you didn't

2563
01:22:54,480 --> 01:22:57,520
use a virtual machine for that so

2564
01:22:57,520 --> 01:22:58,960
we did of course you know we developed

2565
01:22:58,960 --> 01:23:00,810
okay motion development doesn't muck

2566
01:23:00,810 --> 01:23:03,440
[Laughter]

2567
01:23:03,440 --> 01:23:04,719
of course at the end we actually have to

2568
01:23:04,719 --> 01:23:06,560
get it running under our hardware that

2569
01:23:06,560 --> 01:23:08,000
also costs us a bunch of problems you

2570
01:23:08,000 --> 01:23:08,960
know because the boot loaders are

2571
01:23:08,960 --> 01:23:09,920
different you know there's a bunch of

2572
01:23:09,920 --> 01:23:10,960
boot code that you actually need to

2573
01:23:10,960 --> 01:23:12,080
write that you don't have to write if

2574
01:23:12,080 --> 01:23:13,600
you run it on tmu

2575
01:23:13,600 --> 01:23:16,239
uh and that kind of stuff but most of

2576
01:23:16,239 --> 01:23:17,679
the development is all done on tmu in

2577
01:23:17,679 --> 01:23:18,159
fact

2578
01:23:18,159 --> 01:23:19,360
you know if you want to hack a show

2579
01:23:19,360 --> 01:23:21,520
you're running biscuit on qmu

2580
01:23:21,520 --> 01:23:23,440
and it looks very simple to xv6 you know

2581
01:23:23,440 --> 01:23:24,639
the only thing it does like you know it

2582
01:23:24,639 --> 01:23:26,000
shows your prompt there's no window

2583
01:23:26,000 --> 01:23:27,280
system

2584
01:23:27,280 --> 01:23:30,880
nothing like that okay i see

2585
01:23:30,880 --> 01:23:32,719
so like what happens if you if you make

2586
01:23:32,719 --> 01:23:34,080
a mistake in the book

2587
01:23:34,080 --> 01:23:36,719
code uh it doesn't boot you know

2588
01:23:36,719 --> 01:23:37,840
basically nothing happens

2589
01:23:37,840 --> 01:23:40,880
you know it's completely nothing

2590
01:23:40,880 --> 01:23:44,239
how do you know ah

2591
01:23:44,239 --> 01:23:47,120
you will know because you know okay what

2592
01:23:47,120 --> 01:23:48,400
will happen is of course you don't see a

2593
01:23:48,400 --> 01:23:50,000
print statement like in xp6 work the

2594
01:23:50,000 --> 01:23:51,600
first thing we print is like you know

2595
01:23:51,600 --> 01:23:53,600
xv6 hello or something or

2596
01:23:53,600 --> 01:23:56,239
xc6 is booting uh you won't see anything

2597
01:23:56,239 --> 01:23:57,199
like that

2598
01:23:57,199 --> 01:24:00,239
and so you will see nothing and then

2599
01:24:00,239 --> 01:24:02,320
you know you have to track down and

2600
01:24:02,320 --> 01:24:05,520
guess you know what the problem might be

2601
01:24:05,520 --> 01:24:08,560
okay so you do it by looking

2602
01:24:08,560 --> 01:24:10,880
ah okay it's a little bit you can write

2603
01:24:10,880 --> 01:24:12,719
synchronously to the uart you know

2604
01:24:12,719 --> 01:24:15,040
you compute like you know stupid

2605
01:24:15,040 --> 01:24:16,159
characters and you see

2606
01:24:16,159 --> 01:24:17,600
put them in random places in the code

2607
01:24:17,600 --> 01:24:21,270
and hope that you see something

2608
01:24:21,280 --> 01:24:24,159
this is interesting thank you you know i

2609
01:24:24,159 --> 01:24:26,000
wanted to ask um

2610
01:24:26,000 --> 01:24:28,480
when you you so i know like you

2611
01:24:28,480 --> 01:24:29,199
implemented

2612
01:24:29,199 --> 01:24:32,159
the go some of the calls the go-run time

2613
01:24:32,159 --> 01:24:32,960
would make

2614
01:24:32,960 --> 01:24:35,199
um that you cannot make because you're

2615
01:24:35,199 --> 01:24:37,120
implementing the kernel itself

2616
01:24:37,120 --> 01:24:39,440
um is there any like did you just

2617
01:24:39,440 --> 01:24:41,440
implement just all of that in assembly

2618
01:24:41,440 --> 01:24:44,159
or did you say okay like some of this we

2619
01:24:44,159 --> 01:24:45,920
can still do and go like we can

2620
01:24:45,920 --> 01:24:47,840
bring go a bit closer and then do

2621
01:24:47,840 --> 01:24:49,600
assembly only what's necessary

2622
01:24:49,600 --> 01:24:51,520
or to just say like once the goal

2623
01:24:51,520 --> 01:24:52,800
runtime ends like

2624
01:24:52,800 --> 01:24:56,719
that's assembly uh that's where the 1500

2625
01:24:56,719 --> 01:24:58,639
lines of assembly came from

2626
01:24:58,639 --> 01:25:02,159
uh in biscuit you know that is basically

2627
01:25:02,159 --> 01:25:03,760
the code to sort of you know get

2628
01:25:03,760 --> 01:25:05,440
everything ready to be actually able to

2629
01:25:05,440 --> 01:25:08,320
run the go around time

2630
01:25:08,320 --> 01:25:09,280
now some of that we could have

2631
01:25:09,280 --> 01:25:10,800
implemented c but we didn't want to do

2632
01:25:10,800 --> 01:25:12,080
that because we didn't want to use any c

2633
01:25:12,080 --> 01:25:14,239
so we were in assembly

2634
01:25:14,239 --> 01:25:15,840
many of it actually requires assembly

2635
01:25:15,840 --> 01:25:18,320
because it's in the booting part

2636
01:25:18,320 --> 01:25:19,679
right but i guess some of the part

2637
01:25:19,679 --> 01:25:21,520
that's not the b so i'm i

2638
01:25:21,520 --> 01:25:23,679
i'm you know i know that some just you

2639
01:25:23,679 --> 01:25:24,719
cannot avoid

2640
01:25:24,719 --> 01:25:26,960
some boot code and assembly but could

2641
01:25:26,960 --> 01:25:27,840
you uh

2642
01:25:27,840 --> 01:25:29,440
could you have transformed some of the

2643
01:25:29,440 --> 01:25:31,120
assembly to go or did you go to the

2644
01:25:31,120 --> 01:25:32,159
absolute map

2645
01:25:32,159 --> 01:25:34,159
we did uh wrote a whole bunch of gold

2646
01:25:34,159 --> 01:25:35,440
that basically runs

2647
01:25:35,440 --> 01:25:39,040
uh very early on uh

2648
01:25:39,040 --> 01:25:40,480
and you know some of the gogos is quite

2649
01:25:40,480 --> 01:25:42,080
careful it doesn't do any memory

2650
01:25:42,080 --> 01:25:46,629
allocations

2651
01:25:46,639 --> 01:25:48,560
that makes sense we try to write as much

2652
01:25:48,560 --> 01:25:49,920
as possible you know i i

2653
01:25:49,920 --> 01:25:51,360
can like i have to look at the code

2654
01:25:51,360 --> 01:25:53,120
exactly you know to be able to answer

2655
01:25:53,120 --> 01:25:53,920
your uh

2656
01:25:53,920 --> 01:25:55,199
question specifically and you can look

2657
01:25:55,199 --> 01:25:58,400
at the git repo uh but you know that

2658
01:25:58,400 --> 01:26:00,400
uh yeah we tried to write everything and

2659
01:26:00,400 --> 01:26:03,430
go

2660
01:26:03,440 --> 01:26:05,280
and then one like kind of unrelated

2661
01:26:05,280 --> 01:26:06,840
small question i had

2662
01:26:06,840 --> 01:26:09,840
um what does go do with its go routines

2663
01:26:09,840 --> 01:26:11,760
that makes it possible to run like

2664
01:26:11,760 --> 01:26:14,000
hundred thousands of them

2665
01:26:14,000 --> 01:26:15,760
because you cannot just spin up a

2666
01:26:15,760 --> 01:26:18,159
hundred thousand p threads right

2667
01:26:18,159 --> 01:26:22,080
uh yeah it depends uh yeah okay so

2668
01:26:22,080 --> 01:26:24,320
i guess a lot longer and so the main

2669
01:26:24,320 --> 01:26:25,600
issue is that you know you

2670
01:26:25,600 --> 01:26:28,639
need to allocate a stack and uh

2671
01:26:28,639 --> 01:26:30,480
the go runtime actually allocates tax

2672
01:26:30,480 --> 01:26:32,320
incrementally and so grows them

2673
01:26:32,320 --> 01:26:33,120
dynamically

2674
01:26:33,120 --> 01:26:36,560
as you uh run your go go routine

2675
01:26:36,560 --> 01:26:38,400
uh this is where this prologue code is

2676
01:26:38,400 --> 01:26:40,239
for when you make a function call you'll

2677
01:26:40,239 --> 01:26:40,560
see

2678
01:26:40,560 --> 01:26:43,199
if there's enough space to actually make

2679
01:26:43,199 --> 01:26:44,880
the function call and if not it will

2680
01:26:44,880 --> 01:26:47,440
grow to stack dynamically for you

2681
01:26:47,440 --> 01:26:50,639
and often in frets implementations

2682
01:26:50,639 --> 01:26:53,840
uh allocating uh

2683
01:26:53,840 --> 01:26:55,280
threads a little bit more heavyweight

2684
01:26:55,280 --> 01:26:58,149
because uh

2685
01:26:58,159 --> 01:26:59,440
actually for example in linux you know

2686
01:26:59,440 --> 01:27:00,960
basically corresponds the corresponding

2687
01:27:00,960 --> 01:27:03,679
kernel thread is actually allocated too

2688
01:27:03,679 --> 01:27:04,320
and

2689
01:27:04,320 --> 01:27:08,709
they tend to be more heavyweight than

2690
01:27:08,719 --> 01:27:12,000
i see is the sketch is the scheduling of

2691
01:27:12,000 --> 01:27:13,920
all the go routines done completely in

2692
01:27:13,920 --> 01:27:14,880
user space

2693
01:27:14,880 --> 01:27:17,520
or does it help itself with some kernels

2694
01:27:17,520 --> 01:27:18,719
so

2695
01:27:18,719 --> 01:27:25,830
it's mostly done in user space

2696
01:27:25,840 --> 01:27:27,920
so the go runtime allocates a bunch of

2697
01:27:27,920 --> 01:27:29,520
kernel threats

2698
01:27:29,520 --> 01:27:32,080
uh you know they call them i think m

2699
01:27:32,080 --> 01:27:32,719
threads

2700
01:27:32,719 --> 01:27:35,199
and uh on top of that it implements the

2701
01:27:35,199 --> 01:27:37,360
go routines

2702
01:27:37,360 --> 01:27:39,679
oh so it's so it has like a couple

2703
01:27:39,679 --> 01:27:41,679
kernel threads that it shares to all go

2704
01:27:41,679 --> 01:27:43,760
routines based on which one's running

2705
01:27:43,760 --> 01:27:47,520
yes oh that makes a lot of sense yeah

2706
01:27:47,520 --> 01:27:50,800
is there uh like any c c plus plus

2707
01:27:50,800 --> 01:27:51,600
equivalent

2708
01:27:51,600 --> 01:27:53,679
like could you could you do something

2709
01:27:53,679 --> 01:27:54,960
like that to save

2710
01:27:54,960 --> 01:27:56,719
to save some memory yeah people have

2711
01:27:56,719 --> 01:27:58,159
done you know implemented like high

2712
01:27:58,159 --> 01:27:59,440
performance you know

2713
01:27:59,440 --> 01:28:02,159
c c libraries or uh threat libraries

2714
01:28:02,159 --> 01:28:03,199
that way you can create

2715
01:28:03,199 --> 01:28:04,800
like thousands of familiar threads or

2716
01:28:04,800 --> 01:28:06,239
millions of threads you know to

2717
01:28:06,239 --> 01:28:14,080
uh with similar style

2718
01:28:14,080 --> 01:28:16,239
okay uh you guys have a good break you

2719
01:28:16,239 --> 01:28:18,000
gotta head out youtube

2720
01:28:18,000 --> 01:28:21,830
see you next week oh two weeks

2721
01:28:21,840 --> 01:28:26,470
all right

2722
01:28:26,480 --> 01:28:29,920
oh go ahead um

2723
01:28:29,920 --> 01:28:32,960
okay sorry uh so i had a maybe basic

2724
01:28:32,960 --> 01:28:34,560
question about the shims

2725
01:28:34,560 --> 01:28:36,880
and i guess i think also maybe because

2726
01:28:36,880 --> 01:28:38,320
i'm just not familiar with

2727
01:28:38,320 --> 01:28:41,120
kind of specifically what like a runtime

2728
01:28:41,120 --> 01:28:43,440
is um and i guess like my confusion

2729
01:28:43,440 --> 01:28:44,800
comes from the fact that like

2730
01:28:44,800 --> 01:28:47,840
from a mental model of how like xv6 and

2731
01:28:47,840 --> 01:28:48,080
c

2732
01:28:48,080 --> 01:28:50,800
works is that c compiles c as a compiled

2733
01:28:50,800 --> 01:28:51,760
language

2734
01:28:51,760 --> 01:28:53,600
and so it goes directly to assembly or

2735
01:28:53,600 --> 01:28:55,600
machine code

2736
01:28:55,600 --> 01:28:58,159
and so it kind of just runs on the cpu

2737
01:28:58,159 --> 01:29:00,159
and so i guess

2738
01:29:00,159 --> 01:29:02,480
like there is no need for a shim for

2739
01:29:02,480 --> 01:29:03,600
like an xv6

2740
01:29:03,600 --> 01:29:06,719
os um but i guess my understanding is go

2741
01:29:06,719 --> 01:29:08,639
is also a compiled language so it also

2742
01:29:08,639 --> 01:29:10,159
goes to like assembly

2743
01:29:10,159 --> 01:29:12,800
so why is there a need for like a shin

2744
01:29:12,800 --> 01:29:13,760
in this case like why

2745
01:29:13,760 --> 01:29:15,440
why is is there maybe is there a shim

2746
01:29:15,440 --> 01:29:17,760
for like xp6 or you know what what is

2747
01:29:17,760 --> 01:29:18,800
different here and like

2748
01:29:18,800 --> 01:29:20,960
what why are there why are there things

2749
01:29:20,960 --> 01:29:23,040
that can't just be done onto cpu

2750
01:29:23,040 --> 01:29:25,520
yeah yeah yeah great question uh so i

2751
01:29:25,520 --> 01:29:26,880
think the answer to your question is

2752
01:29:26,880 --> 01:29:27,520
that the

2753
01:29:27,520 --> 01:29:30,000
go runtime provides all kinds of

2754
01:29:30,000 --> 01:29:31,600
features that like you know

2755
01:29:31,600 --> 01:29:33,920
you don't have correct in uh running

2756
01:29:33,920 --> 01:29:36,159
when you're running ce and xv6

2757
01:29:36,159 --> 01:29:38,400
so the go runtime provides frets go

2758
01:29:38,400 --> 01:29:40,239
runtime provides scheduler the

2759
01:29:40,239 --> 01:29:42,880
go runtime you know before it's uh hash

2760
01:29:42,880 --> 01:29:44,639
tables the go runtime provides a garbage

2761
01:29:44,639 --> 01:29:45,280
collector

2762
01:29:45,280 --> 01:29:46,800
that actually needs to run at runtime

2763
01:29:46,800 --> 01:29:48,480
right and there's no garbage collector

2764
01:29:48,480 --> 01:29:50,000
in xv6

2765
01:29:50,000 --> 01:29:53,360
and we implement the threads and uh

2766
01:29:53,360 --> 01:29:54,639
for example to support the garbage

2767
01:29:54,639 --> 01:29:56,239
lecture it needs a heap you know where

2768
01:29:56,239 --> 01:29:58,159
to allocate memory from and so it's like

2769
01:29:58,159 --> 01:29:59,600
ask the operating system underlying

2770
01:29:59,600 --> 01:30:01,199
operating system now please give me you

2771
01:30:01,199 --> 01:30:02,560
know some memories or i can use it as a

2772
01:30:02,560 --> 01:30:03,600
heap

2773
01:30:03,600 --> 01:30:06,480
and basically the shim layer implements

2774
01:30:06,480 --> 01:30:07,199
exactly

2775
01:30:07,199 --> 01:30:09,600
that kind of functionality that the go

2776
01:30:09,600 --> 01:30:12,239
runtime needs to do its job

2777
01:30:12,239 --> 01:30:23,110
at runtime

2778
01:30:23,120 --> 01:30:26,239
um yeah i just have

2779
01:30:26,239 --> 01:30:29,040
a f uh so it slightly makes sense um i

2780
01:30:29,040 --> 01:30:29,360
guess

2781
01:30:29,360 --> 01:30:33,030
a follow-up question is

2782
01:30:33,040 --> 01:30:36,550
maybe this is a dumb question but like

2783
01:30:36,560 --> 01:30:38,960
like can't we just compile the runtime

2784
01:30:38,960 --> 01:30:40,000
down

2785
01:30:40,000 --> 01:30:43,360
to machine code or runtime is compiled

2786
01:30:43,360 --> 01:30:43,840
to run

2787
01:30:43,840 --> 01:30:46,159
yeah okay so like you know the runtime

2788
01:30:46,159 --> 01:30:47,679
itself is also compiled but it's like

2789
01:30:47,679 --> 01:30:48,960
sort of part of the program that needs

2790
01:30:48,960 --> 01:30:50,800
to run always when you're running around

2791
01:30:50,800 --> 01:30:53,760
go code it has to be there like even

2792
01:30:53,760 --> 01:30:55,360
like c has a small runtime you know if

2793
01:30:55,360 --> 01:30:56,400
you think about like you know

2794
01:30:56,400 --> 01:30:58,000
we have like printf is part of the

2795
01:30:58,000 --> 01:30:59,520
shirley at the c runtime or like

2796
01:30:59,520 --> 01:31:01,360
streaming operations are part of the

2797
01:31:01,360 --> 01:31:03,679
tag right and they're compiled too but

2798
01:31:03,679 --> 01:31:05,040
you know there's a bunch of like small

2799
01:31:05,040 --> 01:31:06,400
number of functions that the c

2800
01:31:06,400 --> 01:31:09,120
runtime has but runtime is so small

2801
01:31:09,120 --> 01:31:10,960
compared to like the go runtime that you

2802
01:31:10,960 --> 01:31:12,320
know has to support many many more

2803
01:31:12,320 --> 01:31:13,199
features

2804
01:31:13,199 --> 01:31:14,880
because you know the programs the go

2805
01:31:14,880 --> 01:31:17,360
programs rely on them

2806
01:31:17,360 --> 01:31:19,520
i see i see and i guess like the last

2807
01:31:19,520 --> 01:31:20,800
question would maybe be is like

2808
01:31:20,800 --> 01:31:22,880
is it it kind of sounds like that in

2809
01:31:22,880 --> 01:31:23,920
this case the go

2810
01:31:23,920 --> 01:31:26,480
runtime or like actually the shim in

2811
01:31:26,480 --> 01:31:28,159
this case is almost

2812
01:31:28,159 --> 01:31:29,840
taking on some of the functionality of

2813
01:31:29,840 --> 01:31:32,000
normally like it's almost like it's like

2814
01:31:32,000 --> 01:31:33,520
a mini

2815
01:31:33,520 --> 01:31:35,360
it's almost kind of like it's like a

2816
01:31:35,360 --> 01:31:37,120
like a mini os layer like

2817
01:31:37,120 --> 01:31:38,639
in terms that it's just like another

2818
01:31:38,639 --> 01:31:40,719
layer that's performing some low level

2819
01:31:40,719 --> 01:31:41,360
system

2820
01:31:41,360 --> 01:31:44,400
functionality like reasonable yeah yeah

2821
01:31:44,400 --> 01:31:45,760
you can only think like maybe

2822
01:31:45,760 --> 01:31:46,880
you know one way to think about is

2823
01:31:46,880 --> 01:31:49,040
exorcism also has a very very minimal

2824
01:31:49,040 --> 01:31:49,520
shim

2825
01:31:49,520 --> 01:31:51,040
you know maybe like when it boots

2826
01:31:51,040 --> 01:31:52,400
correct the first thing it does actually

2827
01:31:52,400 --> 01:31:53,920
it allocates from stack so that you can

2828
01:31:53,920 --> 01:31:54,800
actually call

2829
01:31:54,800 --> 01:31:57,600
the c main function and you can think

2830
01:31:57,600 --> 01:31:59,440
about that that little fragment of code

2831
01:31:59,440 --> 01:32:00,719
which is all in a couple statements

2832
01:32:00,719 --> 01:32:04,639
it's the same layer for xv6 and once you

2833
01:32:04,639 --> 01:32:05,760
know you're through that couples

2834
01:32:05,760 --> 01:32:07,199
instructions you're actually in c code

2835
01:32:07,199 --> 01:32:08,719
and everything is fine

2836
01:32:08,719 --> 01:32:11,280
and you know the the shim layer for the

2837
01:32:11,280 --> 01:32:12,800
go runtime is slightly bigger because

2838
01:32:12,800 --> 01:32:13,920
there's a bunch of more features that

2839
01:32:13,920 --> 01:32:15,600
need to be set up before the go runtime

2840
01:32:15,600 --> 01:32:18,639
can actually happily execute

2841
01:32:18,639 --> 01:32:20,719
ah okay yeah that that's helpful that

2842
01:32:20,719 --> 01:32:21,679
makes sense

2843
01:32:21,679 --> 01:32:25,280
cool thank you you're welcome

2844
01:32:25,280 --> 01:32:28,719
happy thanksgiving yeah youtube oh i had

2845
01:32:28,719 --> 01:32:29,840
a question about the

2846
01:32:29,840 --> 01:32:32,639
ping pong program that i forgot to ask

2847
01:32:32,639 --> 01:32:32,960
so

2848
01:32:32,960 --> 01:32:34,960
i remember we also did a ping pong

2849
01:32:34,960 --> 01:32:37,040
program in one of the labs

2850
01:32:37,040 --> 01:32:40,480
and it was not a hundred those are a

2851
01:32:40,480 --> 01:32:40,960
thousand

2852
01:32:40,960 --> 01:32:44,239
lines of code why is

2853
01:32:44,239 --> 01:32:47,199
ah because i think uh are you referring

2854
01:32:47,199 --> 01:32:49,040
to lab one where you do the ping pong of

2855
01:32:49,040 --> 01:32:50,880
a bite across the pipe

2856
01:32:50,880 --> 01:32:53,760
yeah okay so that's the user side of the

2857
01:32:53,760 --> 01:32:54,560
benchmark

2858
01:32:54,560 --> 01:32:56,880
the kernel side correct is the other

2859
01:32:56,880 --> 01:32:59,120
side of it and basically you know the

2860
01:32:59,120 --> 01:33:01,120
what we did is implement the kernel pass

2861
01:33:01,120 --> 01:33:04,470
in an identical manner

2862
01:33:04,480 --> 01:33:06,560
okay so like you know you actually

2863
01:33:06,560 --> 01:33:08,159
executing the start of the system call

2864
01:33:08,159 --> 01:33:10,239
or you're saving variables in the stack

2865
01:33:10,239 --> 01:33:12,000
frame you know calling into

2866
01:33:12,000 --> 01:33:14,719
looking up the pipe you know and then uh

2867
01:33:14,719 --> 01:33:16,320
running maybe the scheduler to wake up

2868
01:33:16,320 --> 01:33:17,920
you know the receiver

2869
01:33:17,920 --> 01:33:20,400
uh and that whole code path you know on

2870
01:33:20,400 --> 01:33:21,600
the kernel

2871
01:33:21,600 --> 01:33:24,159
uh we try to implement it identically in

2872
01:33:24,159 --> 01:33:24,800
c and

2873
01:33:24,800 --> 01:33:27,760
go okay but the benchmark is basically

2874
01:33:27,760 --> 01:33:29,120
the same as your benchmark that you

2875
01:33:29,120 --> 01:33:31,040
implemented actually in lab one

2876
01:33:31,040 --> 01:33:33,920
the usual level side of it right right

2877
01:33:33,920 --> 01:33:35,040
okay that makes sense

2878
01:33:35,040 --> 01:33:38,080
so so does that mean that like

2879
01:33:38,080 --> 01:33:39,760
i mean i think that if you do that in

2880
01:33:39,760 --> 01:33:41,520
x56 it would be

2881
01:33:41,520 --> 01:33:43,679
significantly less than a thousand lines

2882
01:33:43,679 --> 01:33:44,800
of code if you like

2883
01:33:44,800 --> 01:33:47,440
take all the kernel code that is oh so

2884
01:33:47,440 --> 01:33:49,040
there's a thousand thousand lines for

2885
01:33:49,040 --> 01:33:50,560
assembly instructions correct

2886
01:33:50,560 --> 01:33:53,600
uh so you know you i i don't know i will

2887
01:33:53,600 --> 01:33:55,040
have to look at it but you know you're

2888
01:33:55,040 --> 01:33:55,360
gonna

2889
01:33:55,360 --> 01:33:57,120
you're gonna use the trap frame code

2890
01:33:57,120 --> 01:33:59,120
your statistical dispatch

2891
01:33:59,120 --> 01:34:00,450
going to the

2892
01:34:00,450 --> 01:34:02,159
[Music]

2893
01:34:02,159 --> 01:34:04,560
fd layer correct the file descriptors

2894
01:34:04,560 --> 01:34:05,199
then

2895
01:34:05,199 --> 01:34:08,719
uh a little bit of pipe code then

2896
01:34:08,719 --> 01:34:11,760
uh so copy in and copy out then the

2897
01:34:11,760 --> 01:34:12,800
scheduler

2898
01:34:12,800 --> 01:34:15,440
and then basically all and then bailing

2899
01:34:15,440 --> 01:34:16,159
out again or

2900
01:34:16,159 --> 01:34:20,000
returning yeah okay that makes sense

2901
01:34:20,000 --> 01:34:22,159
there is a you know i don't know on the

2902
01:34:22,159 --> 01:34:23,840
top of my head how much lines of code is

2903
01:34:23,840 --> 01:34:24,840
but you know there's

2904
01:34:24,840 --> 01:34:29,440
right yeah

