1
00:00:02,110 --> 00:00:03,880
好的，我想我们开始了，

2
00:00:03,970 --> 00:00:07,330
人们想再次打开摄像机，

3
00:00:07,330 --> 00:00:11,830
它可以很好地创造班级氛围，

4
00:00:12,430 --> 00:00:14,140
这是我们能做的最好的。

5
00:00:14,620 --> 00:00:16,750
好的，这是，

6
00:00:17,440 --> 00:00:19,090
今天我们要讨论这篇论文，

7
00:00:19,120 --> 00:00:22,750
使用用高级语言编写 UNIX 内核的好处和成本，

8
00:00:24,070 --> 00:00:30,280
这篇论文编写部分原因是因为 6.S081 或 6.828 ，

9
00:00:30,840 --> 00:00:34,170
这篇论文是由我们编写的，

10
00:00:34,260 --> 00:00:35,670
Robert 和我，

11
00:00:35,670 --> 00:00:39,300
但主要人物是 Cody Cutler ，

12
00:00:39,300 --> 00:00:42,960
他在这门课上当过很多次助教。

13
00:00:43,600 --> 00:00:45,340
这总是有一点，

14
00:00:45,340 --> 00:00:46,480
我不是特别喜欢

15
00:00:46,480 --> 00:00:49,180
谈论我们自己编写的论文，

16
00:00:49,180 --> 00:00:53,890
但是这篇论文基本上来自 6.S081 或 6.828 ，

17
00:00:53,890 --> 00:00:56,740
所以这次我要用一些幻灯片，

18
00:00:56,740 --> 00:00:59,440
而不是在白板上书写。

19
00:01:00,850 --> 00:01:04,720
所以这篇论文的真正来源就是这个问题，

20
00:01:04,720 --> 00:01:07,960
应该用什么语言编写内核。

21
00:01:08,520 --> 00:01:12,540
这是你们很多人都问过的问题，

22
00:01:12,570 --> 00:01:19,350
在过去的 6.828 毕业生中问了很多次，

23
00:01:19,380 --> 00:01:23,490
因为你的操作系统或内核中有 bug ，

24
00:01:23,490 --> 00:01:25,980
你会说，如果我使用另一种语言编写，

25
00:01:25,980 --> 00:01:28,410
也许我就不会有那些 bug 了。

26
00:01:29,140 --> 00:01:32,560
所以这是一个经常出现的问题，

27
00:01:32,560 --> 00:01:36,850
事实上，在整个操作系统社区中，

28
00:01:36,850 --> 00:01:39,430
这是一个争论不休的问题，

29
00:01:39,520 --> 00:01:44,260
但事实并不多，你可以进行任何知情的讨论。

30
00:01:45,200 --> 00:01:47,390
我们将在这节课结束时看到，

31
00:01:47,390 --> 00:01:49,580
在课程中或你读论文时，

32
00:01:49,700 --> 00:01:55,010
我知道我们对这个问题没有明确的答案，

33
00:01:55,160 --> 00:01:59,150
但是我们这篇论文贡献了很多数据，

34
00:01:59,150 --> 00:02:02,870
可以让你有更深入的讨论，

35
00:02:03,140 --> 00:02:07,250
关于什么是内核的好的编程语言。

36
00:02:08,130 --> 00:02:11,220
这就是这篇论文的原创之处，

37
00:02:11,220 --> 00:02:21,300
基本上这篇论文的来源就是你们。

38
00:02:21,860 --> 00:02:25,430
那么，为了回答这个问题，

39
00:02:25,610 --> 00:02:28,880
我们编写了一个新的内核，

40
00:02:29,270 --> 00:02:34,280
并且我们用具有自动内存管理的语言，

41
00:02:34,280 --> 00:02:35,570
这意味着有垃圾收集器，

42
00:02:35,570 --> 00:02:37,760
所以你不需要调用 free ，

43
00:02:37,760 --> 00:02:40,040
可以避免一类 bug ，

44
00:02:40,040 --> 00:02:43,310
这是高级语言通常具有的属性之一，

45
00:02:43,550 --> 00:02:46,220
所以，我们希望选择一种具有这种特性的语言，

46
00:02:46,460 --> 00:02:50,720
我们基本上遵循了传统的 Unix 结构，

47
00:02:50,720 --> 00:02:52,280
我们可以做一个公平的比较。

48
00:02:52,910 --> 00:02:58,640
在某种程度上，你可以认为我们构建的是类似于 xv6 的东西，

49
00:02:58,640 --> 00:03:04,070
功能更多，性能更高。

50
00:03:05,140 --> 00:03:05,980
我的意思是，正如你知道的，

51
00:03:05,980 --> 00:03:12,430
xv6 有各种慢性算法或线性搜索、类型算法，

52
00:03:12,430 --> 00:03:14,920
当然，如果你想实现高性能，

53
00:03:14,920 --> 00:03:15,790
你不能有这些。

54
00:03:17,360 --> 00:03:20,900
所以，这就是论文的来源，

55
00:03:20,900 --> 00:03:23,930
为什么我们构建了 Biscuit 试图回答这个问题，

56
00:03:23,930 --> 00:03:25,100
或者至少给我们一些启示。

57
00:03:25,650 --> 00:03:28,440
首先，我要讨论一下更一般的背景，

58
00:03:28,440 --> 00:03:31,770
我通过电子邮件得到很多问题，

59
00:03:31,770 --> 00:03:34,530
我们正试图获得更多的背景信息，

60
00:03:34,830 --> 00:03:38,400
然后我会更详细地讨论 Biscuit ，

61
00:03:38,610 --> 00:03:42,330
任何时间都可以随意提出问题，

62
00:03:42,540 --> 00:03:47,470
正如你所知道的，这篇论文的动机是你们提出的问题，

63
00:03:47,470 --> 00:03:50,380
所以，请继续问问题。

64
00:03:52,980 --> 00:03:56,160
所以，正如你可以做的那样，

65
00:03:56,370 --> 00:04:00,480
这篇论文的设置是很多内核都是用 C 语言写的，

66
00:04:00,480 --> 00:04:03,270
xv6 是用 C 语言写的，你使用 C 语言编写程序，

67
00:04:03,420 --> 00:04:09,180
你在桌面或手机上看到的大多数流行内核都是用 C 语言编写的，

68
00:04:09,180 --> 00:04:14,130
Windows Linux 以及所有各种形式的 BSD 。

69
00:04:14,850 --> 00:04:21,420
用 C 语言编写的原因是，

70
00:04:21,990 --> 00:04:25,680
C 提供了很多控制，正如你在实验中看到的，

71
00:04:25,770 --> 00:04:28,710
完全控制内存分配和释放，

72
00:04:28,980 --> 00:04:31,290
几乎没有隐式代码，

73
00:04:31,290 --> 00:04:34,140
你几乎可以想象，当你阅读 C 代码的时候，

74
00:04:34,140 --> 00:04:36,540
对应的 RISC-V 指令是什么，

75
00:04:37,000 --> 00:04:38,740
你可以直接访问内存，

76
00:04:38,740 --> 00:04:44,140
你可以读写 PTE 位或者设备寄存器，您知道您知道的PTE位或设备的寄存器，

77
00:04:44,410 --> 00:04:48,640
而且 C 语言本身有很少的依赖，

78
00:04:48,640 --> 00:04:51,280
你并不需要很大的运行时，

79
00:04:51,400 --> 00:04:52,750
为了能够运行 C 程序，

80
00:04:52,750 --> 00:04:55,870
你几乎可以直接在裸硬件上运行。

81
00:04:56,260 --> 00:04:58,540
你已经看到一旦 xv6 启动，

82
00:04:58,540 --> 00:05:00,310
先是几行汇编代码，

83
00:05:00,310 --> 00:05:01,900
然后你就是在运行 C 代码。

84
00:05:02,780 --> 00:05:06,860
但是这些都是 C 语言优点，

85
00:05:06,860 --> 00:05:08,660
也是我们非常喜欢 C 的一个原因。

86
00:05:09,230 --> 00:05:11,810
但是 C 也有一些缺点，

87
00:05:12,080 --> 00:05:16,190
在过去的几十年里已经被证明了，

88
00:05:16,340 --> 00:05:19,340
写安全的 C 代码很难，

89
00:05:19,340 --> 00:05:26,030
有几种类型的 bug ，经常会被利用，

90
00:05:26,030 --> 00:05:27,470
无论是缓冲区溢出，

91
00:05:27,470 --> 00:05:30,950
这可能是在过去最广为人知的问题，

92
00:05:31,450 --> 00:05:35,980
一个数组绑定，或者你正在堆下面写，

93
00:05:36,340 --> 00:05:42,640
use-after-free bug ，你释放了内存，但是它仍在使用，

94
00:05:43,140 --> 00:05:45,060
所以当有人在上面乱写的时候，

95
00:05:45,060 --> 00:05:47,460
在上面乱写一些不好的东西，

96
00:05:47,580 --> 00:05:52,440
通常情况下，线程共享内存时，

97
00:05:52,440 --> 00:05:55,770
很难决定哪些内存可以释放。

98
00:05:56,940 --> 00:05:59,670
有些 bug ，并不会真的出现在那里，

99
00:05:59,940 --> 00:06:04,200
一些 bug 明确地体现在 xv6 中，一些较少，

100
00:06:04,200 --> 00:06:09,360
xv6 的动态内存分配非常少，

101
00:06:09,360 --> 00:06:11,820
你几乎是已经预先分配好了，

102
00:06:12,260 --> 00:06:16,580
缓冲区溢出通常会出现释放 bug 。

103
00:06:17,440 --> 00:06:22,540
事实上，如果你看一看 CVEs ，

104
00:06:22,630 --> 00:06:25,360
有一个网站，

105
00:06:25,360 --> 00:06:27,790
有一个组织保持控制，

106
00:06:27,790 --> 00:06:32,110
检查和记录所有安全漏洞，

107
00:06:32,350 --> 00:06:36,730
调查一下，你会发现，在 2017 年我们做这篇论文的时候，

108
00:06:36,730 --> 00:06:41,380
有 40 个 Linux 内核 bug ，

109
00:06:41,380 --> 00:06:47,950
会导致攻击者完全控制机器。

110
00:06:48,570 --> 00:06:50,220
显然，那些是严重的 bug ，

111
00:06:50,220 --> 00:06:52,740
这些 bug 来自于缓冲区溢出，

112
00:06:52,890 --> 00:06:55,860
以及其他类型的内存安全 bug 。

113
00:06:56,720 --> 00:06:59,990
所以这太糟糕了，

114
00:07:00,020 --> 00:07:01,850
如果你用 C 语言写代码，

115
00:07:01,850 --> 00:07:03,050
很难做到，

116
00:07:03,050 --> 00:07:08,060
即使是专业人士也很难做到这一点。

117
00:07:08,730 --> 00:07:11,580
当然，我相信你在实验里见过这个，

118
00:07:11,580 --> 00:07:16,590
也许，我记得在 Piazza 上的一些问题，

119
00:07:16,590 --> 00:07:19,200
你们遇到 use-after-free bug 的次数，

120
00:07:19,200 --> 00:07:21,690
特别是在写入时复制实验里，

121
00:07:21,930 --> 00:07:23,760
它们出现了很多次。

122
00:07:25,530 --> 00:07:30,660
所以，高级语言吸引人的一个原因是，

123
00:07:30,690 --> 00:07:33,240
高级语言提供了内存安全，

124
00:07:33,360 --> 00:07:37,170
所以，所有 CVE 披露的 bug ，

125
00:07:37,170 --> 00:07:38,670
我在上一张幻灯片中提到的，

126
00:07:38,790 --> 00:07:41,490
将会是不可能的，

127
00:07:41,520 --> 00:07:43,740
如果它们发生了，

128
00:07:43,830 --> 00:07:45,660
它们要么会导致 panic ，

129
00:07:45,690 --> 00:07:48,410
因为运行时会说，

130
00:07:48,410 --> 00:07:50,450
你要写的东西已经不在了，你不能那样做，

131
00:07:50,660 --> 00:07:55,100
或者根本不能表现出来，

132
00:07:55,130 --> 00:07:58,010
因为语言不会允许你编写这样的代码。

133
00:08:00,800 --> 00:08:03,560
高级语言当然还有其他好处，

134
00:08:03,650 --> 00:08:09,710
这门课上的学生也经常提到，

135
00:08:09,740 --> 00:08:11,030
当他们在做实验时，

136
00:08:11,030 --> 00:08:12,350
除了类型安全，

137
00:08:12,350 --> 00:08:14,990
还有具有垃圾收集器的自动内存管理，

138
00:08:15,320 --> 00:08:16,850
所以释放是很简单的，

139
00:08:16,850 --> 00:08:18,080
你不用考虑它，

140
00:08:18,080 --> 00:08:19,850
垃圾收集器会帮你做所有的工作，

141
00:08:19,970 --> 00:08:22,130
它对并发性有好处，

142
00:08:22,130 --> 00:08:23,690
它有很好的抽象性，

143
00:08:23,720 --> 00:08:29,090
比如 Go 它的接口或其他一些类或其他形式的，

144
00:08:29,270 --> 00:08:33,710
这会鼓励你编写模块化代码。

145
00:08:36,620 --> 00:08:38,720
不好的一面，你可能会想，

146
00:08:38,720 --> 00:08:41,360
如果高级语言有这么多好处，

147
00:08:41,360 --> 00:08:42,980
为什么不，

148
00:08:42,980 --> 00:08:47,540
为什么 xv6 不是用 Java Go Python 或其他什么来写，

149
00:08:47,900 --> 00:08:50,810
原因是， Linux ，

150
00:08:50,810 --> 00:08:53,000
原因是它的性能很差，

151
00:08:53,000 --> 00:08:56,600
高级语言是要付出代价的，

152
00:08:56,600 --> 00:08:59,780
有时这被称为高级语言税。

153
00:09:00,240 --> 00:09:05,460
这些是，如果你做一个数组界限，数组索引，

154
00:09:05,460 --> 00:09:07,230
你必须检查边界，

155
00:09:07,230 --> 00:09:09,060
你必须检查空指针，

156
00:09:10,060 --> 00:09:14,020
它们有更昂贵的转换，

157
00:09:14,260 --> 00:09:17,260
垃圾收集也不是免费的，

158
00:09:17,290 --> 00:09:20,260
要花几个周期来追踪，

159
00:09:20,260 --> 00:09:23,740
哪些对象是空闲的，哪些是分配的，这是也是损失。

160
00:09:26,640 --> 00:09:28,620
所以这是从性能方面，

161
00:09:28,650 --> 00:09:30,840
很多论文都集中在这一点。

162
00:09:30,930 --> 00:09:33,870
然后原则上，我的意思是，

163
00:09:33,900 --> 00:09:37,740
它被认为是与 Linux 内核编程的不兼容，

164
00:09:38,360 --> 00:09:40,730
没有直接的内存访问，

165
00:09:40,730 --> 00:09:44,930
因为原则可能知道违反了类型安全，

166
00:09:45,380 --> 00:09:47,090
没有手写汇编语言，

167
00:09:47,090 --> 00:09:49,430
你需要在内核中使用一些手写汇编语言，

168
00:09:49,430 --> 00:09:51,920
在两个线程之间的上下文切换，

169
00:09:51,920 --> 00:09:54,650
或者在机器启动时顺利开始，

170
00:09:55,320 --> 00:10:00,790
通常情况下，

171
00:10:00,880 --> 00:10:06,460
语言可能有一个特定的并发或并行的计划，

172
00:10:06,460 --> 00:10:11,770
可能与内核需要的并发并行不一致，

173
00:10:11,770 --> 00:10:15,730
我们已经看到，比如在调度课程中，

174
00:10:15,730 --> 00:10:19,570
一个线程将锁传递给另一个线程，

175
00:10:19,570 --> 00:10:23,350
有几种并发管理的模式，

176
00:10:23,350 --> 00:10:25,270
这些都是不普通或普通的程序，

177
00:10:25,270 --> 00:10:27,690
但它们确实出现在内核中。

178
00:10:28,580 --> 00:10:35,680
所以，这个论文的目标是，

179
00:10:35,680 --> 00:10:38,560
衡量高级语言的权衡，

180
00:10:38,710 --> 00:10:41,440
探索使用高级语言代替 C 语言的总体效果，

181
00:10:41,470 --> 00:10:44,920
不仅是在安全编程能力方面，

182
00:10:44,950 --> 00:10:46,870
而且在性能成本方面。

183
00:10:47,200 --> 00:10:49,870
当然，如果你想做这个实验，

184
00:10:49,870 --> 00:10:52,390
你需要做那种生产级的内核，

185
00:10:52,390 --> 00:10:53,740
你不能在 xv6 上做到这一点，

186
00:10:53,740 --> 00:10:56,440
因为它太慢了，你可能什么都学不到，

187
00:10:56,470 --> 00:10:59,320
这是一个用 C 语言写得很慢的程序，

188
00:10:59,320 --> 00:11:01,780
你用 Go 也写得很慢，

189
00:11:01,780 --> 00:11:05,230
这并不能告诉你很多关于 C 对 Go 的问题，

190
00:11:05,230 --> 00:11:06,940
它只是说 xv6 很慢。

191
00:11:07,560 --> 00:11:12,570
所以你想要在一个更高性能的内核，

192
00:11:12,690 --> 00:11:15,060
或者内核是为高性能而设计的。

193
00:11:17,600 --> 00:11:19,700
所以你知道有一件事是令人惊讶的，

194
00:11:19,700 --> 00:11:24,260
因为你们中的许多人问到这个，

195
00:11:24,260 --> 00:11:29,300
我想这个问题一定会在文献中得到回答，

196
00:11:29,480 --> 00:11:31,430
事实证明这并不是，

197
00:11:31,490 --> 00:11:36,590
有很多的研究这个问题，

198
00:11:36,590 --> 00:11:40,040
关于高级语言在用户程序中的权衡的问题，

199
00:11:40,510 --> 00:11:46,510
但是内核和用户程序有很大的不同，

200
00:11:46,990 --> 00:11:49,990
比如仔细的内存管理是非常重要的，

201
00:11:50,440 --> 00:11:52,720
这种不同类型的并发性可能略有不同，

202
00:11:52,870 --> 00:11:55,570
所以我们想在内核中做这件事。

203
00:11:56,310 --> 00:12:00,300
我们没有找到任何论文真正回答这个问题，

204
00:12:00,880 --> 00:12:02,620
你能接近的是，

205
00:12:02,620 --> 00:12:07,540
有很多内核是用高级语言编写的，

206
00:12:07,540 --> 00:12:09,640
这样做已经有很长的历史了，

207
00:12:09,640 --> 00:12:13,840
甚至可以追溯到早期的机器，

208
00:12:14,080 --> 00:12:19,450
但是很多这些内核的最新版本，

209
00:12:19,810 --> 00:12:26,650
并不是根据评估高级语言税问题的想法来做的，

210
00:12:27,000 --> 00:12:32,790
而是真正探索新的操作系统设计和新的操作系统架构，

211
00:12:33,090 --> 00:12:36,900
所以它们没有一个是直接评估，

212
00:12:36,900 --> 00:12:39,450
比如面对面的比较，

213
00:12:39,660 --> 00:12:41,970
保持结构不变，

214
00:12:42,210 --> 00:12:45,210
所以你可以真正专注于语言的问题，

215
00:12:45,210 --> 00:12:47,490
而不是其他问题。

216
00:12:49,220 --> 00:12:53,960
事实上，我们过去读过一些论文。

217
00:12:59,350 --> 00:13:02,320
所以，有一个原因可能是，

218
00:13:02,320 --> 00:13:05,290
没有太多的工作回答，

219
00:13:05,290 --> 00:13:07,840
很多论文没有回答这个问题，

220
00:13:07,840 --> 00:13:09,340
做这件事是很困难的，

221
00:13:09,460 --> 00:13:12,580
如果你真的想做它，

222
00:13:12,610 --> 00:13:15,100
想和一个 C 编写的生产级别的内核进行比较，

223
00:13:15,160 --> 00:13:19,510
比如 Linux 或 Windows 之类的东西，

224
00:13:19,750 --> 00:13:23,350
然后你必须构建一个产品级别的内核，

225
00:13:23,350 --> 00:13:28,570
当然，对于一个小团队来说，这是很难做到的，

226
00:13:28,870 --> 00:13:31,570
你知道有很多 Linux 内核开发者，

227
00:13:31,570 --> 00:13:36,580
做了很多修改，一周又一周，一天又一天，

228
00:13:36,580 --> 00:13:39,100
所以很难做到，

229
00:13:39,100 --> 00:13:40,930
做同样的事情，

230
00:13:40,930 --> 00:13:43,450
构建一个同类型的东西，

231
00:13:43,450 --> 00:13:48,460
所以你只能满足于稍微低于。

232
00:13:51,660 --> 00:13:55,050
所以，我们能做的最好的是，

233
00:13:55,170 --> 00:13:57,840
构建一个高级语言的内核，

234
00:13:57,870 --> 00:14:00,360
保持大部分重要方面与 Linux 相同，

235
00:14:00,840 --> 00:14:02,880
优化性能，

236
00:14:02,880 --> 00:14:06,300
优化性能，直到与 Linux 大致相似，

237
00:14:06,300 --> 00:14:09,210
即使它可能不是完全相同的特性，

238
00:14:09,210 --> 00:14:10,950
但它进入了同样的范围内，

239
00:14:11,310 --> 00:14:13,710
然后评估高级语言的权衡。

240
00:14:14,520 --> 00:14:18,300
当然，这种方法的风险是，

241
00:14:18,300 --> 00:14:21,990
我们构建的内核实际上与 Linux 略有不同，

242
00:14:21,990 --> 00:14:23,880
它不会和 Linux 完全一样，

243
00:14:23,880 --> 00:14:28,440
所以当你得出任何结论时，必须非常小心。

244
00:14:28,900 --> 00:14:31,660
这是一个原因，

245
00:14:31,660 --> 00:14:34,570
为什么我们仍然可以得到一个相当清晰的答案，

246
00:14:34,570 --> 00:14:36,640
这就是这篇论文提出的问题，

247
00:14:36,820 --> 00:14:39,910
但我们希望能获得更深层次的洞察力，

248
00:14:39,910 --> 00:14:42,070
而不是基本上什么都不说。

249
00:14:44,560 --> 00:14:47,860
这能理解吗，到目前为止，有什么问题吗？

250
00:14:48,690 --> 00:14:51,030
这就是这篇论文的背景，

251
00:14:51,030 --> 00:14:54,120
以及为什么我们这么做。

252
00:14:55,990 --> 00:14:58,700
好的，如果没有问题，

253
00:14:58,700 --> 00:15:02,510
我想多谈一点关于方法论的问题。

254
00:15:03,290 --> 00:15:07,220
所以，基本的设置是，

255
00:15:07,220 --> 00:15:12,170
在左边，有我们的 Biscuit ，

256
00:15:12,860 --> 00:15:17,600
我们要，在我们的情况中，

257
00:15:17,600 --> 00:15:21,590
我们为这篇论文使用 Go 编写的内核，

258
00:15:21,590 --> 00:15:26,900
它提供了与 Linux 的系统调用大致相同的子集，

259
00:15:26,900 --> 00:15:28,370
你知道它们的方式，

260
00:15:28,370 --> 00:15:30,050
它们有相同的参数，

261
00:15:30,050 --> 00:15:32,150
相同的的调用接口。

262
00:15:32,850 --> 00:15:36,360
我们在接口上运行相同的应用程序，

263
00:15:36,630 --> 00:15:40,680
其中一个应用程序是网络服务器 Nginx ，

264
00:15:41,390 --> 00:15:43,640
所以我们的想法是，

265
00:15:43,640 --> 00:15:49,240
我们在 Biscuit 和 Linux 上使用相同的应用程序，

266
00:15:49,270 --> 00:15:54,730
应用程序使用完全相同的参数生成相同的系统调用[跟踪]，

267
00:15:55,030 --> 00:16:00,100
Biscuit 和 Linux 执行所有必须的操作，

268
00:16:00,100 --> 00:16:02,350
由这些系统调用引起的，

269
00:16:02,590 --> 00:16:05,200
然后我们可以看一下

270
00:16:05,200 --> 00:16:09,070
高级语言内核和 Linux 之间的区别，

271
00:16:09,070 --> 00:16:12,940
并讨论一下什么是权衡。

272
00:16:13,670 --> 00:16:16,760
所以在方法论之后，

273
00:16:16,760 --> 00:16:20,750
因为 Linux 和 Biscuit 不会完全相同，

274
00:16:20,990 --> 00:16:23,870
这里会有一些不同，

275
00:16:23,870 --> 00:16:27,770
但是我们在这里花了很多时间，

276
00:16:27,770 --> 00:16:30,140
尽可能地进行比较，

277
00:16:32,970 --> 00:16:35,670
尽可能想办法做成它。

278
00:16:37,090 --> 00:16:39,460
你们中的很多人都会问这个问题，

279
00:16:39,460 --> 00:16:41,200
使用哪种高级语言，

280
00:16:41,230 --> 00:16:43,000
对于这种工作，

281
00:16:43,030 --> 00:16:47,290
我们选择 Go ，出于几个原因，

282
00:16:47,320 --> 00:16:50,260
它是一种静态编译语言，

283
00:16:50,260 --> 00:16:53,680
所以与 Python 不同，这里没有解释器，

284
00:16:53,800 --> 00:16:57,280
这是我们喜欢静态编译的原因，

285
00:16:57,280 --> 00:16:59,710
因为我们可以编译高性能的代码，

286
00:16:59,770 --> 00:17:01,810
实际上， Go 编译器是相当不错的。

287
00:17:02,740 --> 00:17:06,430
所以它是一种高性能的语言，

288
00:17:06,460 --> 00:17:10,390
此外， Go 的设计是为系统编程的，

289
00:17:10,510 --> 00:17:12,730
内核或系统编程，

290
00:17:12,730 --> 00:17:14,230
所以它是一个很好的选择。

291
00:17:14,780 --> 00:17:19,400
举个例子，为什么它是一个好的系统编程语言，

292
00:17:19,400 --> 00:17:22,460
它很容易调用汇编或其他外来代码，

293
00:17:23,010 --> 00:17:26,250
它对并发有很好的支持，非常方便。

294
00:17:26,550 --> 00:17:29,190
然后另一个我们想要使用它的原因，

295
00:17:29,190 --> 00:17:30,360
因为它有一个垃圾收集器，

296
00:17:31,260 --> 00:17:33,660
关于高级语言需要考虑的一件事，

297
00:17:33,660 --> 00:17:35,460
高级语言的优点之一，

298
00:17:35,460 --> 00:17:37,110
你不需要进行内存管理，

299
00:17:37,380 --> 00:17:40,860
垃圾收集器通常是关键角色，

300
00:17:42,910 --> 00:17:46,420
在内存管理中提供关键角色。

301
00:17:48,830 --> 00:17:51,410
当我们开始写这篇论文的时候，

302
00:17:51,410 --> 00:17:52,820
或者我们开始这个项目的时候，

303
00:17:53,030 --> 00:17:55,790
Rust 不是很流行，

304
00:17:55,790 --> 00:17:58,370
或者 Rust 还不是很稳定和成熟，

305
00:17:58,370 --> 00:17:59,990
它可以写一个真正的内核，

306
00:17:59,990 --> 00:18:03,110
现在回想一下，

307
00:18:03,110 --> 00:18:04,220
如果你再做一次，

308
00:18:04,220 --> 00:18:06,200
你可以使用 Rust 来写，

309
00:18:06,230 --> 00:18:09,020
因为它也是为系统编程设计的，

310
00:18:09,080 --> 00:18:13,760
它有一个很小的运行时，可以产生好的代码，

311
00:18:13,940 --> 00:18:17,390
尽管有一件事，

312
00:18:17,390 --> 00:18:20,660
可能仍然会让人[本能地]去尝试的是，

313
00:18:20,720 --> 00:18:23,210
Rust 首先假设，

314
00:18:23,210 --> 00:18:28,040
如果你想要高性能系统程序，

315
00:18:28,040 --> 00:18:30,170
那么你不能使用垃圾收集器。

316
00:18:30,680 --> 00:18:35,590
事实上， Rust 类型系统以一种非常聪明的方式，

317
00:18:35,590 --> 00:18:36,880
和一种非常有趣的方式设置的，

318
00:18:37,060 --> 00:18:39,490
所以垃圾收集器是不必要的。

319
00:18:40,080 --> 00:18:43,440
在某些方面，我们对回答这个问题很感兴趣，

320
00:18:43,440 --> 00:18:46,110
在高级语言中进行垃圾收集的成本是多少，

321
00:18:46,110 --> 00:18:47,610
关于内核编程，

322
00:18:47,790 --> 00:18:52,440
它的成本是多少，

323
00:18:52,710 --> 00:18:54,990
在某些方面， Rust 绕过了这个问题，

324
00:18:54,990 --> 00:18:57,450
使用一种没有垃圾回收的语言，

325
00:18:57,450 --> 00:18:59,340
你不必须考虑这个成本。

326
00:19:01,860 --> 00:19:02,760
关于这个有什么问题吗，

327
00:19:02,760 --> 00:19:07,070
关于我们决定使用的编程语言方面。

328
00:19:11,050 --> 00:19:13,330
许多邮件里的问题与这个主题有关。

329
00:19:14,850 --> 00:19:16,620
这是一个理论问题，

330
00:19:16,620 --> 00:19:19,380
可能没有直接的答案，

331
00:19:19,440 --> 00:19:24,930
但是如果编写 Linux 内核使用 Rust 而不是 Go ，

332
00:19:25,260 --> 00:19:28,200
在相同的能力下进行优化，

333
00:19:28,230 --> 00:19:31,230
它是否能够实现更高的性能？

334
00:19:32,490 --> 00:19:35,880
比 Go 的并发吗？

335
00:19:36,450 --> 00:19:39,210
比 C ，比如 C 编写的 Linux 内核。

336
00:19:39,630 --> 00:19:41,520
我怀疑它会，

337
00:19:41,520 --> 00:19:44,340
好的，很难知道，只是猜测，

338
00:19:44,340 --> 00:19:45,750
因为我们做有过这个实验，

339
00:19:46,050 --> 00:19:50,490
在我看来，不会比 C 有更高的性能，

340
00:19:50,580 --> 00:19:53,580
但可能大致相同。

341
00:19:54,580 --> 00:19:56,920
因为 C 是低级语言，

342
00:19:56,920 --> 00:19:58,660
你可以假设你在 Rust 里所做的，

343
00:19:58,660 --> 00:19:59,770
你也可以用 C 来做。

344
00:20:04,810 --> 00:20:05,500
这能理解吗？

345
00:20:07,060 --> 00:20:08,020
好的，谢谢。

346
00:20:11,010 --> 00:20:12,390
好的。

347
00:20:13,270 --> 00:20:14,980
好的，我们开始吧，

348
00:20:15,610 --> 00:20:17,800
除非对于这个还有任何其他问题，

349
00:20:17,860 --> 00:20:19,630
再说一次，请随意打断，

350
00:20:19,630 --> 00:20:22,180
这里一节基于讨论的课程，

351
00:20:22,900 --> 00:20:27,820
它的目的是激发智力和兴趣，

352
00:20:27,820 --> 00:20:31,180
所以，如果你对这个话题有什么想说的，可以加入进来。

353
00:20:34,900 --> 00:20:38,140
所以在我想问的问题之前，

354
00:20:38,170 --> 00:20:40,420
也许我会在课程结束时回来看，

355
00:20:40,420 --> 00:20:41,680
课程快结束的时候。

356
00:20:42,280 --> 00:20:47,680
在一定程度上，我们使用高级语言

357
00:20:47,680 --> 00:20:49,180
来避免某种类型的 bug ，

358
00:20:49,300 --> 00:20:51,250
你应该问自己一个问题，

359
00:20:51,310 --> 00:20:56,230
你在实验中出现的哪种 bug 是可以避免的，

360
00:20:56,260 --> 00:20:57,730
如果你使用高级语言。

361
00:20:58,460 --> 00:21:00,830
所以回想一下，

362
00:21:00,830 --> 00:21:03,410
我相信你能想出一些 bug ，

363
00:21:03,410 --> 00:21:06,080
花了你很多时间和痛苦，

364
00:21:06,230 --> 00:21:09,140
你可以问自己这些 bug ，

365
00:21:09,140 --> 00:21:14,180
如果我们在实验中的 xv6 ，

366
00:21:14,180 --> 00:21:16,700
用另一种高级编程语言来完成，

367
00:21:16,730 --> 00:21:18,920
会让生活变得容易很多，

368
00:21:18,950 --> 00:21:21,350
让你有更多的空闲时间做其他事情。

369
00:21:22,470 --> 00:21:24,570
所以我们带着这个问题，

370
00:21:24,570 --> 00:21:27,930
在课程结束时回到这个问题上来。

371
00:21:28,820 --> 00:21:30,920
但是如果你现在有想法，也没问题。

372
00:21:32,350 --> 00:21:35,140
好的，让我说一下 Biscuit ，

373
00:21:35,290 --> 00:21:39,640
其中的工作，

374
00:21:39,640 --> 00:21:41,320
一些惊讶的事情，

375
00:21:41,320 --> 00:21:43,720
我们在构建 Biscuit 过程中的东西，

376
00:21:43,720 --> 00:21:46,450
我们遇到一些没有预料到的东西。

377
00:21:48,360 --> 00:21:49,890
所以用户程序，

378
00:21:49,890 --> 00:21:51,690
这里有一个传统内核，

379
00:21:51,750 --> 00:21:55,170
一个与 Linux 或 xv6 相同的宏内核，

380
00:21:55,320 --> 00:21:57,750
所以这里有用户空间和内核空间，

381
00:21:57,960 --> 00:22:00,150
用户空间程序是，

382
00:22:00,180 --> 00:22:03,210
比如你的编译器 GCC ，

383
00:22:03,210 --> 00:22:06,660
或者在我们的论文中，它是一个网络服务器，

384
00:22:06,660 --> 00:22:08,850
以及其他一些基准。

385
00:22:09,250 --> 00:22:12,820
用户程序都是用 C 语言编写的，

386
00:22:12,820 --> 00:22:14,650
尽管它可以是任何语言编写的，

387
00:22:14,650 --> 00:22:16,600
因为它们只是一个基准，

388
00:22:17,200 --> 00:22:18,550
我们采用 C 语言版本，

389
00:22:18,940 --> 00:22:21,310
并且多数程序都是多线程的，

390
00:22:21,310 --> 00:22:26,140
所以，与 xv6 中每个用户程序只有一个线程不同，

391
00:22:26,200 --> 00:22:30,850
在 Biscuit 中，支持多个用户线程。

392
00:22:31,780 --> 00:22:34,540
对于每个用户线程，

393
00:22:34,750 --> 00:22:39,040
在内核中都有相应的内核线程，

394
00:22:39,220 --> 00:22:43,240
这些内核线程是由 Go 实现的，

395
00:22:43,240 --> 00:22:45,070
Go 调用 Go 例程，

396
00:22:47,970 --> 00:22:50,730
你可以把 Go 例程看作普通线程，

397
00:22:50,760 --> 00:22:56,280
与 xv6 相同的方式，内核具有线程，

398
00:22:57,540 --> 00:22:59,070
Go 协程是类似的，

399
00:22:59,190 --> 00:23:01,140
主要的区别是，

400
00:23:01,140 --> 00:23:04,380
在 xv6 中，线程是由内核实现的，

401
00:23:04,530 --> 00:23:07,350
在这种情况下，是由 Go 运行时提供的，

402
00:23:07,350 --> 00:23:09,090
Go 运行时调度它们，

403
00:23:09,090 --> 00:23:13,770
Go 运行时支持睡眠唤醒或条件变量，

404
00:23:13,770 --> 00:23:15,180
有不同的睡眠唤醒，

405
00:23:15,180 --> 00:23:18,420
但有一些条件变量同步机制，

406
00:23:18,720 --> 00:23:20,730
还有很多原语，

407
00:23:20,730 --> 00:23:23,790
Go 运行时 Go 语言本身提供，

408
00:23:23,790 --> 00:23:26,280
不是由 Biscuit 本身实现的，

409
00:23:26,280 --> 00:23:27,840
我们只是从 Go 运行时获得它们。

410
00:23:29,440 --> 00:23:33,470
GO 运行时本身直接在裸硬件上运行。

411
00:23:36,400 --> 00:23:40,390
我会在课程中更多地谈到这一点，

412
00:23:40,510 --> 00:23:43,180
但你可以认为这是机器启动，

413
00:23:43,180 --> 00:23:45,310
第一件事就是启动到 Go 运行时，

414
00:23:46,000 --> 00:23:47,980
这带来了很多复杂情况，

415
00:23:47,980 --> 00:23:51,850
因为通常 Go 运行时作为用户程序运行在用户空间，

416
00:23:51,850 --> 00:23:54,130
假设有一个内核，

417
00:23:54,130 --> 00:23:55,390
我们可以请求一些服务，

418
00:23:55,390 --> 00:23:59,190
比如，需要为其堆分配内存。

419
00:23:59,710 --> 00:24:02,590
所以这里有一些，

420
00:24:02,590 --> 00:24:05,530
有一些垫片代码，

421
00:24:05,530 --> 00:24:09,340
Biscuit 用来欺骗 Go 进行时，

422
00:24:09,340 --> 00:24:11,920
使其相信它运行在操作系统之上，

423
00:24:11,920 --> 00:24:13,330
即使它是在裸硬件上运行，

424
00:24:14,050 --> 00:24:15,340
获得启动。

425
00:24:16,360 --> 00:24:20,830
然后内核本身跟 xv6 非常相似，

426
00:24:20,890 --> 00:24:22,240
想象有一种模型，

427
00:24:22,240 --> 00:24:25,690
不过它更复杂，性能更高，

428
00:24:25,690 --> 00:24:27,190
它有虚拟内存系统，

429
00:24:27,190 --> 00:24:31,030
比如，你这周要做的 mmap 实验，

430
00:24:31,060 --> 00:24:32,290
它有一个文件系统，

431
00:24:32,290 --> 00:24:34,480
有更高性能的文件系统，

432
00:24:34,870 --> 00:24:36,250
它有一些驱动，

433
00:24:36,250 --> 00:24:37,450
它有磁盘驱动，

434
00:24:37,450 --> 00:24:40,630
它有网络驱动，有网络堆栈，

435
00:24:41,180 --> 00:24:42,710
所以它会更完整，

436
00:24:42,710 --> 00:24:46,670
你可以看到，它有大概 58 个系统调用，

437
00:24:46,670 --> 00:24:49,460
我记不清 xv6 有多少了，

438
00:24:49,460 --> 00:24:52,250
但应该是 18 或 19 个左右。

439
00:24:52,860 --> 00:24:55,800
启动代码的总数是 28000 个，

440
00:24:55,800 --> 00:25:00,030
xv6 我想是在 10000 以下，

441
00:25:00,030 --> 00:25:02,280
所以这里有更多功能。

442
00:25:04,580 --> 00:25:06,650
关于这个高级别的概述，有什么问题吗？

443
00:25:08,470 --> 00:25:11,590
哦，抱歉，我想问一下接口的事，

444
00:25:11,620 --> 00:25:14,890
所以接口像 xv6 一样，是吗，

445
00:25:14,890 --> 00:25:21,040
进程必须把一些东西放在某些寄存器上，

446
00:25:21,040 --> 00:25:25,060
然后它们调用 ecall ，或者不管它是什么。

447
00:25:25,060 --> 00:25:26,980
是的，我会再多说一点，

448
00:25:26,980 --> 00:25:29,020
但它是完全一样的，没有什么不同。

449
00:25:29,530 --> 00:25:30,970
好的，我明白了，谢谢。

450
00:25:32,860 --> 00:25:36,070
一些功能已经提过了，

451
00:25:36,070 --> 00:25:39,400
或许多核值得讨论一下，

452
00:25:39,760 --> 00:25:42,130
Go 对并发的良好支持，

453
00:25:42,130 --> 00:25:44,140
Biscuit 的多核，

454
00:25:44,260 --> 00:25:49,180
以同样方式， xv6 对多核的支持有限，

455
00:25:49,270 --> 00:25:50,560
在这里，我们有

456
00:25:50,560 --> 00:25:55,030
比 xv6 有更细粒度的同步或协调。

457
00:25:55,500 --> 00:25:57,990
它有用户级线程，

458
00:25:58,050 --> 00:26:01,920
由内核线程[提供]，

459
00:26:01,920 --> 00:26:03,570
这是 xv6 没有的，

460
00:26:03,900 --> 00:26:06,150
有日志文件系统，具有更高的性能，

461
00:26:06,150 --> 00:26:09,240
你会在 ext3 论文中看到，

462
00:26:09,450 --> 00:26:13,230
就像 ext3 文件系统。

463
00:26:14,000 --> 00:26:17,930
它有，相当合理，复杂的存储系统，

464
00:26:17,960 --> 00:26:19,400
使用 VMA ，

465
00:26:19,490 --> 00:26:22,760
它可以支持 mmap 之类的东西。

466
00:26:23,270 --> 00:26:25,160
它有一个完整的 TCP/IP 协议栈，

467
00:26:25,160 --> 00:26:29,330
可以通过互联网与其他网络服务器进行通信，

468
00:26:29,480 --> 00:26:33,230
它有两个高性能的驱动器，

469
00:26:33,230 --> 00:26:34,730
比如一个万兆网卡，

470
00:26:35,000 --> 00:26:36,380
在接下来的实验里，

471
00:26:36,380 --> 00:26:40,130
你可以实现一个非常简单的网卡的驱动，

472
00:26:40,130 --> 00:26:43,340
这是一个更高性能和更复杂的驱动程序。

473
00:26:43,770 --> 00:26:45,810
在一个相当复杂的驱动程序中，

474
00:26:45,870 --> 00:26:49,500
比 VIRTIO_DISK 驱动程序更复杂，

475
00:26:49,680 --> 00:26:56,140
你可能在实验里见过的。

476
00:27:06,680 --> 00:27:11,360
那么，就我前面提到的一个用户程序，

477
00:27:11,360 --> 00:27:13,700
每个用户程序运行自己的页表，

478
00:27:14,000 --> 00:27:16,970
用户内核内存由硬件区分，

479
00:27:16,970 --> 00:27:19,580
使用一个内核位，

480
00:27:20,780 --> 00:27:25,250
并且每个用户线程都有对应的内核线程，

481
00:27:25,250 --> 00:27:27,710
比如，当用户线程进行系统调用时，

482
00:27:27,830 --> 00:27:31,460
它将继续在相应的内核线程上运行，

483
00:27:31,640 --> 00:27:33,080
如果系统调用阻塞，

484
00:27:33,080 --> 00:27:35,120
那么另一个在相同地址空间的用户线程，

485
00:27:35,120 --> 00:27:37,910
用户地址空间可能会由内核调度。

486
00:27:38,990 --> 00:27:40,520
如前所述，

487
00:27:40,550 --> 00:27:43,850
内核线程是由 Go 运行时提供的，

488
00:27:43,880 --> 00:27:45,350
所以它们只是 Go 协程。

489
00:27:46,070 --> 00:27:48,170
所以，如果你编写过，

490
00:27:48,170 --> 00:27:51,170
如果你使用 Go 编写过用户程序，

491
00:27:51,170 --> 00:27:55,490
并使用 Go 调用来创建线程，

492
00:27:55,640 --> 00:27:57,890
那些 Go 协程就是

493
00:27:57,890 --> 00:27:59,630
Biscuit 内核使用的。

494
00:28:02,410 --> 00:28:03,790
说到系统调用，

495
00:28:03,790 --> 00:28:07,360
这个问题是刚刚被问到的，

496
00:28:07,660 --> 00:28:12,190
它的工作原理与 xv6 中大致相同，

497
00:28:12,190 --> 00:28:15,370
用户线程将参数放入寄存器中，

498
00:28:15,370 --> 00:28:17,470
使用一个小的库，

499
00:28:17,470 --> 00:28:21,400
它提供了系统调用接口，

500
00:28:21,400 --> 00:28:24,040
然后用户线程执行 SYSENTER 调用，

501
00:28:24,040 --> 00:28:27,490
Biscuit 在 x86 处理器上运行，

502
00:28:27,490 --> 00:28:29,050
而不是在 RISC-V 处理器上，

503
00:28:29,050 --> 00:28:32,350
x86 系统内核中的汇编指令

504
00:28:32,350 --> 00:28:35,470
与 RISC-V 上的略有不同，

505
00:28:36,280 --> 00:28:40,270
但是与 RISC-V 类似，

506
00:28:40,270 --> 00:28:43,060
然后控制权传递给内核线程，

507
00:28:43,650 --> 00:28:45,930
运行那个用户线程的（内核线程），

508
00:28:46,350 --> 00:28:48,720
然后内核线程执行系统调用，

509
00:28:48,720 --> 00:28:50,580
然后使用 SYSEXIT 返回。

510
00:28:51,180 --> 00:28:52,530
大致相同的框架，

511
00:28:52,530 --> 00:28:55,170
它建立一个 trapframe 和其他东西，

512
00:28:57,910 --> 00:28:58,630
好吗？

513
00:29:01,040 --> 00:29:02,390
到目前为止，有什么问题吗，

514
00:29:02,950 --> 00:29:05,200
在我深入讨论更多之前，

515
00:29:05,350 --> 00:29:08,270
意料之外和意料之内的东西，

516
00:29:08,270 --> 00:29:10,430
但我们会有更多不同的挑战，

517
00:29:10,430 --> 00:29:13,250
我想与 xv6 比起来。

518
00:29:13,920 --> 00:29:14,790
我有个问题，

519
00:29:14,790 --> 00:29:17,630
我想，我认为,

520
00:29:18,270 --> 00:29:24,630
Go 希望你更多地使用管道而不是互斥锁，

521
00:29:24,630 --> 00:29:28,230
我想，会不会是，

522
00:29:29,040 --> 00:29:31,680
xv6 中某些东西的设计，

523
00:29:31,680 --> 00:29:35,130
可以使用管道，而不是持有锁。

524
00:29:35,550 --> 00:29:38,070
是的，这是一个很好的问题，

525
00:29:38,070 --> 00:29:40,590
我会在再次回到这个问题上，

526
00:29:40,680 --> 00:29:41,580
再往下看，

527
00:29:41,580 --> 00:29:43,380
我们有几张幻灯片，

528
00:29:43,380 --> 00:29:46,920
关于我们在 Biscuit 中使用了 Go 的哪些特性，

529
00:29:46,920 --> 00:29:51,030
但是，我们没有使用很多的管道，

530
00:29:51,060 --> 00:29:53,760
我们主要使用锁和条件变量。

531
00:29:54,250 --> 00:29:56,950
所以，跟 xv6 的方法很像，

532
00:29:56,950 --> 00:30:00,640
而不是使用管道的，

533
00:30:00,730 --> 00:30:03,700
我们进行了文件系统设计的实验，

534
00:30:03,700 --> 00:30:06,220
对它使用更多的管道，

535
00:30:06,460 --> 00:30:09,130
结果不是很好，

536
00:30:09,220 --> 00:30:10,510
并且我们得到差的性能，

537
00:30:10,720 --> 00:30:15,550
所以，我们又换回了一种更简单的同步方式，

538
00:30:15,550 --> 00:30:17,770
xv6 或 Linux 使用的那样。

539
00:30:21,740 --> 00:30:26,480
好的，这里有几个难题或挑战，

540
00:30:26,480 --> 00:30:27,830
在我们实现的过程中，

541
00:30:28,070 --> 00:30:31,820
第一，我们必须让运行时在裸机上运行，

542
00:30:31,940 --> 00:30:34,460
这需要，你想要，

543
00:30:34,460 --> 00:30:38,060
对运行时进行零修改，尽可能少地修改，

544
00:30:38,060 --> 00:30:40,820
让 Go 有新版本的运行时，

545
00:30:40,820 --> 00:30:41,630
我们可以直接用它。

546
00:30:42,180 --> 00:30:45,330
事实上，多年来，

547
00:30:45,330 --> 00:30:48,540
我们在做这件事，代码也在做这件事，

548
00:30:48,540 --> 00:30:51,600
我们升级了运行库很多次。

549
00:30:52,210 --> 00:30:53,950
这是一件好事，

550
00:30:53,950 --> 00:30:54,520
事实证明，

551
00:30:54,520 --> 00:30:57,640
它们并不是很难在裸机上工作。

552
00:30:58,170 --> 00:31:02,220
Go 是精心设计的，

553
00:31:02,220 --> 00:31:04,890
对操作系统是不可知的，

554
00:31:04,890 --> 00:31:07,050
因为它们希望能够运行在多个操作系统上，

555
00:31:07,050 --> 00:31:09,210
所以，它不依赖于大量的操作系统功能。

556
00:31:09,970 --> 00:31:13,570
我们基本上模拟了需要的功能，

557
00:31:13,750 --> 00:31:15,520
大多数这些功能，

558
00:31:15,520 --> 00:31:18,490
使 Go 运行时可以开始运行，

559
00:31:18,850 --> 00:31:20,650
一旦启动，它就会继续运行。

560
00:31:24,470 --> 00:31:28,670
我们有一些 Go 协程运行不同应用程序的范围，

561
00:31:28,700 --> 00:31:34,220
通常在 Go 程序中，一个单一的应用程序，

562
00:31:34,490 --> 00:31:36,560
这里，我们使用 Go 协程，

563
00:31:36,560 --> 00:31:40,220
在不同的用户应用程序之间。

564
00:31:40,670 --> 00:31:44,900
但是用户应用程序必须与不同的页表一起运行。

565
00:31:45,490 --> 00:31:49,240
这里的[]是，

566
00:31:49,240 --> 00:31:53,230
我们或 Biscuit 不能控制调度器，

567
00:31:53,260 --> 00:31:55,630
因为我们使用的是未修改的 Go 运行时，

568
00:31:55,630 --> 00:31:57,370
所以我们使用的是 Go 运行时调度器，

569
00:31:57,520 --> 00:32:00,010
所以在这个调度器中，我们不能切换页表。

570
00:32:00,460 --> 00:32:05,710
在 Biscuit 中所做的与 xv6 很像，

571
00:32:05,710 --> 00:32:07,450
它切换页表，

572
00:32:07,450 --> 00:32:11,050
当它从内核空间切换到用户空间，或者相反。

573
00:32:12,030 --> 00:32:16,860
所以当进入和退出内核时，切换页表。

574
00:32:17,360 --> 00:32:19,310
这意味着像在 xv6 中，

575
00:32:19,310 --> 00:32:21,590
当你需要复制数据，

576
00:32:21,590 --> 00:32:24,050
从用户空间到内核空间或相反时，

577
00:32:24,140 --> 00:32:27,500
你必须使用 copyin 和 copyout 函数，

578
00:32:27,500 --> 00:32:28,760
我们在 xv6 中已有的，

579
00:32:28,760 --> 00:32:30,890
你需要做页表扫描软件。

580
00:32:33,550 --> 00:32:38,150
另一个挑战是设备中断，

581
00:32:38,600 --> 00:32:41,360
Go 运行时通常在用户模式下运行，

582
00:32:41,420 --> 00:32:44,810
它不会收到来自硬件的中断，

583
00:32:45,200 --> 00:32:47,450
但是我们在裸机上使用它，

584
00:32:47,450 --> 00:32:48,980
所以我们会得到中断，

585
00:32:49,040 --> 00:32:51,830
时钟中断，网络驱动中断，

586
00:32:51,830 --> 00:32:55,850
磁盘驱动中断，比如 UART 。

587
00:32:56,290 --> 00:32:58,150
所以我们需要解决这个问题，

588
00:32:58,150 --> 00:33:01,900
而且在 Go 中也没有这个概念，

589
00:33:01,900 --> 00:33:05,500
在持有锁的同时关闭中断，

590
00:33:05,890 --> 00:33:08,500
因为它只显示用户应用程序，

591
00:33:08,800 --> 00:33:14,290
所以，我们需要对如何写入设备中断很小心，

592
00:33:14,290 --> 00:33:16,330
我们的做法是，

593
00:33:16,330 --> 00:33:18,520
我们在设备中断时几乎什么都不做，

594
00:33:18,700 --> 00:33:20,140
我们不使用任何锁，

595
00:33:20,170 --> 00:33:22,450
我们不分配任何内存，

596
00:33:22,750 --> 00:33:23,980
我们唯一做的是，

597
00:33:23,980 --> 00:33:27,190
把标志送到某个没有被中断的地方，

598
00:33:27,370 --> 00:33:31,900
然后唤醒一个有效的 Go 协程来处理中断。

599
00:33:35,000 --> 00:33:38,240
而那个 Go 协程，当然你可以使用它的所有 Go 的功能。

600
00:33:39,160 --> 00:33:41,620
因为它在中断处理程序的上下文中运行，

601
00:33:41,620 --> 00:33:44,080
只是在正常的 Go 协程中运行。

602
00:33:45,410 --> 00:33:48,830
还有一件令人惊讶的事，

603
00:33:48,860 --> 00:33:51,380
前三件事是完全预料到的，

604
00:33:51,380 --> 00:33:54,350
当构建 Biscuit 时，我们必须要处理的，

605
00:33:54,350 --> 00:33:57,440
最让我们惊讶的一件事，

606
00:33:57,770 --> 00:33:59,930
我们学到了很多，

607
00:33:59,930 --> 00:34:02,120
就是堆耗尽的难题。

608
00:34:02,760 --> 00:34:05,610
所以，我将主要讨论堆耗尽的问题，

609
00:34:05,610 --> 00:34:07,770
它是什么，它是怎么来的，

610
00:34:07,770 --> 00:34:09,030
以及我们是如何解决它的，

611
00:34:09,030 --> 00:34:10,740
但是在深入讨论这个问题之前，

612
00:34:11,040 --> 00:34:12,750
到目前为止，有什么问题吗？

613
00:34:18,810 --> 00:34:20,460
好的，都清楚了。

614
00:34:24,540 --> 00:34:26,700
好的，那么让我们来讨论一下堆耗尽的问题，

615
00:34:26,700 --> 00:34:28,650
我不打算全面深入地讨论论文中的内容，

616
00:34:28,650 --> 00:34:31,650
但至少让你对问题有所了解。

617
00:34:40,940 --> 00:34:42,560
所以，在堆耗尽的情况下，

618
00:34:42,590 --> 00:34:46,430
让我们再次假设这里的蓝框是内核，

619
00:34:49,450 --> 00:34:51,310
内核有一个堆，

620
00:34:51,340 --> 00:34:54,610
是从动态内存中分配的，

621
00:34:54,610 --> 00:34:56,350
在 xv6 中，我们没有这样的堆，

622
00:34:56,350 --> 00:34:58,450
因为我们在内核中没有内存分配器，

623
00:34:58,450 --> 00:34:59,620
所有东西都是静态分配的，

624
00:34:59,650 --> 00:35:01,960
但是任何其他内核中，我们都会有一个堆，

625
00:35:01,960 --> 00:35:06,250
你可以调用内核中的 malloc 和 free 。

626
00:35:08,120 --> 00:35:10,640
这些东西实际上是在堆中分配的，

627
00:35:10,640 --> 00:35:17,600
比如，套接字对象，文件描述符对象或进程对象，

628
00:35:17,900 --> 00:35:19,820
proc 结构体， fd 结构体，

629
00:35:19,820 --> 00:35:23,600
所有我们在 xv6 中静态分配的结构体，

630
00:35:23,720 --> 00:35:25,880
一般的内核，它们会动态分配它们，

631
00:35:26,360 --> 00:35:28,040
所以，当你打开新的文件描述符时，

632
00:35:28,040 --> 00:35:30,830
堆中将分配一个文件描述符对象。

633
00:35:32,230 --> 00:35:33,700
所以，问题是，

634
00:35:33,700 --> 00:35:35,560
如果你运行多个应用程序，

635
00:35:35,560 --> 00:35:38,680
它们可能会打开很多文件描述符，很多套接字，

636
00:35:38,770 --> 00:35:41,380
它们开始缓慢地填满堆，

637
00:35:41,530 --> 00:35:43,870
所以问题是，

638
00:35:43,870 --> 00:35:45,490
在某个时刻，比如堆满了，

639
00:35:45,880 --> 00:35:49,420
没有空间用于分配新对象，

640
00:35:49,420 --> 00:35:53,080
或者当应用程序请求打开新的文件描述符时，

641
00:35:53,080 --> 00:35:56,290
有新的进程，新的 fork ，

642
00:35:56,440 --> 00:35:58,690
内核想要分配一个 proc 结构体，

643
00:35:58,690 --> 00:36:00,790
而堆已经没有空间了。

644
00:36:01,660 --> 00:36:03,580
然后你怎么做，

645
00:36:03,760 --> 00:36:06,280
你做什么，

646
00:36:06,340 --> 00:36:08,470
你怎么处理这个特殊的情况，

647
00:36:08,770 --> 00:36:09,730
这通常，

648
00:36:09,730 --> 00:36:13,210
可能在通常情况下，不会经常出现，

649
00:36:13,300 --> 00:36:15,820
但是如果你重度使用机器，

650
00:36:15,820 --> 00:36:19,420
你有几个重度的使用者进程运行用户级进程，

651
00:36:19,450 --> 00:36:20,800
你可能会遇到这种情况，

652
00:36:20,800 --> 00:36:24,250
所有可用内存都在使用，

653
00:36:24,310 --> 00:36:26,320
你的堆已经满了。

654
00:36:27,120 --> 00:36:29,880
而且没有进程调用 free ，

655
00:36:29,880 --> 00:36:31,170
因为它们都在运行，

656
00:36:31,170 --> 00:36:34,920
并试图为它们的工作分配更多的资源。

657
00:36:39,790 --> 00:36:42,070
所以，所有内核都会面临这个问题，

658
00:36:42,070 --> 00:36:45,070
不论是 C 内核或 Biscuit 或其他任何东西，

659
00:36:45,070 --> 00:36:47,470
任何内核都必须解决这个问题。

660
00:36:48,290 --> 00:36:50,630
它们之所以出现在我们面前，

661
00:36:50,630 --> 00:36:54,410
作为 Biscuit 中的一个严重问题，

662
00:36:54,410 --> 00:36:59,000
是因为在许多内核中，

663
00:37:01,270 --> 00:37:03,610
你可以在 malloc 上返回错误，

664
00:37:03,670 --> 00:37:06,040
xv6 偶尔会这么做，

665
00:37:06,040 --> 00:37:07,930
但是在 Go 运行时中，

666
00:37:07,930 --> 00:37:10,870
当你调用 new 来分配 Go 对象时，

667
00:37:11,080 --> 00:37:13,990
没有错误条件， new 就成功了，

668
00:37:14,400 --> 00:37:16,200
所以没有办法让它失败。

669
00:37:16,740 --> 00:37:22,050
所以让我们讨论一下解决这个问题的可能的方法，

670
00:37:22,770 --> 00:37:26,790
我们偶尔会在 xv6 上看到它，

671
00:37:26,790 --> 00:37:29,850
如果你还记得 bcache ，

672
00:37:29,850 --> 00:37:34,920
如果 xv6 找不到新的块，

673
00:37:34,920 --> 00:37:37,950
一个空闲的块来保存磁盘块，

674
00:37:38,040 --> 00:37:39,630
有时只是抛出 panic 。

675
00:37:40,060 --> 00:37:44,890
这显然是一个完全不期望的解决方案，

676
00:37:44,890 --> 00:37:46,180
也不是一个真正的解决方案，

677
00:37:46,180 --> 00:37:48,280
所以我们称为 strawman 解决方案。

678
00:37:49,010 --> 00:37:52,220
另一种 strawman 解决方案是，

679
00:37:52,250 --> 00:37:55,730
当你调用，比如分配一块新的内存时，

680
00:37:55,730 --> 00:37:59,300
你调用 alloc new 来分配它，

681
00:37:59,600 --> 00:38:02,120
你可以等待内存分配器，

682
00:38:02,820 --> 00:38:04,410
它是一个提议，

683
00:38:04,470 --> 00:38:06,150
结果证明不是一个好的提议，

684
00:38:06,570 --> 00:38:10,500
它不是一个好提议的原因是，你可能会陷入死锁，

685
00:38:10,530 --> 00:38:12,700
假设下面的场景，

686
00:38:12,700 --> 00:38:13,570
你持有一些，

687
00:38:13,570 --> 00:38:15,550
比如，内核有一个很大的内核锁，

688
00:38:15,820 --> 00:38:20,470
然后调用 malloc ，等待内存分配器，

689
00:38:20,770 --> 00:38:22,840
那么就没有其他进程可以运行了。

690
00:38:23,530 --> 00:38:26,470
你的下一个进程中会有死锁，

691
00:38:26,470 --> 00:38:29,980
它尝试运行，比如释放一些内存，

692
00:38:29,980 --> 00:38:31,720
不能运行，其实死锁了。

693
00:38:32,490 --> 00:38:33,180
当然，这是，

694
00:38:33,180 --> 00:38:36,090
如果你有一个很大的内核锁，这是一个明显的问题，

695
00:38:36,090 --> 00:38:40,590
但是即使你有一个非常小的，细粒度的锁，

696
00:38:40,650 --> 00:38:42,210
它很容易运行到这种情况，

697
00:38:42,210 --> 00:38:48,030
等待分配器的进程持有某种锁，

698
00:38:48,030 --> 00:38:50,220
而其他进程需要释放内存，

699
00:38:50,840 --> 00:38:53,420
这会导致你陷入死锁。

700
00:38:54,710 --> 00:39:00,290
所以我们知道 strawman free 失败了，

701
00:39:00,470 --> 00:39:03,440
或者当不再有内存时，

702
00:39:03,440 --> 00:39:06,590
alloc 返回没有指针，检查没有指针，

703
00:39:06,590 --> 00:39:09,200
你不能使用[]来失败。

704
00:39:09,840 --> 00:39:14,070
但是[]并没有那么简单，

705
00:39:14,070 --> 00:39:17,790
进程可能已经分配了内存，

706
00:39:17,820 --> 00:39:19,110
你需要扔掉它，

707
00:39:19,230 --> 00:39:21,900
你可能已经执行了部分磁盘操作，

708
00:39:21,900 --> 00:39:23,550
比如，如果你执行多个步骤，

709
00:39:23,610 --> 00:39:26,340
部分操作可能完成了部分，但不是全部，

710
00:39:26,340 --> 00:39:27,420
你必须跳出困境。

711
00:39:27,880 --> 00:39:31,570
所以，要做对是非常困难的。

712
00:39:32,340 --> 00:39:37,170
有趣的是，当你深入研究这件事时，

713
00:39:37,260 --> 00:39:40,020
考虑如何解决这个问题，

714
00:39:40,140 --> 00:39:43,020
Linux 使用了这两种解决方案。

715
00:39:43,500 --> 00:39:47,550
这两种都有麻烦或问题，

716
00:39:47,730 --> 00:39:52,530
事实上，内核开发人员很难弄清楚这些，

717
00:39:52,560 --> 00:39:54,330
如果你对这个很感兴趣，

718
00:39:54,330 --> 00:39:56,370
并且想看一些有趣的讨论，

719
00:39:56,880 --> 00:39:58,710
在谷歌上搜索 too small to fail，

720
00:39:58,890 --> 00:40:02,730
有一篇文章谈到了其中的一些复杂情况，

721
00:40:02,730 --> 00:40:06,990
释放内存或等待分配器，

722
00:40:06,990 --> 00:40:09,660
以及可能导致的问题。

723
00:40:10,650 --> 00:40:12,930
现在，对我们来说，

724
00:40:12,930 --> 00:40:15,210
strawman 2 就是解决方案，

725
00:40:15,210 --> 00:40:16,140
你可以想象到，

726
00:40:16,140 --> 00:40:16,800
但是对于我们来说，

727
00:40:16,800 --> 00:40:19,620
就像前面提到的，这是不可能的，

728
00:40:19,620 --> 00:40:23,070
因为 new 不能返回，不能失败，

729
00:40:23,100 --> 00:40:24,480
它总是成功的，

730
00:40:24,540 --> 00:40:27,300
所以在某种程度上，这种情况不会发生。

731
00:40:28,590 --> 00:40:31,710
另外，这两种解决方案都不是特别理想，

732
00:40:31,710 --> 00:40:35,160
所以我们要想出一些更好的东西。

733
00:40:36,780 --> 00:40:40,260
到目前为止，关于堆耗尽的设置，有什么问题吗，

734
00:40:40,260 --> 00:40:42,720
在我谈论 Biscuit 是怎么做的之前。

735
00:40:48,420 --> 00:40:49,500
这个问题能理解吗？

736
00:40:58,960 --> 00:41:02,170
我理解为“是的”，然后继续，

737
00:41:02,170 --> 00:41:03,910
但可以随时可以打断。

738
00:41:06,800 --> 00:41:08,810
好的，那么 Biscuit 的解决方案是什么，

739
00:41:08,840 --> 00:41:13,790
从高层级来看， Biscuit 的解决方案几乎是直截了当的，

740
00:41:14,420 --> 00:41:15,890
它所做的是，

741
00:41:15,890 --> 00:41:19,670
当你执行系统调用比如 read 或 fork ，

742
00:41:20,420 --> 00:41:23,900
在进入 fork 系统调用之前，

743
00:41:23,930 --> 00:41:25,910
在 fork 系统调用的开始的地方，

744
00:41:25,910 --> 00:41:28,970
比如 xv6 中的系统调用调度器，

745
00:41:28,970 --> 00:41:31,520
然后，它做的第一件事就是调用 reserve ，

746
00:41:32,630 --> 00:41:34,880
它保留了足够的内存，

747
00:41:35,120 --> 00:41:37,700
以便能够执行系统调用。

748
00:41:38,380 --> 00:41:42,430
所以有足够的空闲内存，

749
00:41:42,430 --> 00:41:45,730
无论系统调用需要的内存是什么，

750
00:41:45,910 --> 00:41:49,570
保留会足够大，也会成功。

751
00:41:50,430 --> 00:41:53,010
所以，一旦系统调用开始，

752
00:41:53,010 --> 00:41:55,560
并且成功地保留了内存，

753
00:41:55,560 --> 00:41:57,390
它会一直运行，

754
00:41:57,420 --> 00:41:59,100
我们不会再遇到这个问题，

755
00:41:59,100 --> 00:42:01,950
这里没有足够的内存或堆耗尽。

756
00:42:03,340 --> 00:42:05,200
如果没有足够的内存，

757
00:42:05,200 --> 00:42:06,790
在你想要预留的时候，

758
00:42:06,820 --> 00:42:08,290
那就在这里等待，

759
00:42:09,940 --> 00:42:11,920
但是在系统调用开始时，

760
00:42:11,920 --> 00:42:13,660
系统调用不持有任何锁，

761
00:42:13,660 --> 00:42:15,040
没有持有任何资源，

762
00:42:15,040 --> 00:42:16,480
所以它是非常好的，

763
00:42:16,480 --> 00:42:21,190
在这里等待，没有死锁的风险。

764
00:42:22,160 --> 00:42:23,660
当它在等待的时候，

765
00:42:23,690 --> 00:42:26,540
它当然可以做，它可以调用，

766
00:42:26,540 --> 00:42:29,690
内核可以驱逐缓存，

767
00:42:29,690 --> 00:42:33,620
尝试减少，释放堆空间，

768
00:42:33,800 --> 00:42:36,920
也许像你看到的，

769
00:42:36,920 --> 00:42:41,000
也许会杀死一个进程，强制释放内存。

770
00:42:41,590 --> 00:42:43,990
然后一旦内存可用，

771
00:42:43,990 --> 00:42:47,020
内核决定，可以满足预订，

772
00:42:47,020 --> 00:42:50,020
然后它会让系统调用开始并运行，

773
00:42:50,170 --> 00:42:52,570
然后执行它需要做的任何事情，

774
00:42:52,900 --> 00:42:55,060
然后在最后，当系统调用完成时，

775
00:42:55,060 --> 00:42:56,170
它说，好的，我完成了，

776
00:42:56,350 --> 00:42:59,410
所有保留的内存都回到池中，

777
00:42:59,620 --> 00:43:02,380
可用于后续的系统调用。

778
00:43:03,770 --> 00:43:07,310
这个解决方案有几个很好的特性，

779
00:43:07,310 --> 00:43:09,980
内核本身不需要检查，

780
00:43:10,010 --> 00:43:14,390
你永远不需要检查内存分配是否会失败，

781
00:43:14,570 --> 00:43:16,190
这在我们的情况下很好，

782
00:43:16,190 --> 00:43:18,110
因为 Go 是不会失败的。

783
00:43:18,620 --> 00:43:20,960
这里不需要错误处理代码，

784
00:43:21,080 --> 00:43:22,400
而且没有死锁的风险，

785
00:43:22,400 --> 00:43:24,860
因为你在一开始就避免了，

786
00:43:24,860 --> 00:43:26,300
没有持有锁。

787
00:43:27,010 --> 00:43:29,830
当然，有很多很棒的，

788
00:43:29,980 --> 00:43:32,290
唯一的问题是一个挑战，

789
00:43:32,290 --> 00:43:33,640
你怎么做预留，

790
00:43:33,880 --> 00:43:34,930
你怎么计算，

791
00:43:34,960 --> 00:43:42,710
系统调用需要多少内存来执行它。

792
00:43:43,590 --> 00:43:45,300
所以现在我们有了一个难题。

793
00:43:47,780 --> 00:43:52,460
你保留的数量是很重要的，

794
00:43:52,460 --> 00:43:53,660
你可以做的一件事是，

795
00:43:53,660 --> 00:43:55,940
你可以保留一半的内存或类似的东西，

796
00:43:55,940 --> 00:43:58,640
对每个系统调用来说都是夸张的内存量，

797
00:43:58,670 --> 00:44:01,850
但也这意味着你限制了可以并发执行的系统调用的数量，

798
00:44:01,850 --> 00:44:03,950
所以你想在某种程度上把工作做得很好，

799
00:44:03,980 --> 00:44:07,220
计算出内存量边界，

800
00:44:07,220 --> 00:44:09,970
系统调用可能需要的（内存量）。

801
00:44:11,050 --> 00:44:17,290
所以，我们做这件事的方式，

802
00:44:17,290 --> 00:44:22,240
是高级语言帮助我们的，

803
00:44:22,390 --> 00:44:25,450
Go 是很容易在进行静态分析的，

804
00:44:25,450 --> 00:44:30,490
事实上， Go 运行时和 Go 基础架构生态系统

805
00:44:30,490 --> 00:44:33,580
附带了很多用于分析 Go 代码的软件包。

806
00:44:34,100 --> 00:44:37,400
我们使用这些软件包来计算

807
00:44:37,700 --> 00:44:42,920
系统调用需要的内存量，

808
00:44:42,950 --> 00:44:44,060
所以你可以考虑，

809
00:44:44,060 --> 00:44:47,240
比如，你有一个 read 系统调用，

810
00:44:47,240 --> 00:44:50,810
我们可以查看系统调用的调用图，

811
00:44:50,810 --> 00:44:54,440
调用函数 f ，调用函数 g ，调用函数 h ，等等，

812
00:44:54,440 --> 00:44:55,790
可能会有很多，

813
00:44:55,910 --> 00:44:58,130
在系统调用结束时，

814
00:44:58,130 --> 00:44:59,060
它再次[绑定]到[堆栈]，

815
00:44:59,060 --> 00:45:01,880
然后返回到用户空间。

816
00:45:02,520 --> 00:45:04,200
我们能做的就是，

817
00:45:04,200 --> 00:45:08,370
分配，或者计算出最大深度，

818
00:45:08,940 --> 00:45:13,770
关于这张调用图，

819
00:45:14,330 --> 00:45:16,100
在任何时间，

820
00:45:16,130 --> 00:45:17,930
然后对于这个最大深度，

821
00:45:17,930 --> 00:45:21,770
计算出每个函数需要多少实时内存，

822
00:45:21,770 --> 00:45:25,640
所以，如果函数调用 new ，分配内存，

823
00:45:25,670 --> 00:45:27,830
我们知道这里有什么类型的对象，

824
00:45:27,860 --> 00:45:28,910
我们使用高级语言，

825
00:45:28,910 --> 00:45:30,770
所以我们可以计算出对象的大小，

826
00:45:30,770 --> 00:45:33,590
我们可以把它们加起来，得到一个数字 s ，

827
00:45:33,620 --> 00:45:36,650
也就是说，内存总量或最大内存量，

828
00:45:36,650 --> 00:45:42,290
那个调用图可以在任何时间活动。

829
00:45:43,290 --> 00:45:45,420
原因是，这有点棘手，

830
00:45:45,420 --> 00:45:46,590
它不是这么简单的，

831
00:45:46,590 --> 00:45:50,280
因为，比如函数 h 可能分配了一些内存，

832
00:45:50,800 --> 00:45:53,470
然后传递回 g ，

833
00:45:53,530 --> 00:45:55,090
所以 h 结束了，

834
00:45:55,510 --> 00:46:00,820
但是 g 得到了 h 分配的内存，

835
00:46:01,120 --> 00:46:03,430
这称为逃逸，

836
00:46:03,430 --> 00:46:08,390
内存从 h 逃逸到 g ，

837
00:46:08,390 --> 00:46:12,770
有一些标准算法做这种逃逸分析，

838
00:46:12,770 --> 00:46:15,560
确定哪些变量逃逸到调用方，

839
00:46:16,010 --> 00:46:17,570
在这种情况下，

840
00:46:17,570 --> 00:46:20,690
无论 h 分配的是什么内存，它仍然是活动的，

841
00:46:20,690 --> 00:46:22,880
我们必须加上 g 的，

842
00:46:23,760 --> 00:46:25,890
所以我们必须加到 s 中。

843
00:46:27,040 --> 00:46:28,510
关于这个，我有一个简短的问题，

844
00:46:29,440 --> 00:46:32,470
所以让我们在一些函数中做更多假设，

845
00:46:32,800 --> 00:46:36,490
根据函数预期的不同工作负荷，

846
00:46:36,790 --> 00:46:40,150
可能分配了不同的内存量，

847
00:46:40,360 --> 00:46:44,590
那么是否有内存分配进程的最坏情况？

848
00:46:44,620 --> 00:46:47,170
是的，这是一种保守的方案，

849
00:46:47,170 --> 00:46:51,430
我们计算，这个工具计算，

850
00:46:51,430 --> 00:46:56,200
最坏的函数调用深度。

851
00:46:56,830 --> 00:47:00,040
从最坏的情况来看，

852
00:47:00,040 --> 00:47:03,940
分析系统调用可能需要多少内存，

853
00:47:03,970 --> 00:47:06,760
在实践中，系统调用可能需要少得多，

854
00:47:06,940 --> 00:47:10,210
但是为了保守，

855
00:47:10,210 --> 00:47:13,240
我们必须为最坏的情况分配打算。

856
00:47:14,000 --> 00:47:18,050
所以我们在这里谈到了几个重要的观点，

857
00:47:18,050 --> 00:47:21,830
因为，一些系统调用比如执行 for 循环，

858
00:47:21,830 --> 00:47:25,020
这取决于系统调用的参数，

859
00:47:25,020 --> 00:47:27,600
你实际上不能静态地计算出界限是什么，

860
00:47:27,990 --> 00:47:31,260
所以，在很多情况下，我们对代码进行了注释，

861
00:47:31,260 --> 00:47:33,900
表示这是循环的最大界限，

862
00:47:34,200 --> 00:47:36,210
你可以假设不会超过这个，

863
00:47:36,210 --> 00:47:38,700
并用它来实际计算这个数字 s 。

864
00:47:39,990 --> 00:47:43,620
同样地，如果你有一个递归函数，

865
00:47:43,980 --> 00:47:46,290
谁知道递归有多深，

866
00:47:46,470 --> 00:47:48,210
这也可能依赖于

867
00:47:48,210 --> 00:47:50,730
动态变量或系统调用的参数。

868
00:47:51,220 --> 00:47:55,150
事实上，我们在某些地方处理 Biscuit ，

869
00:47:55,150 --> 00:47:57,490
避免了递归函数传递，

870
00:47:57,820 --> 00:48:01,990
所以做这个分析是可能的。

871
00:48:02,770 --> 00:48:04,510
所以这种分析不是免费的，

872
00:48:04,510 --> 00:48:05,620
它不是完全自动的，

873
00:48:05,800 --> 00:48:08,980
对于这种情况，它需要几天的工作，

874
00:48:08,980 --> 00:48:16,240
Cody 查看所有这些循环，然后注释。

875
00:48:16,840 --> 00:48:19,540
还有一些 Go 的具体的问题，

876
00:48:19,540 --> 00:48:20,560
你必须处理，

877
00:48:20,560 --> 00:48:22,960
比如切片，它们的大小可能会翻倍，

878
00:48:22,960 --> 00:48:25,150
如果您在切片中添加一个元素，

879
00:48:25,570 --> 00:48:29,500
那么我们模仿最大容量的切片，

880
00:48:29,800 --> 00:48:32,830
但是为了让这些可行用了很多天的工作，

881
00:48:32,860 --> 00:48:35,140
使用这个工具，

882
00:48:35,140 --> 00:48:37,660
你可以得到一个合理的数字，

883
00:48:38,080 --> 00:48:43,390
在计算最大内存量方面，

884
00:48:43,390 --> 00:48:44,830
系统调用所需的（最大内存量）。

885
00:48:46,150 --> 00:48:47,680
所以这就是

886
00:48:47,710 --> 00:48:50,890
Biscuit 解决这个问题的方式。

887
00:48:54,100 --> 00:48:57,910
哦，抱歉，人们还用这个工具做什么，

888
00:48:58,000 --> 00:49:00,250
比如，他们不是在构建内核，

889
00:49:00,250 --> 00:49:01,570
他们用它做什么？

890
00:49:01,600 --> 00:49:03,280
通过静态分析软件包。

891
00:49:03,910 --> 00:49:04,300
是的。

892
00:49:04,330 --> 00:49:08,260
Go 编译器使用它进行各种优化，

893
00:49:08,260 --> 00:49:12,490
做静态分析，

894
00:49:12,760 --> 00:49:17,380
Go 找出最好的方法来编译它。

895
00:49:18,270 --> 00:49:20,490
我明白了，好的，谢谢。

896
00:49:20,880 --> 00:49:23,640
所以这是这个软件包最酷的地方之一，

897
00:49:23,640 --> 00:49:25,020
编译器可以使用，

898
00:49:25,020 --> 00:49:26,250
我们可以做什么。

899
00:49:27,500 --> 00:49:31,790
我们稍后会看到，我们还会使用它的其他几个功能。

900
00:49:32,710 --> 00:49:34,570
这是非常方便的。

901
00:49:37,640 --> 00:49:39,020
好的。

902
00:49:40,580 --> 00:49:42,110
好的，转到实现，

903
00:49:42,200 --> 00:49:46,640
与其他内核非常相似，

904
00:49:46,640 --> 00:49:50,600
或者像 xv6 ，除了更高的性能。

905
00:49:51,070 --> 00:49:54,070
我们采用了

906
00:49:54,070 --> 00:49:58,090
很多 Linux 内核拥有的优化或智慧，

907
00:49:58,090 --> 00:50:00,400
至少在我们试图实现的系统调用上，

908
00:50:00,920 --> 00:50:05,840
对内核文本使用大页面，以避免 TLB 开销，

909
00:50:06,350 --> 00:50:13,460
我们有每个 CPU 的网卡传输队列，以避免端口之间的同步，

910
00:50:13,790 --> 00:50:14,900
我们有 RCU ，

911
00:50:14,900 --> 00:50:17,990
我会更多地讨论目录缓存，

912
00:50:17,990 --> 00:50:22,550
它是无锁或无读锁的目录高速缓存，

913
00:50:22,550 --> 00:50:25,280
在学期末，我们将更详细地讨论 RCU ，

914
00:50:25,280 --> 00:50:27,260
但是，这里会有一些，

915
00:50:29,720 --> 00:50:33,230
一种常见的优化类型，

916
00:50:33,230 --> 00:50:36,200
你需要获得高性能。

917
00:50:36,720 --> 00:50:40,020
我想我们学到的主要教训是，

918
00:50:40,320 --> 00:50:43,410
Go 并没有阻碍这些优化的实现，

919
00:50:44,160 --> 00:50:48,600
所以这些优化可以用 C 和 Linux 实现，

920
00:50:48,600 --> 00:50:51,390
我们可以实现相同的优化，

921
00:50:51,390 --> 00:50:52,680
但是在 Go 中实现，

922
00:50:52,890 --> 00:50:56,410
所以语言本身不是障碍或问题，

923
00:50:56,560 --> 00:51:00,040
实际上完全有利于实现这些优化。

924
00:51:01,460 --> 00:51:03,590
要实现这些优化需要做很多工作，

925
00:51:03,590 --> 00:51:05,720
但与语言无关。

926
00:51:09,810 --> 00:51:12,900
好的，这带来了某种评价，

927
00:51:12,900 --> 00:51:15,990
也就是整篇论文的动机，

928
00:51:15,990 --> 00:51:21,420
试图处理高级语言的好处和成本，

929
00:51:21,420 --> 00:51:24,670
所以，评价可以分成两部分，

930
00:51:24,670 --> 00:51:27,070
先讨论好处，再讨论成本。

931
00:51:29,370 --> 00:51:31,320
有三个问题，

932
00:51:31,320 --> 00:51:35,280
首先，有一个问题，比如没有作弊，

933
00:51:35,280 --> 00:51:38,400
也许我们避开了所有昂贵的高级语言特性，

934
00:51:38,940 --> 00:51:40,890
Go 提供的。

935
00:51:40,950 --> 00:51:45,180
第二个问题，当然是高级语言有没有简化 Biscuit 代码，

936
00:51:45,180 --> 00:51:47,640
并且会阻止一些漏洞，

937
00:51:47,640 --> 00:51:50,400
那些我在课程前面提到的。

938
00:51:51,300 --> 00:51:54,750
首先，关于使用高级语言特性，

939
00:51:54,990 --> 00:51:56,040
我们希望看到，

940
00:51:56,040 --> 00:51:59,370
我们是否与其他大的 Go 项目类似，

941
00:51:59,370 --> 00:52:00,540
在语言功能方面，

942
00:52:00,540 --> 00:52:01,410
所以我们可以说，

943
00:52:01,410 --> 00:52:04,080
整个内核做了，

944
00:52:04,080 --> 00:52:07,410
以相似的方式做相同功能，有相同的优点。

945
00:52:07,860 --> 00:52:10,980
所以我们使用相同的静态分析工具

946
00:52:10,980 --> 00:52:17,430
从根本上分析 GitHub 上的两个大的 Go 软件，

947
00:52:17,490 --> 00:52:19,110
它们有数百万行代码，

948
00:52:19,110 --> 00:52:21,690
一个是 Go 运行时本身和所有它的包，

949
00:52:21,960 --> 00:52:23,790
另一个是系统 Moby 。

950
00:52:24,550 --> 00:52:29,110
然后，我们计算高级语言特性出现的次数，

951
00:52:29,110 --> 00:52:31,270
每千行用了多少次，

952
00:52:31,360 --> 00:52:32,740
这张图显示这些，

953
00:52:32,740 --> 00:52:36,360
x 轴是语言特性。

954
00:52:36,390 --> 00:52:39,540
allocations 对应于调用 new ，

955
00:52:39,570 --> 00:52:41,400
这对应于内存，

956
00:52:41,400 --> 00:52:44,550
由垃圾收集器动态分配。

957
00:52:44,910 --> 00:52:49,080
maps 对应于哈希表，切片或动态数组，

958
00:52:49,080 --> 00:52:51,030
这是 channel 同步，

959
00:52:51,030 --> 00:52:53,280
正如你所看到的，我们很少使用它，

960
00:52:53,280 --> 00:52:55,410
但是 Go 运行时和 Moby 也是如此。

961
00:52:56,160 --> 00:52:58,950
显然，我们最喜欢的特性，

962
00:52:59,010 --> 00:53:04,260
它是函数多返回，能够返回多个值。

963
00:53:04,800 --> 00:53:06,750
我们使用闭包，

964
00:53:06,810 --> 00:53:08,550
我们没有使用 finalizer ，

965
00:53:08,580 --> 00:53:10,710
我们使用了一些 defer ，

966
00:53:10,710 --> 00:53:13,410
我们创造了很多 Go 协程，

967
00:53:13,410 --> 00:53:14,550
我们使用接口。

968
00:53:15,040 --> 00:53:18,760
类型断言，从一种类型转换为另一种类型，

969
00:53:19,180 --> 00:53:21,760
关于类型断言。

970
00:53:21,970 --> 00:53:24,310
并且导入很多包，

971
00:53:24,340 --> 00:53:27,220
内核本身是由多个软件包构建的，

972
00:53:27,220 --> 00:53:29,230
而不是一个大的单一程序。

973
00:53:29,880 --> 00:53:30,600
所以，如果你看这个，

974
00:53:30,600 --> 00:53:34,830
一些功能 Biscuit 比 Golang 和 Moby 使用得少，

975
00:53:34,830 --> 00:53:38,760
有时可能会或多或少失去一些功能，

976
00:53:39,970 --> 00:53:43,480
而不是以任何明显不同的方式。

977
00:53:44,090 --> 00:53:46,190
所以，由此得出的主要结论是，

978
00:53:46,190 --> 00:53:49,730
使用了 Go 提供的高级功能，

979
00:53:49,730 --> 00:53:55,190
不会为了获得好的性能而回避它们。

980
00:53:56,950 --> 00:53:58,270
好的。

981
00:53:58,850 --> 00:54:00,500
我有个问题，

982
00:54:01,430 --> 00:54:05,450
你怎么能数得清所有这些，

983
00:54:05,450 --> 00:54:08,150
你使用了静态分析工具吗？

984
00:54:08,960 --> 00:54:12,140
是的，基本上用的是静态分析包，

985
00:54:12,140 --> 00:54:14,810
然后写了一个使用静态分析包的小程序

986
00:54:14,810 --> 00:54:16,730
检查这些程序中的每一条语句，

987
00:54:16,730 --> 00:54:18,680
看看是哪种类型的语句。

988
00:54:19,800 --> 00:54:22,290
然后，你可以获取参数

989
00:54:22,290 --> 00:54:23,970
查看参数是如何使用的，

990
00:54:23,970 --> 00:54:26,100
这给你一种感觉，关于，

991
00:54:27,080 --> 00:54:29,120
允许你对这些功能计数。

992
00:54:31,250 --> 00:54:31,760
好的。

993
00:54:37,600 --> 00:54:41,290
好的，接下来的事情有点主观，

994
00:54:41,380 --> 00:54:45,940
高级语言简化了 Biscuit 代码吗？

995
00:54:46,730 --> 00:54:48,140
是的，我认为它是这样的，

996
00:54:48,170 --> 00:54:51,950
所以，举一两个例子进行讨论，

997
00:54:51,950 --> 00:54:56,180
但是你现在有 GC 分配是非常好的，

998
00:54:56,180 --> 00:54:57,380
也许我可以说明这一点。

999
00:54:57,380 --> 00:54:58,550
如果你考虑 xv6 ，

1000
00:54:58,550 --> 00:54:59,630
或者执行 exec ，

1001
00:55:00,170 --> 00:55:01,160
在执行 exec 时，

1002
00:55:01,160 --> 00:55:04,820
有很多数据结构需要释放，或者返回到内核，

1003
00:55:05,930 --> 00:55:09,290
以便以后的进程可以使用，

1004
00:55:09,290 --> 00:55:10,820
使用垃圾收集器很容易，

1005
00:55:10,820 --> 00:55:12,650
垃圾收集器会处理所有的事情，

1006
00:55:12,680 --> 00:55:14,300
你不需要做太多。

1007
00:55:14,700 --> 00:55:16,800
所以，如果你分配，释放一个地址页面，

1008
00:55:16,800 --> 00:55:19,170
地址空间对应的 VMA

1009
00:55:19,170 --> 00:55:21,390
也会被垃圾收集器自动释放。

1010
00:55:22,420 --> 00:55:24,400
是的，所以这很简单，

1011
00:55:24,700 --> 00:55:26,260
正如我们前面提到的，

1012
00:55:26,260 --> 00:55:29,680
多个返回值在编程风格方面非常好，

1013
00:55:29,890 --> 00:55:31,000
闭包也很好，

1014
00:55:31,000 --> 00:55:31,870
maps 也很好，

1015
00:55:31,870 --> 00:55:35,230
你不需要有很多[]，

1016
00:55:35,410 --> 00:55:36,940
比如在 xv6 中，

1017
00:55:37,300 --> 00:55:39,970
以线性方式查找东西，

1018
00:55:39,970 --> 00:55:43,930
但是如果你有哈希表或映射作为第一类对象或抽象，

1019
00:55:43,930 --> 00:55:45,250
程序员不用再那么做，

1020
00:55:47,450 --> 00:55:51,110
你使用 map ，运行时将负责高效地执行所有操作。

1021
00:55:51,960 --> 00:55:56,400
所以，我认为定性来说，你得到了更简单的代码。

1022
00:55:57,450 --> 00:55:59,070
但是定性的很清楚，

1023
00:55:59,070 --> 00:56:01,170
举一个更具体的例子，

1024
00:56:01,170 --> 00:56:06,630
高级语言，特别是垃圾收集器大放异彩的地方是，

1025
00:56:06,630 --> 00:56:08,700
当存在大量并发时，

1026
00:56:09,120 --> 00:56:10,200
当存在并发线程，

1027
00:56:10,200 --> 00:56:12,660
而线程共享特定的数据项。

1028
00:56:13,330 --> 00:56:17,230
举个例子，这是一个简单的例子，

1029
00:56:17,230 --> 00:56:19,600
你可以把这个问题归结为，

1030
00:56:19,600 --> 00:56:25,150
假设动态分配对象，比如一个 buf ，

1031
00:56:25,210 --> 00:56:28,300
fork 出一个线程，然后执行那个 buf ，

1032
00:56:28,300 --> 00:56:30,670
还有另一个线程也处理 buf ，

1033
00:56:30,670 --> 00:56:31,780
并对这个 buf 执行一些操作。

1034
00:56:32,330 --> 00:56:33,590
当两个线程都完成时，

1035
00:56:33,590 --> 00:56:34,790
buf 需要释放，

1036
00:56:34,880 --> 00:56:39,530
让它们可以用于后续的内核操作。

1037
00:56:40,200 --> 00:56:43,200
问题是，谁应该做这件事，谁来负责，

1038
00:56:43,770 --> 00:56:49,980
用 C 来协调有点困难，

1039
00:56:49,980 --> 00:56:52,230
因为你必须有某种方法来确定

1040
00:56:52,230 --> 00:56:54,000
buf 并未被使用，

1041
00:56:54,090 --> 00:56:55,290
如果你使用垃圾收集器，

1042
00:56:55,350 --> 00:56:56,460
没有什么需要决定的，

1043
00:56:56,490 --> 00:56:59,760
两个线程运行，完成对 buf 的操作后，

1044
00:56:59,970 --> 00:57:02,310
没有线程再指向 buf ，

1045
00:57:02,310 --> 00:57:06,090
垃圾收集器将从线程堆栈开始跟踪，

1046
00:57:06,330 --> 00:57:09,870
并且永远不会计算 buf 任何线程堆栈，

1047
00:57:09,870 --> 00:57:13,230
所以，垃圾收集器会在稍后的某个时刻释放内存。

1048
00:57:13,720 --> 00:57:15,940
所以，在垃圾收集语言中，

1049
00:57:15,940 --> 00:57:17,800
你根本不必考虑这个问题。

1050
00:57:19,990 --> 00:57:25,360
有一种你可以解决这个问题的方法，在 C 内核中，

1051
00:57:25,360 --> 00:57:28,270
所以你可以计算对象的引用计数，

1052
00:57:28,270 --> 00:57:31,600
引用计数当然要用锁来保护，

1053
00:57:31,600 --> 00:57:33,550
也许是一些原子操作，

1054
00:57:33,850 --> 00:57:35,830
然后，当引用的计数达到零时，

1055
00:57:35,830 --> 00:57:38,470
你可以取消引用它。

1056
00:57:40,640 --> 00:57:41,210
事实证明，

1057
00:57:41,210 --> 00:57:43,970
引用计数中的锁实际上比较昂贵，

1058
00:57:44,000 --> 00:57:46,820
如果你想要高性能，

1059
00:57:46,820 --> 00:57:50,060
将并发性扩展到内核数，

1060
00:57:50,060 --> 00:57:51,980
那么可能会成为一个瓶颈，

1061
00:57:52,010 --> 00:57:53,270
我们之后会看到，

1062
00:57:53,270 --> 00:57:55,070
几周后，我们看的论文，

1063
00:57:55,070 --> 00:57:57,170
非常明确地谈到了这一点。

1064
00:57:57,890 --> 00:57:59,510
所以人们倾向于，

1065
00:57:59,540 --> 00:58:02,510
想要做高性能，获得良好的并行性，

1066
00:58:02,510 --> 00:58:03,470
人们倾向于避免它们。

1067
00:58:04,020 --> 00:58:06,690
事实上，在特定情况下，

1068
00:58:06,690 --> 00:58:09,120
我们试图避免它们，在读取块中，

1069
00:58:09,180 --> 00:58:12,120
你希望至少在读取中是无锁的，

1070
00:58:12,150 --> 00:58:13,530
这样你就不用损失了。

1071
00:58:14,080 --> 00:58:17,020
比如，这是我们这样做的一个代码片段，

1072
00:58:17,020 --> 00:58:18,370
这里我们有一个 get 函数，

1073
00:58:18,820 --> 00:58:21,490
用于读取队列的头部，

1074
00:58:21,790 --> 00:58:24,670
并返回队列头部的任何内容，

1075
00:58:25,310 --> 00:58:27,920
它是以一种无锁的方式运行的，

1076
00:58:27,920 --> 00:58:31,400
使用 atomic_load 来读取头部，

1077
00:58:31,400 --> 00:58:32,990
但是它并没有使用锁，

1078
00:58:33,510 --> 00:58:35,730
然后，写入使用了锁。

1079
00:58:35,730 --> 00:58:40,310
所以这是无锁，而写入不是无锁。

1080
00:58:41,280 --> 00:58:43,980
这是 Linux 内核中非常常见的风格，

1081
00:58:43,980 --> 00:58:46,290
所以写入者拿到了锁，

1082
00:58:46,320 --> 00:58:48,120
无论查找头部的任何东西，

1083
00:58:48,120 --> 00:58:52,500
也许是 pop 函数，将头部从队列中弹出，

1084
00:58:52,950 --> 00:58:55,290
然后，你可以重复使用它，

1085
00:58:55,850 --> 00:58:58,420
然后解锁，当你释放头部时。

1086
00:58:58,720 --> 00:59:02,680
现在再来一次，

1087
00:59:02,740 --> 00:59:04,240
这有一点困难，

1088
00:59:04,270 --> 00:59:05,860
你什么时候真正释放头部，

1089
00:59:05,980 --> 00:59:07,510
因为可能是这种情况，

1090
00:59:07,510 --> 00:59:09,190
一些其他的并发线程，

1091
00:59:09,190 --> 00:59:11,680
正好在做这个 atomic_store 之前，

1092
00:59:11,980 --> 00:59:13,690
这个函数过来，

1093
00:59:13,690 --> 00:59:16,210
得到一个指向那个特定对象的指针，

1094
00:59:16,210 --> 00:59:18,520
所以一旦你完成了这个 atomic_store ，

1095
00:59:18,610 --> 00:59:20,290
你不能释放指针，

1096
00:59:20,290 --> 00:59:23,500
因为可能有另一个线程有指向它的指针，

1097
00:59:23,530 --> 00:59:24,880
如果你在这里释放它，

1098
00:59:24,880 --> 00:59:26,860
你可能会有一个 use-after-free bug。

1099
00:59:27,900 --> 00:59:32,490
我们会在几节课中看到，

1100
00:59:33,050 --> 00:59:36,380
有一种非常聪明的解决方案，

1101
00:59:36,770 --> 00:59:39,020
称为读取复制更新或 RCU ，

1102
00:59:39,320 --> 00:59:40,790
它所做的是，

1103
00:59:40,790 --> 00:59:44,420
推迟释放内存，直到知道它是安全的。

1104
00:59:45,050 --> 00:59:48,500
它有一个非常聪明的方案来决定什么时候它是安全的，

1105
00:59:48,650 --> 00:59:51,470
但是这个方案有各种各样的限制，

1106
00:59:51,470 --> 00:59:54,140
程序员必须遵守一些规则，

1107
00:59:54,500 --> 00:59:59,180
你必须遵循他们所谓的 RCU 临界区，

1108
00:59:59,700 --> 01:00:02,910
比如，你不能调用，

1109
01:00:02,910 --> 01:00:06,240
你不能在 RCU 临界区或调度中进入睡眠。

1110
01:00:06,930 --> 01:00:11,430
所以，尽管 Linux 内核使用非常成功，

1111
01:00:11,430 --> 01:00:12,780
但是比较容易出错，

1112
01:00:12,780 --> 01:00:16,050
需要仔细的程序才能正确。

1113
01:00:16,860 --> 01:00:20,190
在垃圾收集器语言的情况下，比如 Go ，

1114
01:00:20,190 --> 01:00:22,170
这不是问题，

1115
01:00:22,230 --> 01:00:26,370
因为垃圾收集器会确定某个东西何时不再使用，

1116
01:00:26,370 --> 01:00:27,450
然后才会释放它。

1117
01:00:28,210 --> 01:00:31,150
所以对程序员没有限制，

1118
01:00:31,210 --> 01:00:33,910
只是由垃圾收集器来处理。

1119
01:00:36,020 --> 01:00:37,280
所以这是一个例子，

1120
01:00:37,280 --> 01:00:42,800
在某种程度上更定性或更明确，

1121
01:00:42,800 --> 01:00:45,110
你可以从垃圾收集语言的优势中看出。

1122
01:00:45,920 --> 01:00:48,800
好的，关于 CVE 我已经提到过了，

1123
01:00:49,100 --> 01:00:53,120
我们检查了所有的 CVE 并进行人工检查，

1124
01:00:53,420 --> 01:00:56,480
然后试着决定 Go 是否能解决这个问题。

1125
01:00:56,980 --> 01:00:59,020
有 11 个我们不能确定，

1126
01:00:59,110 --> 01:01:03,130
我们看了解决这个问题的补丁，

1127
01:01:03,130 --> 01:01:06,610
我们不能确定 Go 的结果会是什么，

1128
01:01:06,610 --> 01:01:08,680
或者我们如何改变，

1129
01:01:09,400 --> 01:01:11,080
我们可以看看如何修复它，

1130
01:01:11,080 --> 01:01:13,870
但是不能决定 Go 是否会避免这个问题。

1131
01:01:14,650 --> 01:01:17,560
CVE 中的多个逻辑错误，

1132
01:01:17,560 --> 01:01:20,860
很可能 Go 也会出现与 C 一样的的逻辑错误，

1133
01:01:20,860 --> 01:01:23,350
结果会是一样的。

1134
01:01:23,880 --> 01:01:27,120
但是大约有 40 个内存安全漏洞，

1135
01:01:27,150 --> 01:01:29,580
释放后使用或双重释放或越界使用，

1136
01:01:29,970 --> 01:01:32,910
这八个消失了，

1137
01:01:32,910 --> 01:01:34,770
因为垃圾收集器负责处理它们，

1138
01:01:34,770 --> 01:01:37,080
像最后几张幻灯片中描述的那样。

1139
01:01:37,500 --> 01:01:40,800
在 32 个案例中， Go 会引起 panic ，

1140
01:01:40,800 --> 01:01:43,440
因为比如 Go 会超出数组界限，

1141
01:01:44,090 --> 01:01:47,810
当然， panic 是不好的，内核会崩溃，

1142
01:01:47,990 --> 01:01:50,090
但这比安全漏洞要好。

1143
01:01:50,880 --> 01:01:54,900
所以， 40 个案例，高级语言帮助了我们。

1144
01:01:59,920 --> 01:02:03,070
好的，这就是好的方面，

1145
01:02:03,100 --> 01:02:07,690
所以现在我想谈谈高级语言的性能成本，

1146
01:02:07,690 --> 01:02:10,240
高级语言税。

1147
01:02:10,820 --> 01:02:11,750
在做那之前，

1148
01:02:11,750 --> 01:02:13,760
让我问一下是否有其他问题？

1149
01:02:20,990 --> 01:02:23,480
好的，我要讲一下它们，

1150
01:02:23,480 --> 01:02:25,880
我不确定能不能讲完全部六个，

1151
01:02:25,910 --> 01:02:28,520
因为我们在最后至少预留几分钟，

1152
01:02:28,520 --> 01:02:32,600
我们将回到课程的起点，今天的问题。

1153
01:02:35,900 --> 01:02:38,150
所以要设置实验，

1154
01:02:38,180 --> 01:02:42,260
Biscuit 运行在裸硬件上，

1155
01:02:42,770 --> 01:02:47,630
所以这些实验是在小的物理机器上运行的，而不是在 QEMU 上，

1156
01:02:47,630 --> 01:02:51,950
是 4 核， 2.8Ghz 的英特尔处理器，

1157
01:02:51,950 --> 01:02:54,560
16GB 内存，但禁用了超线程。

1158
01:02:54,590 --> 01:02:55,820
我们使用三个应用程序，

1159
01:02:55,850 --> 01:02:57,530
一个 Web 服务器，一个键/值存储

1160
01:02:57,620 --> 01:02:58,850
和一个邮件服务器基准测试。

1161
01:02:59,220 --> 01:03:02,970
这些应用程序都给内核很大的压力，

1162
01:03:03,030 --> 01:03:05,820
所以，它们执行系统调用，

1163
01:03:05,820 --> 01:03:08,280
内核必须做大量工作。

1164
01:03:09,050 --> 01:03:09,800
你可以看到这个，

1165
01:03:09,800 --> 01:03:12,590
因为这些应用程序中的大部分时间都花在内核中。

1166
01:03:15,060 --> 01:03:16,260
所以第一个问题是，

1167
01:03:16,260 --> 01:03:19,110
Linux 或者 Biscuit 是不是，

1168
01:03:19,110 --> 01:03:24,330
生产级别的内核或工业级别的内核，

1169
01:03:24,660 --> 01:03:25,650
所以我们所做的是，

1170
01:03:25,650 --> 01:03:27,870
我们通过比较 Biscuit 和 Linux ，

1171
01:03:27,900 --> 01:03:31,800
对于 Linux ，我们使用的是 4.9 Linux ，

1172
01:03:31,800 --> 01:03:32,850
现在有点过时了，

1173
01:03:32,850 --> 01:03:35,580
因为论文已经有几年的历史了。

1174
01:03:36,140 --> 01:03:39,230
当然，当我们使用 Linux 时，必须禁用所有功能，

1175
01:03:39,230 --> 01:03:42,770
Biscuit 不提供的，

1176
01:03:42,770 --> 01:03:45,260
比如页表隔离，轮询，

1177
01:03:45,260 --> 01:03:47,690
各种各样的一些功能，

1178
01:03:47,690 --> 01:03:50,750
这些功能不是 Biscuit 所提供的，也不是 xv6 所提供的，

1179
01:03:51,170 --> 01:03:52,460
我们在 Linux 上禁用了它们，

1180
01:03:52,460 --> 01:03:54,230
以使比较尽可能地公平。

1181
01:03:54,880 --> 01:03:57,340
当然，有些功能很难禁用，

1182
01:03:57,340 --> 01:03:59,800
我们不能禁用，

1183
01:03:59,920 --> 01:04:02,110
但我们试着尽可能靠近。

1184
01:04:02,820 --> 01:04:05,130
然后我们测量了吞吐量。

1185
01:04:05,740 --> 01:04:10,990
如你所见， Biscuit 几乎总是比较慢，

1186
01:04:11,110 --> 01:04:12,820
它总是比 Linux 慢，

1187
01:04:13,330 --> 01:04:17,380
CMailbench 会差大约 10% ，

1188
01:04:17,380 --> 01:04:19,330
在 Nginx 上，再多一点，

1189
01:04:19,450 --> 01:04:21,280
Redis 是 10% 或 15% 。

1190
01:04:21,820 --> 01:04:24,700
但是你应该粗粒度地比较这些数字，

1191
01:04:24,700 --> 01:04:27,250
因为，它们不一样，

1192
01:04:27,460 --> 01:04:30,610
这不是一一对应的比较，

1193
01:04:30,700 --> 01:04:32,800
但是首先，

1194
01:04:33,070 --> 01:04:35,560
它们至少是大致相同的，

1195
01:04:35,560 --> 01:04:38,500
它们不是 2 倍、 3 倍、 4 倍或 10 倍的差距，

1196
01:04:38,680 --> 01:04:43,450
所以，也许真正能够做到这一点是值得的，

1197
01:04:43,860 --> 01:04:45,600
从中得出一些结论。

1198
01:04:51,820 --> 01:04:53,050
所以我们看一下，

1199
01:04:53,050 --> 01:04:55,540
我们分析代码，

1200
01:04:55,540 --> 01:04:59,800
并尝试对代码所花费的周期分类，

1201
01:04:59,800 --> 01:05:03,970
特别是，我们关注的是垃圾收集器中有哪些循环，

1202
01:05:03,970 --> 01:05:07,570
哪些周期在 prologue 函数调用中，

1203
01:05:07,570 --> 01:05:11,110
Go 的 prologue 做了很多工作，

1204
01:05:11,110 --> 01:05:13,390
确保堆栈足够大，

1205
01:05:13,390 --> 01:05:14,710
可以在堆栈中运行，

1206
01:05:15,130 --> 01:05:20,560
写入屏障循环，这是在垃圾收集器模式时，

1207
01:05:20,560 --> 01:05:24,550
垃圾收集器打开写入障碍，

1208
01:05:25,080 --> 01:05:28,860
用于跟踪不同空间之间的指针。

1209
01:05:29,310 --> 01:05:31,470
而安全周期，

1210
01:05:31,650 --> 01:05:38,380
安全周期是在列表边界检查上花费的周期，

1211
01:05:38,380 --> 01:05:40,330
诸如此类的事情，无指针检查。

1212
01:05:42,500 --> 01:05:46,280
所以如果你看这些应用程序，这里的数字，

1213
01:05:46,400 --> 01:05:50,660
3% 的执行时间花在了 GC 周期上，

1214
01:05:50,660 --> 01:05:54,200
我们会稍微讨论一下为什么这个很低，

1215
01:05:54,200 --> 01:05:56,780
但在这种情况下，

1216
01:05:56,780 --> 01:05:59,660
垃圾收集器在这些应用程序运行时运行，

1217
01:05:59,660 --> 01:06:01,790
所以这不是我们测量应用程序的情况，

1218
01:06:01,790 --> 01:06:03,170
我们提供了很多内存，

1219
01:06:03,170 --> 01:06:08,040
只是运行而不需要垃圾收集器，

1220
01:06:08,460 --> 01:06:11,910
令人惊讶的是， prologue 周期是最高的，

1221
01:06:12,030 --> 01:06:14,640
这就是方案的方式，

1222
01:06:14,640 --> 01:06:18,330
我们使用这些时间检查内核堆栈，

1223
01:06:18,330 --> 01:06:19,710
或线程堆栈，

1224
01:06:19,710 --> 01:06:21,390
或 Go 协程是否需要增长，

1225
01:06:21,970 --> 01:06:25,660
而这是 Go 设计中的一种[]，

1226
01:06:25,660 --> 01:06:27,340
它可能更容易降低，

1227
01:06:27,790 --> 01:06:29,770
写入屏障的时间很短，

1228
01:06:29,770 --> 01:06:33,700
有 2-3% 在安全循环中。

1229
01:06:34,570 --> 01:06:37,990
所以在某种意义上，这是个好消息，

1230
01:06:37,990 --> 01:06:42,280
你不在，（高级语言）税并不是很大，

1231
01:06:42,280 --> 01:06:43,960
当然，这个数字可能会高得多，

1232
01:06:43,990 --> 01:06:49,420
因为这完全取决于堆的数量和大小，

1233
01:06:49,420 --> 01:06:52,210
或者活跃的对象的数量，

1234
01:06:52,210 --> 01:06:55,060
因为垃圾收集器必须跟踪所有活动对象

1235
01:06:55,060 --> 01:06:56,860
以确定哪些对象是不活动的。

1236
01:06:57,520 --> 01:07:00,460
所以，如果有很多活的对象，

1237
01:07:00,460 --> 01:07:02,680
垃圾收集器不得不跟踪更多的对象，

1238
01:07:02,740 --> 01:07:06,700
所以这与活跃对象的数量完全成线性关系。

1239
01:07:07,290 --> 01:07:08,790
我们也做了一些其他的实验。

1240
01:07:09,380 --> 01:07:10,970
让我稍微缩小一点，

1241
01:07:11,180 --> 01:07:13,970
我们分配了大量的活动数据，

1242
01:07:14,300 --> 01:07:15,620
200 万个虚拟节点，

1243
01:07:15,620 --> 01:07:17,450
可以将其视为 200 万个 inode ，

1244
01:07:17,840 --> 01:07:20,600
并且释放大量的堆内存，

1245
01:07:20,630 --> 01:07:23,930
或者修改垃圾收集器拥有的堆内存的大小，

1246
01:07:23,930 --> 01:07:25,130
为了释放内存，

1247
01:07:25,340 --> 01:07:28,580
然后[]，然后测量成本。

1248
01:07:29,140 --> 01:07:30,670
就是这张表，

1249
01:07:30,880 --> 01:07:33,280
我们有大约 640 兆字节的活跃数据，

1250
01:07:33,610 --> 01:07:36,370
使用不同的内存大小运行，

1251
01:07:36,640 --> 01:07:40,090
在一种大小的情况下，有 320 兆字节的数据，

1252
01:07:40,090 --> 01:07:41,860
所以活跃与空闲的比是 2 ，

1253
01:07:42,190 --> 01:07:43,810
你可以看到，在这种情况下，

1254
01:07:44,080 --> 01:07:48,580
Go 很好地模仿了垃圾收集器的开销，

1255
01:07:48,580 --> 01:07:50,620
因为垃圾收集器需要运行很多次，

1256
01:07:50,650 --> 01:07:52,150
因为它没有太多堆内存。

1257
01:07:52,900 --> 01:07:56,590
但是，如果你有两倍空闲的内存，

1258
01:07:56,590 --> 01:07:57,940
你可以买到足够的内存，

1259
01:07:57,940 --> 01:08:00,160
空闲内存是活跃内存的两倍，

1260
01:08:00,280 --> 01:08:05,230
那么垃圾收集开销不是那么大，在 9% 的范围内。

1261
01:08:05,890 --> 01:08:11,020
所以，要将 GC 开销控制在 10% 以下，

1262
01:08:11,140 --> 01:08:15,670
就物理内存而言，你需要大约三倍的堆大小。

1263
01:08:19,920 --> 01:08:20,970
对于这个，有什么问题吗？

1264
01:08:23,500 --> 01:08:27,520
我有一个关于写入障碍的问题，

1265
01:08:27,520 --> 01:08:29,920
那些是什么，

1266
01:08:29,980 --> 01:08:33,790
是不是像你说的一些权限？

1267
01:08:34,270 --> 01:08:38,740
如果你记得之前的课程，

1268
01:08:38,740 --> 01:08:41,560
那个 Appel&Li 论文，

1269
01:08:41,560 --> 01:08:44,200
在那里，我们讨论了 to 和 from 空间。

1270
01:08:44,700 --> 01:08:47,370
垃圾收集器运行，

1271
01:08:47,370 --> 01:08:50,940
必须检查指针是否在 from 空间中，

1272
01:08:50,940 --> 01:08:52,770
因为如果它在 form 空间中，你必须复制它。

1273
01:08:53,420 --> 01:08:56,870
基本上写入屏障类似，

1274
01:08:57,830 --> 01:08:59,270
是同一种类型的想法，

1275
01:08:59,270 --> 01:09:01,580
你需要检查每个指针，

1276
01:09:01,580 --> 01:09:04,550
查看实际指向的空间，

1277
01:09:04,550 --> 01:09:06,200
垃圾收集器所需要的。

1278
01:09:07,300 --> 01:09:07,540
好的。

1279
01:09:07,540 --> 01:09:08,470
那就是写入屏障。

1280
01:09:11,730 --> 01:09:15,210
抱歉，比如空闲内存，

1281
01:09:15,210 --> 01:09:17,490
它是怎么工作的，

1282
01:09:17,490 --> 01:09:19,320
在活跃内存大于空闲的情况下。

1283
01:09:19,740 --> 01:09:23,340
哦，好的，你买了一些内存，

1284
01:09:23,780 --> 01:09:26,900
而活跃内存是这些 vnode 使用的内存，

1285
01:09:27,200 --> 01:09:29,750
然后又有 320 兆字节是空闲的。

1286
01:09:30,540 --> 01:09:33,840
所以，当这个应用程序分配更多 vnode 时，

1287
01:09:33,840 --> 01:09:35,610
首先来自空闲内存，

1288
01:09:35,610 --> 01:09:36,750
直到空闲内存变满，

1289
01:09:36,750 --> 01:09:39,210
垃圾收集器同时运行。

1290
01:09:40,350 --> 01:09:44,130
所以我们的运行方式是三种配置，

1291
01:09:44,130 --> 01:09:49,260
在一种配置中，空闲内存量是活动内存的两倍，

1292
01:09:49,920 --> 01:09:52,620
这意味着垃圾收集器有很多堆内存，

1293
01:09:53,010 --> 01:09:56,070
在与应用程序一起运行的同时执行某种操作。

1294
01:09:56,730 --> 01:09:58,080
如果有很多堆内存，

1295
01:09:58,230 --> 01:09:59,970
在这种情况下，是空闲内存，

1296
01:09:59,970 --> 01:10:02,220
那么垃圾收集器的开销就没有那么高，

1297
01:10:03,310 --> 01:10:06,130
在那里是 10% 左右，而不是 34% 。

1298
01:10:07,520 --> 01:10:09,080
好的，我知道了，谢谢。

1299
01:10:09,260 --> 01:10:11,150
考虑有一些闲置空间，

1300
01:10:11,180 --> 01:10:13,280
让垃圾收集器做它的工作。

1301
01:10:14,460 --> 01:10:18,240
是的，我以为一共是 320 ，那就太迷惑了。

1302
01:10:18,270 --> 01:10:20,970
不，总数是 320 加上 640 ，

1303
01:10:21,180 --> 01:10:23,940
并且我的最后一行是 640 加上 1280 。

1304
01:10:24,650 --> 01:10:26,300
好的，谢谢。

1305
01:10:29,930 --> 01:10:31,610
我要跳过这个，

1306
01:10:31,700 --> 01:10:36,290
让我稍微说一下关于暂停，

1307
01:10:36,290 --> 01:10:37,280
你知道这是，

1308
01:10:37,860 --> 01:10:40,200
Go 垃圾收集器是一个并发垃圾收集器，

1309
01:10:40,200 --> 01:10:45,510
短暂的暂停让世界停下来很短的一段时间，

1310
01:10:45,510 --> 01:10:46,860
用于启用写入障碍，

1311
01:10:46,860 --> 01:10:49,350
然后，应用程序继续运行，

1312
01:10:49,650 --> 01:10:51,570
在垃圾收集器不工作的情况下，

1313
01:10:51,690 --> 01:10:55,860
它是渐进式的，就像我们几周前讨论的那样，

1314
01:10:55,860 --> 01:10:59,940
每个对 new 的调用都会执行一些垃圾收集工作。

1315
01:11:00,800 --> 01:11:03,020
所以每次你做一点垃圾收集工作，

1316
01:11:03,020 --> 01:11:05,390
有一些延误，有代价的。

1317
01:11:06,110 --> 01:11:09,560
所以我们测量了，

1318
01:11:09,560 --> 01:11:13,580
使用一个应用程序，并查看了最大停顿时间，

1319
01:11:13,580 --> 01:11:15,920
应用程序可以停止的最长时间，

1320
01:11:15,920 --> 01:11:18,050
当然垃圾收集器需要做一些工作。

1321
01:11:19,140 --> 01:11:24,840
结果是最大单次停顿是 150 微秒，

1322
01:11:25,200 --> 01:11:28,800
这是使用 TCP 堆栈的 Web 服务器的情况，

1323
01:11:28,800 --> 01:11:33,120
基本上 TCP 连接表的很大一部分需要标记，

1324
01:11:33,150 --> 01:11:36,930
在你继续之前，这花了 115 微秒。

1325
01:11:37,660 --> 01:11:44,140
单个 Nginx http 请求的最大总暂停时间是

1326
01:11:44,140 --> 01:11:46,420
单个暂停次数的总和，

1327
01:11:46,420 --> 01:11:51,670
并且单个请求的总最大暂停时间是 582 微秒，

1328
01:11:51,910 --> 01:11:54,430
所以当请求进入机器时，

1329
01:11:54,490 --> 01:12:00,850
在总共有 582 微秒延迟，执行该请求。

1330
01:12:03,100 --> 01:12:06,100
而且这种情况非常罕见，

1331
01:12:06,190 --> 01:12:11,620
只有 3% 的请求时间延迟超过 100 微秒。

1332
01:12:12,380 --> 01:12:14,840
所以这并不好，

1333
01:12:14,840 --> 01:12:17,690
如果你想要实现一个 SLA ，

1334
01:12:17,690 --> 01:12:24,850
或者请求的最长时间很小，

1335
01:12:25,360 --> 01:12:29,980
但是你查看谷歌的 Tail at Scale 的论文，

1336
01:12:29,980 --> 01:12:33,280
比如最长的请求需要多长时间，

1337
01:12:33,280 --> 01:12:34,210
他们谈论的是

1338
01:12:34,210 --> 01:12:37,480
几十毫秒，毫秒或 10 毫秒的量级，

1339
01:12:37,690 --> 01:12:43,870
所以这些程序有最大暂停，

1340
01:12:43,870 --> 01:12:47,050
最大的暂停是 582 微秒，

1341
01:12:47,050 --> 01:12:48,250
在预算之内。

1342
01:12:48,860 --> 01:12:51,290
这不是很理想，但也不疯狂，

1343
01:12:51,380 --> 01:12:53,810
所以基本上说，

1344
01:12:55,110 --> 01:12:56,610
这基本上说明，

1345
01:12:56,610 --> 01:12:59,550
Go 设计者做得非常好，

1346
01:12:59,550 --> 01:13:01,170
在实现垃圾收集器方面，

1347
01:13:02,070 --> 01:13:03,420
或者令人印象深刻的工作。

1348
01:13:04,160 --> 01:13:07,250
这是我们在做这个项目时注意到的一件事，

1349
01:13:07,250 --> 01:13:09,200
每次我们升级 Go 运行时，

1350
01:13:09,320 --> 01:13:11,870
下一个运行时，带来了更好的垃圾收集器，

1351
01:13:11,870 --> 01:13:13,490
这些数字变得越来越好。

1352
01:13:17,910 --> 01:13:22,050
好的，我想再说一个技术细节，

1353
01:13:22,050 --> 01:13:26,730
到目前为止， Linux 和 Biscuit 之间的第一个比较，

1354
01:13:26,730 --> 01:13:27,930
这并不公平，

1355
01:13:27,930 --> 01:13:32,490
因为 Biscuit 和 Linux 实现的功能略有不同，

1356
01:13:32,760 --> 01:13:34,230
所以我们又做了一个实验，

1357
01:13:34,230 --> 01:13:38,550
我们尝试编写两个完全相同的内核路径，

1358
01:13:38,730 --> 01:13:43,650
在 Linux 和类似的 C 和 Go 中，

1359
01:13:43,770 --> 01:13:48,660
所以，我们看了代码路径，并对其进行验证，

1360
01:13:48,660 --> 01:13:51,180
基本上它实现的是完全相同的东西，

1361
01:13:51,180 --> 01:13:52,710
我们看一下汇编结构，

1362
01:13:52,710 --> 01:13:55,410
来真正了解它们的不同之处，

1363
01:13:55,500 --> 01:13:56,760
会有一些不同，

1364
01:13:56,760 --> 01:13:59,070
因为 Go 要支付安全检查，

1365
01:13:59,340 --> 01:14:02,640
但就基本操作而言，

1366
01:14:02,640 --> 01:14:05,790
至少两个代码路径在功能方面是相同的。

1367
01:14:07,380 --> 01:14:09,960
我们对两条代码路径都这样做了，

1368
01:14:09,960 --> 01:14:11,070
这很难做到，

1369
01:14:11,070 --> 01:14:13,650
因为这是辛苦的工作，

1370
01:14:13,650 --> 01:14:14,460
我们做了两个，

1371
01:14:14,700 --> 01:14:15,840
或者 Cody 做了两个。

1372
01:14:16,410 --> 01:14:17,490
然后我们对它们进行比较，

1373
01:14:18,040 --> 01:14:20,350
这是其中一个结果，

1374
01:14:20,350 --> 01:14:22,840
这是管道 ping-pong 测试，

1375
01:14:22,840 --> 01:14:24,970
ping-pong 字节在管道上通过，

1376
01:14:25,180 --> 01:14:27,430
我们查看了通过内核的代码路径，

1377
01:14:27,430 --> 01:14:30,880
让字节从管道的一端到管道的另一端。

1378
01:14:31,790 --> 01:14:39,100
Go 中的代码有 1.2k 行，

1379
01:14:39,100 --> 01:14:42,070
而 C 是 1.8k 行代码，

1380
01:14:42,400 --> 01:14:44,140
而且没有分配，没有 GC ，

1381
01:14:44,140 --> 01:14:46,660
所以这些东西是不同之处，

1382
01:14:46,720 --> 01:14:48,610
我们还研究了运行时，

1383
01:14:48,610 --> 01:14:51,400
比如在两个代码路径中花费的时间最多的地方，

1384
01:14:51,400 --> 01:14:54,360
同样的前十大指令出现了，

1385
01:14:54,360 --> 01:14:57,930
所以我们有信心，代码路径真的很近，

1386
01:14:58,080 --> 01:15:00,850
近到可以让它们相似。

1387
01:15:01,390 --> 01:15:04,570
然后我们看一下每秒可以完成的操作量，

1388
01:15:04,630 --> 01:15:06,490
正如你在这里看到的，

1389
01:15:06,580 --> 01:15:11,650
Go 比 C 实现慢一点，

1390
01:15:12,010 --> 01:15:15,610
大约慢了 1.15% 。

1391
01:15:16,260 --> 01:15:21,180
你看一下 prologue/safety-check ，

1392
01:15:21,180 --> 01:15:24,150
这些都是 C 代码不需要执行的指令，

1393
01:15:24,270 --> 01:15:29,310
结果是汇编指令多了 16% ，

1394
01:15:29,370 --> 01:15:32,280
所以这大概是有道理的。

1395
01:15:32,830 --> 01:15:36,070
所以主要结论是 Go 会更慢，

1396
01:15:36,280 --> 01:15:39,610
但是很有竞争性，不是慢得离谱。

1397
01:15:40,570 --> 01:15:42,790
这似乎与之前的结果是一样的，

1398
01:15:42,790 --> 01:15:45,610
我们直接将 Linux 与 Biscuit 进行比较。

1399
01:15:47,790 --> 01:15:50,920
好的，让我放大更多一点，

1400
01:15:50,950 --> 01:15:52,720
让我跳过这个，

1401
01:15:52,750 --> 01:15:54,370
因为我想稍微谈一下，

1402
01:15:54,460 --> 01:15:57,220
我们一开始问的这类问题，

1403
01:15:57,220 --> 01:15:59,740
是否应该对新内核使用高级语言。

1404
01:16:00,830 --> 01:16:03,950
也许，不是直接回答，

1405
01:16:03,950 --> 01:16:05,750
在这张幻灯片里，我有一些想法，

1406
01:16:05,750 --> 01:16:07,370
我们得出了一些结论，

1407
01:16:07,370 --> 01:16:10,400
这不是一个明确的结论，一些考虑，

1408
01:16:10,760 --> 01:16:13,490
所以也许我们应该退后一步，问问自己这个问题，

1409
01:16:13,490 --> 01:16:15,940
比如你喜欢什么，

1410
01:16:15,940 --> 01:16:19,510
你是更喜欢用 C 语言编写 xv6 和实验，

1411
01:16:19,510 --> 01:16:23,020
还是更喜欢使用类似 Go 的高级语言。

1412
01:16:23,660 --> 01:16:25,940
特别是回答这个问题，

1413
01:16:25,940 --> 01:16:28,190
你会避免什么样的 bug ，

1414
01:16:28,220 --> 01:16:31,520
也许你在这节课中有一些时间

1415
01:16:31,520 --> 01:16:33,320
来思考一下你有什么 bug ，

1416
01:16:33,770 --> 01:16:36,860
我很想听到你的经历，

1417
01:16:38,160 --> 01:16:41,610
你认为切换到高级语言

1418
01:16:41,610 --> 01:16:43,050
会如何改变你的经历。

1419
01:16:45,090 --> 01:16:47,460
或者你这个问题有任何想法。

1420
01:16:51,460 --> 01:16:55,010
让我暂停一会，

1421
01:16:55,010 --> 01:16:57,560
你可以考虑一下，再加入进来。

1422
01:16:59,120 --> 01:17:02,180
我有过几次这样做的经历，

1423
01:17:02,180 --> 01:17:04,250
我在函数中创建对象，

1424
01:17:04,460 --> 01:17:06,980
然后返回指向该对象的指针，

1425
01:17:06,980 --> 01:17:08,540
然后我用指针做一些事情，

1426
01:17:08,840 --> 01:17:11,120
然后我意识到这个物体不见了。

1427
01:17:11,450 --> 01:17:15,670
是的，这是一个典型的释放后使用的例子。

1428
01:17:17,810 --> 01:17:22,010
是的，第二次我比第一次更快地意识到了这一点。

1429
01:17:22,440 --> 01:17:23,490
是的，这绝对是真的，

1430
01:17:23,490 --> 01:17:25,320
当你看到几次这些 bug ，

1431
01:17:25,320 --> 01:17:26,340
你可以做得更好。

1432
01:17:26,990 --> 01:17:29,180
还有任何关于这个的其他想法吗，

1433
01:17:29,180 --> 01:17:31,340
人们有过什么样的经历。

1434
01:17:33,110 --> 01:17:37,090
想想你最坏的 bug ，花了最多时间的 bug ，

1435
01:17:38,820 --> 01:17:40,830
高级语言会有帮助吗？

1436
01:17:43,320 --> 01:17:47,640
我觉得有些 bug 确实很难对付，

1437
01:17:47,700 --> 01:17:51,000
但同时，就像在这个上下文中，

1438
01:17:51,000 --> 01:17:55,170
我非常感谢能够使用如此低级的 C 语言，

1439
01:17:55,260 --> 01:17:58,320
因为它帮助我获得，

1440
01:17:58,410 --> 01:18:02,670
对操作系统内部的情况有了非常深刻的了解，

1441
01:18:02,670 --> 01:18:04,260
比如它是如何处理内存的，

1442
01:18:04,260 --> 01:18:07,260
它绝对是新的，

1443
01:18:07,260 --> 01:18:09,630
不把所有的东西都抽象化，

1444
01:18:09,630 --> 01:18:12,540
真正看到到底发生了什么。

1445
01:18:15,560 --> 01:18:16,430
是啊，这很有道理，

1446
01:18:16,430 --> 01:18:19,170
还有其他任何人对此有意见吗？

1447
01:18:20,070 --> 01:18:24,300
我想也有很多 bug ，

1448
01:18:24,300 --> 01:18:32,660
在我在字符串末尾或类似的地方写入的时候，

1449
01:18:32,720 --> 01:18:36,650
但是我没有得到任何有用的反馈，

1450
01:18:36,650 --> 01:18:40,610
然后我无法解释的非常奇怪的事情发生了，

1451
01:18:41,150 --> 01:18:42,890
所以，是的，我。

1452
01:18:42,920 --> 01:18:44,900
那出现在实验一中，

1453
01:18:46,130 --> 01:18:47,900
那里有很多奇怪的操作，

1454
01:18:47,900 --> 01:18:50,210
比如当你解析目录之类的东西的时候。

1455
01:18:51,410 --> 01:18:53,000
它出现在多个应用程序中。

1456
01:18:53,390 --> 01:18:56,180
好的，我并不惊讶。

1457
01:18:56,570 --> 01:18:57,830
好的，这是一个很好的例子，

1458
01:18:57,830 --> 01:19:01,280
拥有真正的字符串对象是非常好的。

1459
01:19:03,870 --> 01:19:05,040
我想说的是，

1460
01:19:05,040 --> 01:19:09,390
我发现缺少映射之类的东西，

1461
01:19:09,690 --> 01:19:14,640
每次我需要做 for 循环，然后查找。

1462
01:19:15,160 --> 01:19:15,700
是的。

1463
01:19:15,700 --> 01:19:16,960
不过，我要说的是，

1464
01:19:16,960 --> 01:19:20,020
来自高级编程背景，

1465
01:19:20,500 --> 01:19:23,650
这是我第一次真正接触到像 C 这样的东西，

1466
01:19:23,710 --> 01:19:25,210
所以跟 Noah 的观点一样，

1467
01:19:25,210 --> 01:19:27,010
它在某种程度上帮助我理解了，

1468
01:19:27,070 --> 01:19:28,390
这意味着什么，

1469
01:19:29,140 --> 01:19:31,840
我正在编写的代码是在 CPU 上运行的，

1470
01:19:31,840 --> 01:19:34,000
一切都是从 CPU 的角度出发的。

1471
01:19:34,360 --> 01:19:42,460
是的，还有其他想法吗？

1472
01:19:46,580 --> 01:19:48,770
哦，我记得具体是，

1473
01:19:48,770 --> 01:19:54,590
安全字符串复制和字符串复制的区别，

1474
01:19:54,830 --> 01:19:58,850
其中一个使用空终止符，

1475
01:19:58,850 --> 01:20:00,200
那就是。

1476
01:20:00,200 --> 01:20:04,270
是的，一个常见的 C bug 。

1477
01:20:04,390 --> 01:20:07,720
好吧，第一件事是谢谢你的投入，

1478
01:20:07,870 --> 01:20:12,100
当然，我们不会将 xv6 更改为 Go

1479
01:20:12,100 --> 01:20:13,300
或任何高级语言，

1480
01:20:13,300 --> 01:20:16,990
因为 Noah 和 Amir 提到的原因，

1481
01:20:18,140 --> 01:20:20,180
Go 隐藏的太多了，

1482
01:20:20,210 --> 01:20:21,710
在这个课程中，

1483
01:20:21,710 --> 01:20:24,350
整个目的是试图理解所有事情，

1484
01:20:24,350 --> 01:20:27,470
在 CPU 和系统调用接口之间，

1485
01:20:27,560 --> 01:20:30,890
比如， Go 隐藏了线程，

1486
01:20:31,040 --> 01:20:33,410
你知道我们不想隐藏它，

1487
01:20:33,410 --> 01:20:35,660
我们想向你解释线程是如何实现的，

1488
01:20:35,900 --> 01:20:39,710
所以，我们不想对你隐藏这个。

1489
01:20:40,190 --> 01:20:41,660
所以可以肯定的是，未来几年，

1490
01:20:41,660 --> 01:20:45,440
xv6 课程将继续使用 C ，

1491
01:20:45,770 --> 01:20:47,750
但是如果你实现一个新的内核，

1492
01:20:47,750 --> 01:20:53,700
你的目标不是教育学生关于内核的知识，

1493
01:20:53,700 --> 01:20:57,900
但目标是安全的，高性能的内核，

1494
01:20:58,050 --> 01:21:00,990
你可以从这项研究中得出一些结论，

1495
01:21:00,990 --> 01:21:03,000
他们做了什么，我们做了什么。

1496
01:21:03,500 --> 01:21:06,830
是的，内存或性能是最重要的，

1497
01:21:06,860 --> 01:21:10,730
你不能牺牲 15% ，那么你应该使用 C ，

1498
01:21:10,820 --> 01:21:14,390
如果你想最大限度地减少内存使用，也应该使用 C 。

1499
01:21:15,180 --> 01:21:17,130
如果安全很重要，

1500
01:21:17,130 --> 01:21:18,900
也许高级语言就是我们要走的路。

1501
01:21:19,600 --> 01:21:24,550
也许在许多情况下，性能是重要的，而不是绝对的，

1502
01:21:24,820 --> 01:21:25,600
在很多情况下，

1503
01:21:25,600 --> 01:21:29,140
我认为使用高级语言做内核是非常合理的事情。

1504
01:21:30,220 --> 01:21:31,720
也许我学到了一件事，

1505
01:21:31,720 --> 01:21:35,500
也许 Cody Robert 和我从整个项目中学到的是，

1506
01:21:35,500 --> 01:21:38,050
任何编程语言都是编程语言，

1507
01:21:38,050 --> 01:21:39,880
你可以用它来构建内核，

1508
01:21:39,880 --> 01:21:41,380
你可以构建用户应用程序，

1509
01:21:41,500 --> 01:21:44,530
在某种程度上，这并不是什么真正的阻碍。

1510
01:21:50,800 --> 01:21:53,170
好的，我觉得该结束了，

1511
01:21:53,170 --> 01:21:56,320
如果你还有什么问题，

1512
01:21:56,320 --> 01:21:59,620
可以随意停留并提问，

1513
01:21:59,620 --> 01:22:01,150
如果你要去别的地方，

1514
01:22:01,510 --> 01:22:04,540
祝你顺利完成 mmap 实验，

1515
01:22:04,540 --> 01:22:05,440
对于你们，

1516
01:22:05,440 --> 01:22:08,110
当我们要离开校园过感恩节的人来说，

1517
01:22:08,320 --> 01:22:11,920
一路顺风，希望感恩节过后见到你，

1518
01:22:11,920 --> 01:22:13,630
在感恩节后的周一的课程中。

1519
01:22:17,650 --> 01:22:18,130
谢谢。

1520
01:22:20,250 --> 01:22:22,800
我很好奇，你是怎么实现的，

1521
01:22:22,830 --> 01:22:25,380
上面说你在在硬件上做这个，

1522
01:22:25,440 --> 01:22:29,100
所以当你开始的时候，你是怎么开始的。

1523
01:22:30,010 --> 01:22:32,290
这里有很少的垫片代码，

1524
01:22:32,380 --> 01:22:34,840
它对硬件做足够的设置，

1525
01:22:34,840 --> 01:22:37,390
当 Biscuit 请求，

1526
01:22:37,390 --> 01:22:41,320
当 Go 运行时请求堆的内存时，

1527
01:22:41,320 --> 01:22:42,940
我们可以响应。

1528
01:22:44,240 --> 01:22:50,270
这是 Go 运行时所依赖的主要内容之一。

1529
01:22:51,460 --> 01:22:53,200
是的，我想你说的是，

1530
01:22:53,200 --> 01:22:57,490
你没有使用虚拟机，所以。

1531
01:22:57,490 --> 01:23:02,830
我们用了，当然大部分开发都在 QEMU 上，

1532
01:23:02,830 --> 01:23:06,280
当然，我们还必须让它在硬件上运行，

1533
01:23:06,370 --> 01:23:08,140
这也要解决一堆问题，

1534
01:23:08,140 --> 01:23:09,580
因为引导加载程序不同，

1535
01:23:09,580 --> 01:23:11,380
需要编写一系列引导代码，

1536
01:23:11,380 --> 01:23:13,210
如果你在 QEMU 上运行就不用写了，

1537
01:23:13,600 --> 01:23:15,220
诸如此类的东西，

1538
01:23:15,220 --> 01:23:17,680
但是大部分的开发都是在 QEMU 上完成的，

1539
01:23:17,680 --> 01:23:21,460
事实上，如果你想在 QEMU 上运行 Biscuit ，

1540
01:23:21,640 --> 01:23:23,260
它看起来非常简单，类似 xv6 ，

1541
01:23:23,260 --> 01:23:25,510
它唯一就是显示提示符，

1542
01:23:25,510 --> 01:23:28,120
没有窗口系统，什么都没有。

1543
01:23:29,800 --> 01:23:30,760
好的，我明白了，

1544
01:23:31,000 --> 01:23:34,720
所以如果你在引导代码中犯了错误，会发生什么情况。

1545
01:23:35,660 --> 01:23:36,500
它不能启动，

1546
01:23:36,530 --> 01:23:37,910
基本上什么都没发生，

1547
01:23:37,910 --> 01:23:39,620
完全没什么东西。

1548
01:23:40,370 --> 01:23:41,720
你怎么知道？

1549
01:23:42,460 --> 01:23:44,920
你会知道的，

1550
01:23:44,920 --> 01:23:49,060
因为你知道，因为你看不到打印的语句，

1551
01:23:49,060 --> 01:23:51,160
比如 xv6 ，我们打印的第一件事是，

1552
01:23:51,160 --> 01:23:54,820
比如 xv6 hello 或者 xv6 引导，

1553
01:23:55,180 --> 01:23:56,800
你不会看到这样的东西，

1554
01:23:57,250 --> 01:23:58,930
所以你什么也看不到，

1555
01:23:59,080 --> 01:24:04,000
然后你必须追踪，并猜测问题可能出在哪里。

1556
01:24:05,640 --> 01:24:08,130
好的，那你是通过查看吗？

1557
01:24:08,660 --> 01:24:12,410
好的，你可以向 UART 同步写一个，

1558
01:24:12,440 --> 01:24:13,730
你可以比如，

1559
01:24:13,940 --> 01:24:17,750
你看到的字符，把它们放在代码中的随机位置，

1560
01:24:17,750 --> 01:24:18,830
希望你能看到一些东西。

1561
01:24:21,440 --> 01:24:23,090
这很有趣，谢谢。

1562
01:24:23,420 --> 01:24:23,660
你知道。

1563
01:24:23,660 --> 01:24:25,610
我想问一下，

1564
01:24:26,000 --> 01:24:30,050
当你，我知道你实现 Go ，

1565
01:24:30,050 --> 01:24:32,960
有一些调用 Go 进行时会创建，

1566
01:24:32,990 --> 01:24:34,730
有一些无法创建，

1567
01:24:34,730 --> 01:24:36,680
因为你正在实现内核本身，

1568
01:24:37,130 --> 01:24:38,780
有没有类似的，

1569
01:24:38,780 --> 01:24:41,480
你是不是使用汇编实现了，

1570
01:24:41,510 --> 01:24:45,200
或者这些也可以使用 Go 来实现，

1571
01:24:45,200 --> 01:24:47,480
比如我们可以让 Go 走地更近一点，

1572
01:24:47,480 --> 01:24:49,520
然后汇编只做需要的事情，

1573
01:24:49,640 --> 01:24:53,720
你说的，一旦 Go 运行时结束，就是汇编？

1574
01:24:54,230 --> 01:24:58,070
这就是 1500 行汇编的来源，

1575
01:24:58,650 --> 01:25:00,990
在 Biscuit 中，

1576
01:25:01,170 --> 01:25:02,760
这基本上就是代码，

1577
01:25:02,760 --> 01:25:06,420
为运行 Go 运行时做好准备。

1578
01:25:08,450 --> 01:25:10,040
其中一些我们可以使用 C 实现，

1579
01:25:10,040 --> 01:25:11,030
但我们不想这样做，

1580
01:25:11,030 --> 01:25:12,260
因为我们不想使用任何 C 语言，

1581
01:25:12,260 --> 01:25:13,160
所以我们使用汇编。

1582
01:25:13,900 --> 01:25:15,940
其中许多需要汇编，

1583
01:25:15,940 --> 01:25:17,110
因为它在引导部分。

1584
01:25:18,250 --> 01:25:20,980
是的，但我想有些部分，不是引导，

1585
01:25:20,980 --> 01:25:26,410
我知道有些你不能避免一些引导代码和汇编，

1586
01:25:26,410 --> 01:25:30,400
但是你能不能把一些汇编改为 Go ，

1587
01:25:30,400 --> 01:25:32,170
还是你做了[]。

1588
01:25:32,170 --> 01:25:34,240
我们做了很多 Go ，

1589
01:25:34,240 --> 01:25:38,050
是在很早的时候就开始了，

1590
01:25:38,480 --> 01:25:41,060
有些 Go 非常小心，

1591
01:25:41,120 --> 01:25:42,860
它不进行任何内存分配，

1592
01:25:46,820 --> 01:25:49,490
我们试着尽可能多地使用 Go ，

1593
01:25:49,520 --> 01:25:52,010
我必须看代码，

1594
01:25:52,010 --> 01:25:54,320
才能回答你的问题，

1595
01:25:54,320 --> 01:25:57,050
具体地说，你可以看看 git repo ，

1596
01:25:57,050 --> 01:26:00,790
但是，是的，我们试着使用 Go 写所有的东西。

1597
01:26:03,580 --> 01:26:06,520
然后我有一个不相干的小问题，

1598
01:26:06,880 --> 01:26:09,970
Go 协程是怎么做的，

1599
01:26:09,970 --> 01:26:13,180
使它可以运行成百上千的 Go 协程，

1600
01:26:14,040 --> 01:26:17,520
因为你不能起成百上千个个线程。

1601
01:26:18,210 --> 01:26:19,680
是的，这要看情况，

1602
01:26:19,710 --> 01:26:23,340
时间很长，

1603
01:26:23,340 --> 01:26:26,760
所以主要的问题是你需要分配堆栈，

1604
01:26:27,320 --> 01:26:31,280
而 Go 运行时会递增地分配堆栈，

1605
01:26:31,490 --> 01:26:36,350
随着你运行 Go 协程，它们会动态增长，

1606
01:26:36,500 --> 01:26:38,870
这是 prologue 代码的作用，

1607
01:26:38,960 --> 01:26:40,160
当你进行函数调用时，

1608
01:26:40,160 --> 01:26:41,570
你会查看是否有足够的空间

1609
01:26:41,570 --> 01:26:44,000
来进行函数调用，

1610
01:26:44,000 --> 01:26:46,520
如果没有，它将为你动态增长。

1611
01:26:47,390 --> 01:26:50,390
通常在 pthread 实现中，

1612
01:26:50,570 --> 01:26:55,370
分配线程是更重量级的，

1613
01:26:55,370 --> 01:27:00,500
因为，比如 Linux 对应，

1614
01:27:00,500 --> 01:27:02,810
对应的内核线程也要被分配，

1615
01:27:03,680 --> 01:27:05,930
它们往往更重量级。

1616
01:27:08,790 --> 01:27:09,390
我明白了,

1617
01:27:10,090 --> 01:27:14,830
Go 协程的调度是否完全在用户空间中完成的，

1618
01:27:14,860 --> 01:27:17,860
或者它帮助自己使用一些内核。

1619
01:27:18,400 --> 01:27:20,950
它主要是在用户空间中完成的。

1620
01:27:25,930 --> 01:27:28,900
所以 Go 运行时分配了一堆内核线程，

1621
01:27:29,520 --> 01:27:32,790
他们把它们叫做 mthreads ，

1622
01:27:32,790 --> 01:27:36,000
在这之上，它实现了 Go 协程。

1623
01:27:37,370 --> 01:27:40,460
所以它有几个内核线程，

1624
01:27:40,460 --> 01:27:43,520
它共享给所有的 Go 协程，基于正在运行的。

1625
01:27:43,880 --> 01:27:44,270
是的。

1626
01:27:44,920 --> 01:27:46,240
哦，理解了，是的。

1627
01:27:47,580 --> 01:27:51,600
有没有类似的 C 或 C++ 的等价物，

1628
01:27:51,750 --> 01:27:56,130
比如，你能不能做这样的事来节省内存。

1629
01:27:56,340 --> 01:27:59,010
是的，人们已经做到了，可以管理高性能，

1630
01:27:59,010 --> 01:28:02,310
C 库是线程库，

1631
01:28:02,310 --> 01:28:05,730
你可以为数以百万计的线程创建数以千计的线程，

1632
01:28:05,730 --> 01:28:08,070
使用类似的方式。

1633
01:28:14,160 --> 01:28:17,100
好了，你们好好休息，我得走了。

1634
01:28:17,130 --> 01:28:17,730
你也是。

1635
01:28:18,060 --> 01:28:24,000
下周或下两周见。

1636
01:28:24,490 --> 01:28:25,750
是的，哦。

1637
01:28:26,660 --> 01:28:27,410
哦，请继续。

1638
01:28:29,220 --> 01:28:34,620
抱歉，我有一个关于垫片的基本问题，

1639
01:28:34,620 --> 01:28:36,900
我想我可能，

1640
01:28:36,900 --> 01:28:41,580
还不太熟悉运行库是什么样子，

1641
01:28:41,790 --> 01:28:44,370
我猜我的疑惑来自这一事实，

1642
01:28:44,370 --> 01:28:48,510
比如，在裸机器上 xv6 和 C 如何工作的，

1643
01:28:48,510 --> 01:28:51,540
C 是一种编译语言，

1644
01:28:51,840 --> 01:28:54,690
所以它直接进入汇编或机器代码，

1645
01:28:54,930 --> 01:28:58,110
所以它像是在 CPU 上运行，

1646
01:28:58,230 --> 01:28:59,520
所以我想，

1647
01:28:59,550 --> 01:29:04,320
就像 xv6 操作系统不需要垫片程序一样，

1648
01:29:04,740 --> 01:29:08,220
但我想 Go 也是一种编译语言，

1649
01:29:08,220 --> 01:29:10,050
所以也会变成汇编语言，

1650
01:29:10,170 --> 01:29:13,410
那么为什么在这种情况下需要垫片，

1651
01:29:13,410 --> 01:29:16,800
xv6 是否有这样的垫片，

1652
01:29:16,800 --> 01:29:18,420
或者这里有什么不同，

1653
01:29:18,420 --> 01:29:22,590
为什么有些事情不能只在 CPU 上做。

1654
01:29:23,070 --> 01:29:24,630
是的，一个很好的问题，

1655
01:29:24,660 --> 01:29:27,270
所以我想你问题的答案是，

1656
01:29:27,270 --> 01:29:30,570
Go 运行时提供了所有类型的功能，

1657
01:29:30,570 --> 01:29:32,850
比如你没有的，

1658
01:29:32,850 --> 01:29:35,910
当你在 xv6 中运行 C 的时候，

1659
01:29:36,210 --> 01:29:38,100
所以 Go 运行时提供线程，

1660
01:29:38,250 --> 01:29:40,350
Go 运行时提供调度器，

1661
01:29:40,350 --> 01:29:43,380
Go 运行时提供哈希表，

1662
01:29:43,380 --> 01:29:45,150
Go 运行时提供垃圾收集器，

1663
01:29:45,420 --> 01:29:47,130
这需要在运行时运行，

1664
01:29:47,130 --> 01:29:49,410
而在 xv6 中没有垃圾收集器，

1665
01:29:49,860 --> 01:29:51,780
并且我们实现了线程，

1666
01:29:52,200 --> 01:29:55,020
比如，为了支持垃圾收集器，

1667
01:29:55,020 --> 01:29:57,420
它需要一个堆来分配内存，

1668
01:29:57,450 --> 01:30:00,270
所以访问底层的操作系统，

1669
01:30:00,270 --> 01:30:01,980
请给我一些内存，

1670
01:30:01,980 --> 01:30:02,940
我可以把它当作堆使用。

1671
01:30:03,610 --> 01:30:08,350
基本上垫片层实现了这些功能，

1672
01:30:08,350 --> 01:30:13,330
Go 运行时在运行时要做的工作。

1673
01:30:23,120 --> 01:30:24,590
我明白。

1674
01:30:25,200 --> 01:30:28,860
是的，你说得有点道理，

1675
01:30:28,860 --> 01:30:30,930
我还有一个后续问题，

1676
01:30:32,550 --> 01:30:34,140
也许这是一个愚蠢的问题，

1677
01:30:34,140 --> 01:30:42,250
比如我们能不能编译运行时到机器代码，或者。

1678
01:30:42,250 --> 01:30:44,290
运行时被编译为运行。

1679
01:30:44,290 --> 01:30:44,740
好的。

1680
01:30:44,860 --> 01:30:47,350
运行库本身也是编译的，

1681
01:30:47,350 --> 01:30:48,700
但这是程序的一部分，

1682
01:30:48,700 --> 01:30:51,460
在运行 Go 代码时需要一直运行。

1683
01:30:52,190 --> 01:30:53,090
它必须在那里，

1684
01:30:53,180 --> 01:30:55,190
就像 C 也有一个很小的运行时，

1685
01:30:55,190 --> 01:30:57,620
如果你想一想，我们有 printf ，

1686
01:30:57,620 --> 01:30:59,210
是 C 运行时的一部分，

1687
01:30:59,600 --> 01:31:02,180
字符串操作是 C 运行时的一部分，

1688
01:31:02,480 --> 01:31:03,650
它们也是编译的，

1689
01:31:03,650 --> 01:31:07,280
但是 C 运行时有一些很少的函数，

1690
01:31:07,430 --> 01:31:10,760
但是它们的运行时太小了，跟 Go 运行时比起来，

1691
01:31:10,760 --> 01:31:12,890
支持更多的功能，

1692
01:31:13,160 --> 01:31:16,010
因为 Go 程序依赖于它们。

1693
01:31:17,320 --> 01:31:18,850
我明白了，我明白了，

1694
01:31:18,850 --> 01:31:20,800
我想最后一个问题可能是这样的，

1695
01:31:20,800 --> 01:31:23,530
在这种情况下，是不是有点像，

1696
01:31:23,530 --> 01:31:27,010
Go 运行时或这种情况下的垫片程序

1697
01:31:27,010 --> 01:31:30,610
承担了一些常用功能，

1698
01:31:30,820 --> 01:31:32,860
就像它几乎就像一个小的，

1699
01:31:33,640 --> 01:31:36,880
它就像一个小的操作系统层，

1700
01:31:36,910 --> 01:31:39,070
就像它是另一层，

1701
01:31:39,070 --> 01:31:43,030
执行一些低级系统功能。

1702
01:31:44,260 --> 01:31:45,430
是的，你可以，

1703
01:31:45,460 --> 01:31:47,440
也许可以用一种方式来考虑 xv6 ，

1704
01:31:47,440 --> 01:31:49,540
它也有一个非常非常小的垫片，

1705
01:31:49,660 --> 01:31:51,460
也许当引导的时候，

1706
01:31:51,460 --> 01:31:53,590
它做的第一件事就是分配一些堆栈，

1707
01:31:53,590 --> 01:31:56,350
就可以调用 C 主函数了。

1708
01:31:57,240 --> 01:31:59,640
你可以考虑一下这段代码，

1709
01:31:59,640 --> 01:32:00,960
它只有几个语句，

1710
01:32:00,960 --> 01:32:02,670
就是 xv6 的垫片层。

1711
01:32:03,710 --> 01:32:06,410
一旦你通过了几个指令，

1712
01:32:06,410 --> 01:32:08,120
你到达 C 代码，一切都很好。

1713
01:32:08,790 --> 01:32:12,690
Go 运行时的垫片层稍微大一些，

1714
01:32:12,690 --> 01:32:14,790
因为还有更多的功能需要设置，

1715
01:32:14,790 --> 01:32:16,950
在 Go 运行时执行之前。

1716
01:32:18,700 --> 01:32:22,150
好的，这很有帮助，很有道理，酷。

1717
01:32:23,150 --> 01:32:23,540
谢谢。

1718
01:32:23,960 --> 01:32:24,590
不用谢。

1719
01:32:25,460 --> 01:32:26,180
感恩节快乐。

1720
01:32:26,420 --> 01:32:27,050
是的，你也是。

1721
01:32:28,240 --> 01:32:32,650
哦，我有个关于 ping-pong 程序的问题忘了问，

1722
01:32:32,680 --> 01:32:36,790
我记得我们在一个实验中也做了一个 ping-pong 程序。

1723
01:32:38,070 --> 01:32:43,950
那不是一百，一千行代码，为什么是。

1724
01:32:44,420 --> 01:32:48,050
因为，第一，我想你说的是实验一，

1725
01:32:48,050 --> 01:32:50,210
你做了 ping-pong 让一个字节通过管道。

1726
01:32:50,860 --> 01:32:51,400
是的。

1727
01:32:51,610 --> 01:32:54,580
好的，那是用户空间的基准测试，

1728
01:32:54,610 --> 01:32:57,550
内核方面是另一面，

1729
01:32:57,550 --> 01:33:00,130
我们所做的是，

1730
01:33:00,130 --> 01:33:02,170
实现以相同方式传递的内核。

1731
01:33:04,530 --> 01:33:05,130
好的。

1732
01:33:05,190 --> 01:33:08,550
所以在执行系统调用，

1733
01:33:08,550 --> 01:33:10,890
使用堆栈帧中的变量，

1734
01:33:10,890 --> 01:33:13,200
调用查看管道，

1735
01:33:13,200 --> 01:33:17,800
然后可能会运行调度程序来唤醒接收者，

1736
01:33:18,010 --> 01:33:20,020
那是整个代码路径，

1737
01:33:20,020 --> 01:33:23,620
在内核方面，我们试图实现它，

1738
01:33:23,620 --> 01:33:25,240
在 C 和 Go 中是一样的。

1739
01:33:25,700 --> 01:33:26,690
好的，我明白了。

1740
01:33:26,720 --> 01:33:28,910
但基准与你的基准一样，

1741
01:33:28,910 --> 01:33:31,010
你在实验一中实现的，

1742
01:33:31,100 --> 01:33:32,330
它的用户级别方面。

1743
01:33:33,250 --> 01:33:35,020
好的，这就说得通了，

1744
01:33:35,050 --> 01:33:37,430
所以，那是不是意味着，

1745
01:33:38,140 --> 01:33:40,390
我的意思是，如果在 xv6 中这样做，

1746
01:33:40,390 --> 01:33:44,080
将大大少于 1000 行代码，

1747
01:33:44,080 --> 01:33:47,560
如果你愿意，使用所有内核代码。

1748
01:33:47,560 --> 01:33:50,470
这里有上千行的汇编指令，

1749
01:33:50,620 --> 01:33:54,370
我不知道，我必须看一下，

1750
01:33:54,370 --> 01:33:57,340
但你会用到 trapframe 代码，

1751
01:33:57,340 --> 01:33:58,750
系统调用调度，

1752
01:33:59,140 --> 01:34:04,240
到 fd 层，文件描述符，

1753
01:34:04,510 --> 01:34:07,600
然后是一小段管道代码，

1754
01:34:07,720 --> 01:34:10,810
然后是 copyin 和 copyout ，

1755
01:34:11,020 --> 01:34:12,640
然后是调度器，

1756
01:34:12,940 --> 01:34:16,780
然后再次跳出或返回。

1757
01:34:17,750 --> 01:34:21,390
是的，好的，这就说得通了。

1758
01:34:21,690 --> 01:34:26,610
我不知道怎么表示脑中的代码，

1759
01:34:26,610 --> 01:34:26,640
但是你知道。

